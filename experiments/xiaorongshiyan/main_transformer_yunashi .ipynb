{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T05:06:51.110932Z",
     "start_time": "2025-07-23T05:06:51.102923Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)  # 你可以换成其它数字\n",
    "# 数据集类\n",
    "class ProteinNPYDataset(Dataset):\n",
    "    def __init__(self, pos_path, neg_path):\n",
    "        self.pos = np.load(pos_path, mmap_mode='r')\n",
    "        self.neg = np.load(neg_path, mmap_mode='r')\n",
    "        self.lengths = [len(self.pos), len(self.neg)]\n",
    "        self.total_len = self.lengths[0] + self.lengths[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.lengths[0]:\n",
    "            x = self.pos[idx]\n",
    "            y = 1\n",
    "        else:\n",
    "            x = self.neg[idx - self.lengths[0]]\n",
    "            y = 0\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "fc31fd06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.619737Z",
     "start_time": "2025-07-23T04:32:33.594914Z"
    }
   },
   "source": [
    "class MLPExperts(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.fc1 = nn.Linear(d_model, d_ff * num_experts, bias=True)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model, bias=True)\n",
    "        self.d_ff = d_ff\n",
    "    def forward(self, x, expert_idx):\n",
    "        # x: [B*L, d_model], expert_idx: [B*L, k]\n",
    "        all_hidden = self.fc1(x)  # [B*L, d_ff * num_experts]\n",
    "        all_hidden = all_hidden.view(x.size(0), self.num_experts, self.d_ff)  # [B*L, num_experts, d_ff]\n",
    "        out = []\n",
    "        for i in range(expert_idx.size(1)):\n",
    "            idx = expert_idx[:, i]  # [B*L]\n",
    "            hidden = all_hidden[torch.arange(x.size(0)), idx]  # [B*L, d_ff]\n",
    "            hidden = F.gelu(hidden)\n",
    "            out_i = self.fc2(hidden)  # [B*L, d_model]\n",
    "            out.append(out_i)\n",
    "        out = torch.stack(out, dim=1)  # [B*L, k, d_model]\n",
    "        return out\n",
    "class NoisyTopKMoE(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts=30, k=2, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.k = k\n",
    "        self.noisy_std = noisy_std\n",
    "        self.experts = MLPExperts(d_model, d_ff, num_experts)\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, d_model]\n",
    "        B, L, D = x.shape\n",
    "        x_flat = x.reshape(-1, D)  # [B*L, D]\n",
    "        gate_logits = self.gate(x_flat)  # [B*L, num_experts]\n",
    "        # Noisy gating\n",
    "        if self.training and self.noisy_std > 0:\n",
    "            noise = torch.randn_like(gate_logits) * self.noisy_std\n",
    "            gate_logits = gate_logits + noise\n",
    "        gate_scores = F.softmax(gate_logits, dim=-1)  # [B*L, num_experts]\n",
    "\n",
    "          # 稀疏路由：只选top-k\n",
    "        topk_val, topk_idx = torch.topk(gate_scores, self.k, dim=-1)  # [B*L, k]\n",
    "        # 负载均衡损失（新版，防止爆炸）\n",
    "        meangate = gate_scores.mean(dim=0)  # [num_experts]\n",
    "        load_balance_loss = (meangate * meangate).sum() * (self.num_experts ** 2)\n",
    "        # 专家并行输出\n",
    "        expert_outs = self.experts(x_flat, topk_idx)  # [B*L, k, d_model]\n",
    "        topk_val = topk_val / (topk_val.sum(dim=-1, keepdim=True) + 1e-9)\n",
    "        moe_out = (expert_outs * topk_val.unsqueeze(-1)).sum(dim=1)  # [B*L, d_model]\n",
    "        moe_out = moe_out.view(B, L, D)\n",
    "        return moe_out, load_balance_loss"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "21ee1baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.693276Z",
     "start_time": "2025-07-23T04:32:33.685629Z"
    }
   },
   "source": [
    "class TransformerMoEBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, num_experts=30, k=3, dropout=0.1, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.moe = NoisyTopKMoE(d_model, d_ff, num_experts, k, noisy_std)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        moe_out, load_balance_loss = self.moe(x)\n",
    "        x = x + self.dropout(moe_out)\n",
    "        x = self.norm2(x)\n",
    "        return x, load_balance_loss\n",
    "\n",
    "class TransformerMoE(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerMoEBlock(d_model, nhead, d_ff, num_experts, k, dropout, noisy_std)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        total_load_balance_loss = 0\n",
    "        for layer in self.layers:\n",
    "            x, lb_loss = layer(x)\n",
    "            total_load_balance_loss += lb_loss\n",
    "        x = x.mean(dim=1)  # 池化\n",
    "        logits = self.classifier(x)\n",
    "        return logits, total_load_balance_loss"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a0b85430a6d3b6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 普通transformer",
   "id": "f9b49e542d7deab4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.732983Z",
     "start_time": "2025-07-23T04:32:33.724555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(F.gelu(self.fc1(x))))\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # ✅ 完全移除位置编码\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ✅ 直接处理输入，不添加位置编码\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + self.dropout(ffn_out)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return x, 0.0\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, d_ff=2048, num_layers=4, dropout=0.1, num_classes=2):\n",
    "        super().__init__()\n",
    "        # ✅ 不使用位置编码，与TransformerMoE保持一致\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, nhead, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        total_load_balance_loss = 0.0\n",
    "        for layer in self.layers:\n",
    "            x, _ = layer(x)\n",
    "        x = x.mean(dim=1)  # 全局平均池化\n",
    "        logits = self.classifier(x)\n",
    "        return logits, total_load_balance_loss"
   ],
   "id": "ff172b9123c9d21c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.764158Z",
     "start_time": "2025-07-23T04:32:33.755317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # 正类概率\n",
    "    \n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "        confusion_matrix, roc_auc_score, average_precision_score\n",
    "    )\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # 计算所有指标\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # 敏感性\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # 特异性\n",
    "    \n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}, AUPRC: {auprc:.4f}, SN: {sn:.4f}, SP: {sp:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc, auc, auprc, sn, sp\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, moe_loss_weight=0.01, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():  # 开启混合精度\n",
    "            logits, lb_loss = model(x)\n",
    "            loss = criterion(logits, y) + moe_loss_weight * lb_loss\n",
    "        scaler.scale(loss).backward()      # 用scaler缩放loss反向传播\n",
    "        scaler.step(optimizer)             # 用scaler.step更新参数\n",
    "        scaler.update()                    # 更新scaler状态\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "id": "e1476e5594aa401d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.823037Z",
     "start_time": "2025-07-23T04:32:33.819857Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "92bbb75e5fe3ac2f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "dff51c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:34:29.460045Z",
     "start_time": "2025-07-23T04:32:35.080689Z"
    }
   },
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# 数据路径\n",
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "\n",
    "train_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4,dropout=0.1,num_classes=2\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = GradScaler()  # 在训练前初始化\n",
    "\n",
    "\n",
    "def train_one_epoch_putong(model, loader, optimizer, criterion, device, moe_loss_weight=0.01, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            logits, lb_loss = model(x)\n",
    "            # ❌ 普通Transformer的lb_loss=0.0，这里应该设为0\n",
    "            loss = criterion(logits, y)  \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "# 初始化scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 训练主循环\n",
    "epochs = 10\n",
    "best_acc = 0\n",
    "best_state = None\n",
    "best_path = \"/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_best.pth\"\n",
    "last_path = \"/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train_one_epoch_putong(model, train_loader, optimizer, criterion, device, scaler=scaler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    # 保存最后一次模型权重\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "    print(f\"Last model saved at epoch {epoch+1} ({last_path})\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/3699395688.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # 在训练前初始化\n",
      "/tmp/ipykernel_3474920/3699395688.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3699395688.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3351\n",
      "Last model saved at epoch 1 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1839\n",
      "Last model saved at epoch 2 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1823\n",
      "Last model saved at epoch 3 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1536\n",
      "Last model saved at epoch 4 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1451\n",
      "Last model saved at epoch 5 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1527\n",
      "Last model saved at epoch 6 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1298\n",
      "Last model saved at epoch 7 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1249\n",
      "Last model saved at epoch 8 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1106\n",
      "Last model saved at epoch 9 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0936\n",
      "Last model saved at epoch 10 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "897d1af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:34:32.852595Z",
     "start_time": "2025-07-23T04:34:29.461842Z"
    }
   },
   "source": [
    "# 1. 加载模型\n",
    "model = Transformer(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4,dropout=0.1,num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # 正类概率\n",
    "    \n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "        confusion_matrix, roc_auc_score, average_precision_score\n",
    "    )\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # 计算所有指标\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # 敏感性\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # 特异性\n",
    "    \n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}, AUPRC: {auprc:.4f}, SN: {sn:.4f}, SP: {sp:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc, auc, auprc, sn, sp\n",
    "\n",
    "\n",
    "# 测试\n",
    "eval_model(model, test_loader, device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/3351279906.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9112, PRE: 0.9242, REC: 0.9535, F1: 0.9386, MCC: 0.7796\n",
      "Test AUC: 0.9664, AUPRC: 0.9862, SN: 0.9535, SP: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9112271540469974,\n",
       " 0.9241706161137441,\n",
       " 0.9535452322738386,\n",
       " 0.9386281588447654,\n",
       " 0.7796373962089861,\n",
       " 0.9663629514178713,\n",
       " 0.9862288602159184,\n",
       " 0.9535452322738386,\n",
       " 0.8066465256797583)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:06:51.100938Z",
     "start_time": "2025-07-23T05:05:00.330950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 重新训练普通Transformer - 修正版本（使用最后轮权重）\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 数据加载\n",
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "\n",
    "train_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 创建普通Transformer模型\n",
    "model = Transformer(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, dropout=0.1, num_classes=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 修正的训练函数\n",
    "def train_one_epoch_transformer(model, loader, optimizer, criterion, device, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            logits, _ = model(x)  # 普通Transformer的lb_loss=0.0\n",
    "            loss = criterion(logits, y)  # ✅ 只使用分类损失\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"=== 重新训练普通Transformer (消融实验baseline) ===\")\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train_one_epoch_transformer(model, train_loader, optimizer, criterion, device, scaler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # ✅ 移除测试集验证，避免过拟合\n",
    "    # 只在训练期间打印训练损失，不在测试集上选择模型\n",
    "\n",
    "# ✅ 保存最后一轮训练后的模型权重\n",
    "save_path = \"/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_baseline_final.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\n✅ 普通Transformer最终权重保存至: {save_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🔥 消融实验对比结果\")\n",
    "print(\"=\"*70)\n",
    "print(\"📊 TransformerMoE (你的SOTA方法):\")\n",
    "print(\"   ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\")\n",
    "print(\"   AUC: 0.9685, AUPRC: 0.9869, SN: 0.9425, SP: 0.8731\")\n",
    "\n",
    "print(f\"\\n📈 普通Transformer (训练15轮后的最终模型):\")\n",
    "# ✅ 使用训练完成后的最终模型进行测试\n",
    "final_results = eval_model(model, test_loader, device)\n",
    "\n",
    "print(f\"\\n🚀 MoE架构带来的性能提升:\")\n",
    "f1_improvement = 0.9454 - final_results[3]\n",
    "mcc_improvement = 0.8120 - final_results[4]\n",
    "auc_improvement = 0.9685 - final_results[5]\n",
    "\n",
    "print(f\"   F1提升: +{f1_improvement:.4f} ({(f1_improvement/final_results[3]*100):.1f}%)\")\n",
    "print(f\"   MCC提升: +{mcc_improvement:.4f}\")\n",
    "print(f\"   AUC提升: +{auc_improvement:.4f}\")\n",
    "\n",
    "if f1_improvement > 0.02:\n",
    "    print(\"   ✨ MoE架构显著提升了模型性能!\")\n",
    "elif f1_improvement > 0.005:\n",
    "    print(\"   👍 MoE架构有一定性能提升\")\n",
    "else:\n",
    "    print(\"   🤔 MoE架构提升有限，需要进一步分析\")\n",
    "\n",
    "print(f\"\\n📋 实验设置说明:\")\n",
    "print(f\"   - 普通Transformer: 训练{epochs}轮，使用最终权重测试\")\n",
    "print(f\"   - TransformerMoE: 训练10轮，使用最终权重测试\")\n",
    "print(f\"   - 两者使用相同的训练数据和超参数\")\n",
    "print(f\"   - 避免基于测试集选择模型，确保公平对比\")"
   ],
   "id": "fd5ab8474f47d187",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1694275328.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 重新训练普通Transformer (消融实验baseline) ===\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/1694275328.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3558\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1823\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1662\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1516\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1483\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1452\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1369\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1247\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1181\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1033\n",
      "\n",
      "✅ 普通Transformer最终权重保存至: /exp_data/sjx/star/experiments/xiaorongshiyan/transformer_baseline_final.pth\n",
      "\n",
      "======================================================================\n",
      "🔥 消融实验对比结果\n",
      "======================================================================\n",
      "📊 TransformerMoE (你的SOTA方法):\n",
      "   ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
      "   AUC: 0.9685, AUPRC: 0.9869, SN: 0.9425, SP: 0.8731\n",
      "\n",
      "📈 普通Transformer (训练15轮后的最终模型):\n",
      "Test ACC: 0.9199, PRE: 0.9211, REC: 0.9707, F1: 0.9452, MCC: 0.8005\n",
      "Test AUC: 0.9631, AUPRC: 0.9831, SN: 0.9707, SP: 0.7946\n",
      "\n",
      "🚀 MoE架构带来的性能提升:\n",
      "   F1提升: +0.0002 (0.0%)\n",
      "   MCC提升: +0.0115\n",
      "   AUC提升: +0.0054\n",
      "   🤔 MoE架构提升有限，需要进一步分析\n",
      "\n",
      "📋 实验设置说明:\n",
      "   - 普通Transformer: 训练10轮，使用最终权重测试\n",
      "   - TransformerMoE: 训练10轮，使用最终权重测试\n",
      "   - 两者使用相同的训练数据和超参数\n",
      "   - 避免基于测试集选择模型，确保公平对比\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 不同层数",
   "id": "4dd7b3027ea8d728"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:54:03.622318Z",
     "start_time": "2025-07-23T04:34:32.853986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据加载\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "\n",
    "train_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 实验不同层数\n",
    "layer_configs = [1, 2, 3, 4]\n",
    "results = {}\n",
    "\n",
    "for num_layers in layer_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"训练 {num_layers}层 TransformerMoE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 创建模型\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, \n",
    "        nhead=8, \n",
    "        d_ff=2048, \n",
    "        num_layers=num_layers, \n",
    "        num_experts=30, \n",
    "        k=3, \n",
    "        dropout=0.1, \n",
    "        noisy_std=1.0, \n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "    \n",
    "    # 优化器和损失函数\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 训练\n",
    "    epochs = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, 0.01, scaler)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # 保存训练完成后的最终模型权重\n",
    "    save_path = f\"/exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_{num_layers}layer_final.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"\\n{num_layers}层模型训练完成，权重保存至: {save_path}\")\n",
    "    \n",
    "    # 测试最终模型性能\n",
    "    print(f\"\\n{num_layers}层TransformerMoE最终测试结果:\")\n",
    "    final_metrics = eval_model(model, test_loader, device)\n",
    "    results[num_layers] = {\n",
    "        'acc': final_metrics[0], 'pre': final_metrics[1], 'rec': final_metrics[2],\n",
    "        'f1': final_metrics[3], 'mcc': final_metrics[4], 'auc': final_metrics[5],\n",
    "        'auprc': final_metrics[6], 'sn': final_metrics[7], 'sp': final_metrics[8]\n",
    "    }\n",
    "\n",
    "# 汇总所有结果\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"所有层数TransformerMoE结果汇总\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Layers':<8}{'ACC':<8}{'PRE':<8}{'REC':<8}{'F1':<8}{'MCC':<8}{'AUC':<8}{'AUPRC':<8}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "for layers in layer_configs:\n",
    "    r = results[layers]\n",
    "    print(f\"{layers:<8}{r['acc']:<8.4f}{r['pre']:<8.4f}{r['rec']:<8.4f}{r['f1']:<8.4f}{r['mcc']:<8.4f}{r['auc']:<8.4f}{r['auprc']:<8.4f}\")\n",
    "  \n"
   ],
   "id": "6068229d909d9a9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "训练 1层 TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 开启混合精度\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6056\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4693\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4554\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4467\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4434\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4344\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4238\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4130\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4137\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3933\n",
      "\n",
      "1层模型训练完成，权重保存至: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_1layer_final.pth\n",
      "\n",
      "1层TransformerMoE最终测试结果:\n",
      "Test ACC: 0.9051, PRE: 0.9297, REC: 0.9377, F1: 0.9337, MCC: 0.7673\n",
      "Test AUC: 0.9543, AUPRC: 0.9804, SN: 0.9377, SP: 0.8248\n",
      "\n",
      "==================================================\n",
      "训练 2层 TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 开启混合精度\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8998\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7754\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7541\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7466\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7405\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7311\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7093\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7040\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6904\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6726\n",
      "\n",
      "2层模型训练完成，权重保存至: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_2layer_final.pth\n",
      "\n",
      "2层TransformerMoE最终测试结果:\n",
      "Test ACC: 0.9034, PRE: 0.9645, REC: 0.8973, F1: 0.9297, MCC: 0.7811\n",
      "Test AUC: 0.9621, AUPRC: 0.9852, SN: 0.8973, SP: 0.9184\n",
      "\n",
      "==================================================\n",
      "训练 3层 TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 开启混合精度\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2840\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0787\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0686\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0517\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0491\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0400\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0369\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0193\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0160\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9982\n",
      "\n",
      "3层模型训练完成，权重保存至: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_3layer_final.pth\n",
      "\n",
      "3层TransformerMoE最终测试结果:\n",
      "Test ACC: 0.9182, PRE: 0.9458, REC: 0.9389, F1: 0.9423, MCC: 0.8017\n",
      "Test AUC: 0.9611, AUPRC: 0.9820, SN: 0.9389, SP: 0.8671\n",
      "\n",
      "==================================================\n",
      "训练 4层 TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 开启混合精度\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5557\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3823\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3616\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3555\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3458\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3378\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3211\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3190\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3105\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3073\n",
      "\n",
      "4层模型训练完成，权重保存至: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_4layer_final.pth\n",
      "\n",
      "4层TransformerMoE最终测试结果:\n",
      "Test ACC: 0.9191, PRE: 0.9300, REC: 0.9584, F1: 0.9440, MCC: 0.7993\n",
      "Test AUC: 0.9329, AUPRC: 0.9480, SN: 0.9584, SP: 0.8218\n",
      "\n",
      "======================================================================\n",
      "所有层数TransformerMoE结果汇总\n",
      "======================================================================\n",
      "Layers  ACC     PRE     REC     F1      MCC     AUC     AUPRC   \n",
      "----------------------------------------------------------------------\n",
      "1       0.9051  0.9297  0.9377  0.9337  0.7673  0.9543  0.9804  \n",
      "2       0.9034  0.9645  0.8973  0.9297  0.7811  0.9621  0.9852  \n",
      "3       0.9182  0.9458  0.9389  0.9423  0.8017  0.9611  0.9820  \n",
      "4       0.9191  0.9300  0.9584  0.9440  0.7993  0.9329  0.9480  \n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:41:07.510753Z",
     "start_time": "2025-07-23T06:32:45.773065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 严格控制随机性的训练对比\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_deterministic_seed(seed=42):\n",
    "    \"\"\"设置更严格的确定性种子\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # 更严格的确定性设置\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# 重新训练4层模型，使用更严格的随机控制\n",
    "set_deterministic_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 创建模型\n",
    "model_new = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, \n",
    "    num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "\n",
    "# 使用相同的训练设置\n",
    "optimizer = torch.optim.AdamW(model_new.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"=== 重新训练4层TransformerMoE (严格随机控制) ===\")\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train_one_epoch(model_new, train_loader, optimizer, criterion, device, 0.01, scaler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "# 测试新训练的模型\n",
    "print(\"\\n=== 新训练的4层模型测试结果 ===\")\n",
    "new_results = eval_model(model_new, test_loader, device)\n",
    "\n",
    "# 加载你的SOTA模型进行对比\n",
    "model_sota = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, \n",
    "    num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "model_sota.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n",
    "\n",
    "print(\"\\n=== SOTA模型测试结果 ===\")\n",
    "sota_results = eval_model(model_sota, test_loader, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 结果对比分析\")\n",
    "print(\"=\"*60)\n",
    "print(f\"SOTA模型 F1: {sota_results[3]:.4f}\")\n",
    "print(f\"新训练模型 F1: {new_results[3]:.4f}\")\n",
    "print(f\"F1差异: {abs(sota_results[3] - new_results[3]):.4f}\")\n",
    "\n",
    "if abs(sota_results[3] - new_results[3]) < 0.01:\n",
    "    print(\"✅ 结果基本一致，差异在合理范围内\")\n",
    "elif abs(sota_results[3] - new_results[3]) < 0.02:\n",
    "    print(\"⚠️ 有一定差异，但仍在可接受范围\")\n",
    "else:\n",
    "    print(\"❗ 差异较大，可能存在其他因素\")"
   ],
   "id": "25ff0aed7353db71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1809652477.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 重新训练4层TransformerMoE (严格随机控制) ===\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 开启混合精度\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/functional.py:5501: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  proj = linear(q, w, b)\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/functional.py:6241: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/functional.py:6246: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  attn_output = torch.bmm(attn_output_weights, v)\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/autograd/graph.py:825: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6783\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3769\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3604\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3480\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3414\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3197\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3178\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2931\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2949\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2835\n",
      "\n",
      "=== 新训练的4层模型测试结果 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/modules/activation.py:1308: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9104, PRE: 0.9441, REC: 0.9291, F1: 0.9365, MCC: 0.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1809652477.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_sota.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SOTA模型测试结果 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/modules/activation.py:1308: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
      "\n",
      "============================================================\n",
      "📊 结果对比分析\n",
      "============================================================\n",
      "SOTA模型 F1: 0.9454\n",
      "新训练模型 F1: 0.9365\n",
      "F1差异: 0.0089\n",
      "✅ 结果基本一致，差异在合理范围内\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:09:50.183440Z",
     "start_time": "2025-07-23T04:09:50.183050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "  # 使用最佳模型进行最终测试\n",
    "    model.load_state_dict(best_state)\n",
    "    final_metrics = eval_model(model, test_loader, device)\n",
    "    results[num_layers] = {\n",
    "        'acc': final_metrics[0], 'pre': final_metrics[1], 'rec': final_metrics[2],\n",
    "        'f1': final_metrics[3], 'mcc': final_metrics[4], 'auc': final_metrics[5],\n",
    "        'auprc': final_metrics[6], 'sn': final_metrics[7], 'sp': final_metrics[8]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{num_layers}层TransformerMoE最终测试结果:\")\n",
    "    print(f\"ACC: {final_metrics[0]:.4f}, PRE: {final_metrics[1]:.4f}, REC: {final_metrics[2]:.4f}\")\n",
    "    print(f\"F1: {final_metrics[3]:.4f}, MCC: {final_metrics[4]:.4f}\")\n",
    "    print(f\"AUC: {final_metrics[5]:.4f}, AUPRC: {final_metrics[6]:.4f}\")\n",
    "    print(f\"SN: {final_metrics[7]:.4f}, SP: {final_metrics[8]:.4f}\")\n",
    "\n",
    "# 汇总所有结果\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"所有层数TransformerMoE结果汇总\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Layers':<8}{'ACC':<8}{'PRE':<8}{'REC':<8}{'F1':<8}{'MCC':<8}{'AUC':<8}{'AUPRC':<8}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "for layers in layer_configs:\n",
    "    r = results[layers]\n",
    "    print(f\"{layers:<8}{r['acc']:<8.4f}{r['pre']:<8.4f}{r['rec']:<8.4f}{r['f1']:<8.4f}{r['mcc']:<8.4f}{r['auc']:<8.4f}{r['auprc']:<8.4f}\")"
   ],
   "id": "9b0ad23965ff0253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 我的最佳模型测试集性能",
   "id": "f0197c0e04fc26d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:31:28.102348Z",
     "start_time": "2025-07-23T06:31:09.749478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设模型结构和ProteinNPYDataset已定义，device已设置\n",
    "import torch\n",
    "\n",
    "# 1. 加载模型\n",
    "model = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2. 加载测试集\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 3. 定义评估函数\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc\n",
    "\n",
    "# 4. 测试\n",
    "eval_model(model, test_loader, device)"
   ],
   "id": "176b7cb9a5004cf2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/4116043199.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9225413402959095,\n",
       " 0.948339483394834,\n",
       " 0.9425427872860636,\n",
       " 0.9454322501532803,\n",
       " 0.8120485793877618)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 记录\n",
    "第一次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "\n",
    "结果 Test ACC: 0.9173, PRE: 0.9199, REC: 0.9682, F1: 0.9434, MCC: 0.7939\n",
    "\n",
    "第二次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=5, num_experts=30, k=2, dropout=0.2, noisy_std=1.0, num_classes=2 epoch=20\n",
    "\n",
    "结果 Test ACC: 0.8973, PRE: 0.9464, REC: 0.9071, F1: 0.9263, MCC: 0.7589\n",
    "\n",
    "第三次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=15\n",
    "结果Test ACC: 0.9121, PRE: 0.9544, REC: 0.9205, F1: 0.9371, MCC: 0.7926\n",
    "\n",
    "第四次参数设置d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "数据集变成不加gan\n",
    "\n",
    "结果：Test ACC: 0.8808, PRE: 0.9570, REC: 0.8716, F1: 0.9123, MCC: 0.7350\n",
    "\n",
    "第五次参数设置d_model=1152, nhead=8, d_ff=2048, num_layers=3, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "\n",
    "结果：Test ACC: 0.9017, PRE: 0.9094, REC: 0.9572, F1: 0.9327, MCC: 0.7540\n",
    "\n",
    "第六次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10 加上了一个kaming初始化\n",
    "\n",
    "结果：Test ACC: 0.9130, PRE: 0.9367, REC: 0.9413, F1: 0.9390, MCC: 0.7871\n",
    "\n",
    "第七次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=40, k=2, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "结果：Test ACC: 0.8782, PRE: 0.9508, REC: 0.8741, F1: 0.9108, MCC: 0.7260\n",
    "\n",
    "第八次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=35, k=2, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "结果Test ACC: 0.9112, PRE: 0.9409, REC: 0.9340, F1: 0.9374, MCC: 0.7848\n",
    "\n",
    "第九次参数设置d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=25, k=2, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "结果Test ACC: 0.8982, PRE: 0.8899, REC: 0.9780, F1: 0.9319, MCC: 0.7452\n",
    "\n",
    "第十次参数设置 d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=1, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "\n",
    "结果：Test ACC: 0.9017, PRE: 0.9657, REC: 0.8936, F1: 0.9283, MCC: 0.7786\n",
    "\n",
    "第十一次参数设置d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "结果Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
    "\n",
    "\n",
    "### 十折验证集\n",
    "参数均使用前边的最佳模型的参数\n",
    "\n",
    "结果：========== 10-Fold CV Results ==========\n",
    "Mean ACC: 0.9401 ± 0.0058\n",
    "Mean PRE: 0.9264\n",
    "Mean REC: 0.9260\n",
    "Mean F1:  0.9252\n",
    "Mean MCC: 0.8523\n",
    "\n",
    "### 十折测试集\n",
    "结果：========== 10-Fold Test Results ==========\n",
    "Mean ACC: 0.9155 ± 0.0048\n",
    "Mean PRE: 0.9338\n",
    "Mean REC: 0.9488\n",
    "Mean F1:  0.9411\n",
    "Mean MCC: 0.7925"
   ],
   "id": "20df39fc2248804a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### sota十折训练集\n",
    " 每一折得分：\n",
    "        ACC        F1       MCC        SN        SP    Recall  Precision  \\\n",
    "0  0.884783  0.918836  0.720346  0.917431  0.804511  0.917431   0.920245   \n",
    "1  0.876087  0.915052  0.689696  0.938838  0.721805  0.938838   0.892442   \n",
    "2  0.891304  0.923313  0.736793  0.920489  0.819549  0.920489   0.926154   \n",
    "3  0.895425  0.927273  0.741669  0.935780  0.795455  0.935780   0.918919   \n",
    "4  0.895425  0.928144  0.738638  0.948012  0.765152  0.948012   0.909091   \n",
    "5  0.877996  0.913846  0.705075  0.908257  0.803030  0.908257   0.919505   \n",
    "6  0.901961  0.932127  0.756676  0.944954  0.795455  0.944954   0.919643   \n",
    "7  0.880174  0.917541  0.700500  0.935780  0.742424  0.935780   0.900000   \n",
    "8  0.886710  0.920973  0.721165  0.926606  0.787879  0.926606   0.915408   \n",
    "9  0.895425  0.928571  0.737651  0.954128  0.750000  0.954128   0.904348   \n",
    " AUC     AUPRC  \n",
    "0  0.958152  0.983695  \n",
    "1  0.936746  0.972714  \n",
    "2  0.944264  0.974113  \n",
    "3  0.946958  0.978492  \n",
    "4  0.965110  0.986893  \n",
    "5  0.922667  0.964155  \n",
    "6  0.942174  0.974796  \n",
    "7  0.942591  0.976072  \n",
    "8  0.944213  0.976352  \n",
    "9  0.932583  0.959434  \n",
    "\n",
    "📈 各指标平均 ± 标准差：\n",
    "ACC: 0.8885 ± 0.0087\n",
    "F1: 0.9226 ± 0.0063\n",
    "MCC: 0.7248 ± 0.0212\n",
    "SN: 0.9330 ± 0.0146\n",
    "SP: 0.7785 ± 0.0319\n",
    "Recall: 0.9330 ± 0.0146\n",
    "Precision: 0.9126 ± 0.0107\n",
    "AUC: 0.9435 ± 0.0120\n",
    "AUPRC: 0.9747 ± 0.0081"
   ],
   "id": "acd92ac1664ca339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 十折交叉验证",
   "id": "ce8481db9fb0292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T03:08:39.450535Z",
     "start_time": "2025-07-20T03:08:39.444790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, average_precision_score\n",
    "\n",
    "import os\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ],
   "id": "d046bb7ba803721d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T03:08:41.397485Z",
     "start_time": "2025-07-20T03:08:41.390460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, moe_loss_weight=0.01, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            logits, lb_loss = model(x)\n",
    "            loss = criterion(logits, y) + moe_loss_weight * lb_loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    print(f\"Val ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc"
   ],
   "id": "cc7e459aef30a0bc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:45:53.281928Z",
     "start_time": "2025-07-19T16:31:18.844487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "\n",
    "# 构建全体索引和标签\n",
    "pos_len = np.load(train_pos, mmap_mode='r').shape[0]\n",
    "neg_len = np.load(train_neg, mmap_mode='r').shape[0]\n",
    "all_indices = np.concatenate([np.arange(pos_len), np.arange(neg_len) + pos_len])\n",
    "all_labels = np.concatenate([np.ones(pos_len, dtype=int), np.zeros(neg_len, dtype=int)])\n",
    "\n",
    "# 数据集\n",
    "full_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "\n",
    "# K折分层\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_indices, all_labels), 1):\n",
    "    print(f\"\\n========== Fold {fold}/10 ==========\")\n",
    "    train_loader = DataLoader(Subset(full_dataset, train_idx), batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(Subset(full_dataset, val_idx), batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[Fold {fold}] Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                logits, lb_loss = model(x)\n",
    "                loss = criterion(logits, y) + 0.01 * lb_loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        all_preds, all_labels_fold = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits, _ = model(x)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels_fold.extend(y.cpu().numpy())\n",
    "        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "        acc = accuracy_score(all_labels_fold, all_preds)\n",
    "        pre = precision_score(all_labels_fold, all_preds)\n",
    "        rec = recall_score(all_labels_fold, all_preds)\n",
    "        f1 = f1_score(all_labels_fold, all_preds)\n",
    "        mcc = matthews_corrcoef(all_labels_fold, all_preds)\n",
    "        print(f\"Val ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_state = model.state_dict()\n",
    "            torch.save(best_state, f\"/exp_data/sjx/star/main_transformer_moe_weight/cv_point/best_fold{fold}.pth\")\n",
    "            print(f\"Best model saved for fold {fold} at epoch {epoch+1}\")\n",
    "\n",
    "    all_metrics.append((best_acc, pre, rec, f1, mcc))\n",
    "    print(f\"[Fold {fold}] Best ACC: {best_acc:.4f}\")\n",
    "\n",
    "# 汇总结果\n",
    "all_metrics = np.array(all_metrics)\n",
    "print(\"\\n========== 10-Fold CV Results ==========\")\n",
    "print(f\"Mean ACC: {all_metrics[:,0].mean():.4f} ± {all_metrics[:,0].std():.4f}\")\n",
    "print(f\"Mean PRE: {all_metrics[:,1].mean():.4f}± {all_metrics[:,1].std():.4f}\")\n",
    "print(f\"Mean REC: {all_metrics[:,2].mean():.4f}± {all_metrics[:,2].std():.4f}\")\n",
    "print(f\"Mean F1:  {all_metrics[:,3].mean():.4f}± {all_metrics[:,3].std():.4f}\")\n",
    "print(f\"Mean MCC: {all_metrics[:,4].mean():.4f}± {all_metrics[:,4].std():.4f}\")"
   ],
   "id": "cde6cd3f45854fd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/10 ==========\n",
      "\n",
      "[Fold 1] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5652\n",
      "Val ACC: 0.9115, PRE: 0.9327, REC: 0.8872, F1: 0.9094, MCC: 0.8239\n",
      "Best model saved for fold 1 at epoch 1\n",
      "\n",
      "[Fold 1] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3694\n",
      "Val ACC: 0.9252, PRE: 0.9215, REC: 0.9299, F1: 0.9256, MCC: 0.8504\n",
      "Best model saved for fold 1 at epoch 2\n",
      "\n",
      "[Fold 1] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3596\n",
      "Val ACC: 0.9328, PRE: 0.9383, REC: 0.9268, F1: 0.9325, MCC: 0.8657\n",
      "Best model saved for fold 1 at epoch 3\n",
      "\n",
      "[Fold 1] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3524\n",
      "Val ACC: 0.9252, PRE: 0.9515, REC: 0.8963, F1: 0.9231, MCC: 0.8518\n",
      "\n",
      "[Fold 1] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3447\n",
      "Val ACC: 0.9298, PRE: 0.9462, REC: 0.9116, F1: 0.9286, MCC: 0.8601\n",
      "\n",
      "[Fold 1] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3282\n",
      "Val ACC: 0.9176, PRE: 0.8743, REC: 0.9756, F1: 0.9222, MCC: 0.8408\n",
      "\n",
      "[Fold 1] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3202\n",
      "Val ACC: 0.9237, PRE: 0.8798, REC: 0.9817, F1: 0.9280, MCC: 0.8531\n",
      "\n",
      "[Fold 1] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3109\n",
      "Val ACC: 0.9405, PRE: 0.9313, REC: 0.9512, F1: 0.9412, MCC: 0.8811\n",
      "Best model saved for fold 1 at epoch 8\n",
      "\n",
      "[Fold 1] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3105\n",
      "Val ACC: 0.9191, PRE: 0.9231, REC: 0.9146, F1: 0.9188, MCC: 0.8382\n",
      "\n",
      "[Fold 1] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3017\n",
      "Val ACC: 0.9267, PRE: 0.9142, REC: 0.9421, F1: 0.9279, MCC: 0.8538\n",
      "[Fold 1] Best ACC: 0.9405\n",
      "\n",
      "========== Fold 2/10 ==========\n",
      "\n",
      "[Fold 2] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6760\n",
      "Val ACC: 0.9405, PRE: 0.9706, REC: 0.9083, F1: 0.9384, MCC: 0.8827\n",
      "Best model saved for fold 2 at epoch 1\n",
      "\n",
      "[Fold 2] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3859\n",
      "Val ACC: 0.9237, PRE: 0.9663, REC: 0.8777, F1: 0.9199, MCC: 0.8509\n",
      "\n",
      "[Fold 2] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3672\n",
      "Val ACC: 0.9313, PRE: 0.8895, REC: 0.9847, F1: 0.9347, MCC: 0.8676\n",
      "\n",
      "[Fold 2] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3574\n",
      "Val ACC: 0.9496, PRE: 0.9428, REC: 0.9572, F1: 0.9499, MCC: 0.8993\n",
      "Best model saved for fold 2 at epoch 4\n",
      "\n",
      "[Fold 2] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3480\n",
      "Val ACC: 0.9481, PRE: 0.9681, REC: 0.9266, F1: 0.9469, MCC: 0.8970\n",
      "\n",
      "[Fold 2] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3399\n",
      "Val ACC: 0.9221, PRE: 0.9539, REC: 0.8869, F1: 0.9192, MCC: 0.8463\n",
      "\n",
      "[Fold 2] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3293\n",
      "Val ACC: 0.9145, PRE: 0.9721, REC: 0.8532, F1: 0.9088, MCC: 0.8352\n",
      "\n",
      "[Fold 2] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3222\n",
      "Val ACC: 0.9496, PRE: 0.9509, REC: 0.9480, F1: 0.9495, MCC: 0.8992\n",
      "\n",
      "[Fold 2] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3238\n",
      "Val ACC: 0.9237, PRE: 0.9425, REC: 0.9021, F1: 0.9219, MCC: 0.8481\n",
      "\n",
      "[Fold 2] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3088\n",
      "Val ACC: 0.9450, PRE: 0.9396, REC: 0.9511, F1: 0.9453, MCC: 0.8901\n",
      "[Fold 2] Best ACC: 0.9496\n",
      "\n",
      "========== Fold 3/10 ==========\n",
      "\n",
      "[Fold 3] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6411\n",
      "Val ACC: 0.9312, PRE: 0.9490, REC: 0.9113, F1: 0.9298, MCC: 0.8631\n",
      "Best model saved for fold 3 at epoch 1\n",
      "\n",
      "[Fold 3] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3839\n",
      "Val ACC: 0.9327, PRE: 0.9275, REC: 0.9388, F1: 0.9331, MCC: 0.8655\n",
      "Best model saved for fold 3 at epoch 2\n",
      "\n",
      "[Fold 3] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3561\n",
      "Val ACC: 0.9358, PRE: 0.9331, REC: 0.9388, F1: 0.9360, MCC: 0.8716\n",
      "Best model saved for fold 3 at epoch 3\n",
      "\n",
      "[Fold 3] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3534\n",
      "Val ACC: 0.9159, PRE: 0.9359, REC: 0.8930, F1: 0.9139, MCC: 0.8327\n",
      "\n",
      "[Fold 3] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3500\n",
      "Val ACC: 0.9297, PRE: 0.9049, REC: 0.9602, F1: 0.9318, MCC: 0.8609\n",
      "\n",
      "[Fold 3] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3373\n",
      "Val ACC: 0.9327, PRE: 0.9464, REC: 0.9174, F1: 0.9317, MCC: 0.8658\n",
      "\n",
      "[Fold 3] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3219\n",
      "Val ACC: 0.9235, PRE: 0.9511, REC: 0.8930, F1: 0.9211, MCC: 0.8487\n",
      "\n",
      "[Fold 3] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3185\n",
      "Val ACC: 0.9235, PRE: 0.9184, REC: 0.9297, F1: 0.9240, MCC: 0.8472\n",
      "\n",
      "[Fold 3] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3068\n",
      "Val ACC: 0.9297, PRE: 0.9404, REC: 0.9174, F1: 0.9288, MCC: 0.8596\n",
      "\n",
      "[Fold 3] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3044\n",
      "Val ACC: 0.9052, PRE: 0.9585, REC: 0.8471, F1: 0.8994, MCC: 0.8159\n",
      "[Fold 3] Best ACC: 0.9358\n",
      "\n",
      "========== Fold 4/10 ==========\n",
      "\n",
      "[Fold 4] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6252\n",
      "Val ACC: 0.9495, PRE: 0.9401, REC: 0.9602, F1: 0.9501, MCC: 0.8993\n",
      "Best model saved for fold 4 at epoch 1\n",
      "\n",
      "[Fold 4] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3803\n",
      "Val ACC: 0.9480, PRE: 0.9564, REC: 0.9388, F1: 0.9475, MCC: 0.8962\n",
      "\n",
      "[Fold 4] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3782\n",
      "Val ACC: 0.9251, PRE: 0.8819, REC: 0.9817, F1: 0.9291, MCC: 0.8556\n",
      "\n",
      "[Fold 4] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3507\n",
      "Val ACC: 0.9434, PRE: 0.9475, REC: 0.9388, F1: 0.9432, MCC: 0.8869\n",
      "\n",
      "[Fold 4] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3403\n",
      "Val ACC: 0.9343, PRE: 0.9226, REC: 0.9480, F1: 0.9351, MCC: 0.8688\n",
      "\n",
      "[Fold 4] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3386\n",
      "Val ACC: 0.9450, PRE: 0.9477, REC: 0.9419, F1: 0.9448, MCC: 0.8899\n",
      "\n",
      "[Fold 4] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3254\n",
      "Val ACC: 0.9037, PRE: 0.9074, REC: 0.8991, F1: 0.9032, MCC: 0.8074\n",
      "\n",
      "[Fold 4] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3125\n",
      "Val ACC: 0.9205, PRE: 0.9310, REC: 0.9083, F1: 0.9195, MCC: 0.8412\n",
      "\n",
      "[Fold 4] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3007\n",
      "Val ACC: 0.9343, PRE: 0.9176, REC: 0.9541, F1: 0.9355, MCC: 0.8692\n",
      "\n",
      "[Fold 4] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3137\n",
      "Val ACC: 0.9327, PRE: 0.9174, REC: 0.9511, F1: 0.9339, MCC: 0.8660\n",
      "[Fold 4] Best ACC: 0.9495\n",
      "\n",
      "========== Fold 5/10 ==========\n",
      "\n",
      "[Fold 5] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6743\n",
      "Val ACC: 0.9220, PRE: 0.8966, REC: 0.9541, F1: 0.9244, MCC: 0.8458\n",
      "Best model saved for fold 5 at epoch 1\n",
      "\n",
      "[Fold 5] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3820\n",
      "Val ACC: 0.9281, PRE: 0.9403, REC: 0.9144, F1: 0.9271, MCC: 0.8566\n",
      "Best model saved for fold 5 at epoch 2\n",
      "\n",
      "[Fold 5] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3556\n",
      "Val ACC: 0.9373, PRE: 0.9206, REC: 0.9572, F1: 0.9385, MCC: 0.8753\n",
      "Best model saved for fold 5 at epoch 3\n",
      "\n",
      "[Fold 5] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3469\n",
      "Val ACC: 0.9327, PRE: 0.9174, REC: 0.9511, F1: 0.9339, MCC: 0.8660\n",
      "\n",
      "[Fold 5] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3418\n",
      "Val ACC: 0.9266, PRE: 0.8974, REC: 0.9633, F1: 0.9292, MCC: 0.8555\n",
      "\n",
      "[Fold 5] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3314\n",
      "Val ACC: 0.9266, PRE: 0.8952, REC: 0.9664, F1: 0.9294, MCC: 0.8559\n",
      "\n",
      "[Fold 5] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3155\n",
      "Val ACC: 0.9098, PRE: 0.9408, REC: 0.8746, F1: 0.9065, MCC: 0.8216\n",
      "\n",
      "[Fold 5] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3304\n",
      "Val ACC: 0.9144, PRE: 0.8712, REC: 0.9725, F1: 0.9191, MCC: 0.8344\n",
      "\n",
      "[Fold 5] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3061\n",
      "Val ACC: 0.9220, PRE: 0.8988, REC: 0.9511, F1: 0.9242, MCC: 0.8455\n",
      "\n",
      "[Fold 5] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3054\n",
      "Val ACC: 0.9312, PRE: 0.9379, REC: 0.9235, F1: 0.9307, MCC: 0.8625\n",
      "[Fold 5] Best ACC: 0.9373\n",
      "\n",
      "========== Fold 6/10 ==========\n",
      "\n",
      "[Fold 6] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6754\n",
      "Val ACC: 0.9251, PRE: 0.9696, REC: 0.8777, F1: 0.9213, MCC: 0.8540\n",
      "Best model saved for fold 6 at epoch 1\n",
      "\n",
      "[Fold 6] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3838\n",
      "Val ACC: 0.9358, PRE: 0.9582, REC: 0.9113, F1: 0.9342, MCC: 0.8726\n",
      "Best model saved for fold 6 at epoch 2\n",
      "\n",
      "[Fold 6] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3685\n",
      "Val ACC: 0.9373, PRE: 0.9583, REC: 0.9144, F1: 0.9358, MCC: 0.8755\n",
      "Best model saved for fold 6 at epoch 3\n",
      "\n",
      "[Fold 6] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3521\n",
      "Val ACC: 0.9220, PRE: 0.8730, REC: 0.9878, F1: 0.9268, MCC: 0.8514\n",
      "\n",
      "[Fold 6] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3478\n",
      "Val ACC: 0.9434, PRE: 0.9290, REC: 0.9602, F1: 0.9444, MCC: 0.8874\n",
      "Best model saved for fold 6 at epoch 5\n",
      "\n",
      "[Fold 6] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3415\n",
      "Val ACC: 0.9312, PRE: 0.9548, REC: 0.9052, F1: 0.9294, MCC: 0.8636\n",
      "\n",
      "[Fold 6] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3325\n",
      "Val ACC: 0.9251, PRE: 0.9696, REC: 0.8777, F1: 0.9213, MCC: 0.8540\n",
      "\n",
      "[Fold 6] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3147\n",
      "Val ACC: 0.9434, PRE: 0.9290, REC: 0.9602, F1: 0.9444, MCC: 0.8874\n",
      "\n",
      "[Fold 6] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3241\n",
      "Val ACC: 0.9495, PRE: 0.9623, REC: 0.9358, F1: 0.9488, MCC: 0.8994\n",
      "Best model saved for fold 6 at epoch 9\n",
      "\n",
      "[Fold 6] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3082\n",
      "Val ACC: 0.9174, PRE: 0.9691, REC: 0.8624, F1: 0.9126, MCC: 0.8400\n",
      "[Fold 6] Best ACC: 0.9495\n",
      "\n",
      "========== Fold 7/10 ==========\n",
      "\n",
      "[Fold 7] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5767\n",
      "Val ACC: 0.9312, PRE: 0.9147, REC: 0.9511, F1: 0.9325, MCC: 0.8631\n",
      "Best model saved for fold 7 at epoch 1\n",
      "\n",
      "[Fold 7] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3784\n",
      "Val ACC: 0.9388, PRE: 0.9184, REC: 0.9633, F1: 0.9403, MCC: 0.8787\n",
      "Best model saved for fold 7 at epoch 2\n",
      "\n",
      "[Fold 7] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3571\n",
      "Val ACC: 0.9190, PRE: 0.8806, REC: 0.9694, F1: 0.9229, MCC: 0.8422\n",
      "\n",
      "[Fold 7] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3518\n",
      "Val ACC: 0.9281, PRE: 0.9217, REC: 0.9358, F1: 0.9287, MCC: 0.8564\n",
      "\n",
      "[Fold 7] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3414\n",
      "Val ACC: 0.9297, PRE: 0.9460, REC: 0.9113, F1: 0.9283, MCC: 0.8599\n",
      "\n",
      "[Fold 7] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3384\n",
      "Val ACC: 0.9113, PRE: 0.8587, REC: 0.9847, F1: 0.9174, MCC: 0.8316\n",
      "\n",
      "[Fold 7] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3220\n",
      "Val ACC: 0.9297, PRE: 0.9377, REC: 0.9205, F1: 0.9290, MCC: 0.8595\n",
      "\n",
      "[Fold 7] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3190\n",
      "Val ACC: 0.9312, PRE: 0.9352, REC: 0.9266, F1: 0.9309, MCC: 0.8624\n",
      "\n",
      "[Fold 7] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3087\n",
      "Val ACC: 0.9373, PRE: 0.9333, REC: 0.9419, F1: 0.9376, MCC: 0.8747\n",
      "\n",
      "[Fold 7] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3073\n",
      "Val ACC: 0.9190, PRE: 0.8848, REC: 0.9633, F1: 0.9224, MCC: 0.8412\n",
      "[Fold 7] Best ACC: 0.9388\n",
      "\n",
      "========== Fold 8/10 ==========\n",
      "\n",
      "[Fold 8] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5816\n",
      "Val ACC: 0.9343, PRE: 0.9410, REC: 0.9266, F1: 0.9337, MCC: 0.8686\n",
      "Best model saved for fold 8 at epoch 1\n",
      "\n",
      "[Fold 8] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3854\n",
      "Val ACC: 0.9266, PRE: 0.8974, REC: 0.9633, F1: 0.9292, MCC: 0.8555\n",
      "\n",
      "[Fold 8] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3647\n",
      "Val ACC: 0.9220, PRE: 0.8730, REC: 0.9878, F1: 0.9268, MCC: 0.8514\n",
      "\n",
      "[Fold 8] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3515\n",
      "Val ACC: 0.9220, PRE: 0.9395, REC: 0.9021, F1: 0.9204, MCC: 0.8447\n",
      "\n",
      "[Fold 8] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3449\n",
      "Val ACC: 0.9159, PRE: 0.8676, REC: 0.9817, F1: 0.9211, MCC: 0.8391\n",
      "\n",
      "[Fold 8] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3329\n",
      "Val ACC: 0.9388, PRE: 0.9388, REC: 0.9388, F1: 0.9388, MCC: 0.8777\n",
      "Best model saved for fold 8 at epoch 6\n",
      "\n",
      "[Fold 8] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3322\n",
      "Val ACC: 0.9450, PRE: 0.9396, REC: 0.9511, F1: 0.9453, MCC: 0.8900\n",
      "Best model saved for fold 8 at epoch 7\n",
      "\n",
      "[Fold 8] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3325\n",
      "Val ACC: 0.9312, PRE: 0.9172, REC: 0.9480, F1: 0.9323, MCC: 0.8629\n",
      "\n",
      "[Fold 8] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3134\n",
      "Val ACC: 0.9297, PRE: 0.9518, REC: 0.9052, F1: 0.9279, MCC: 0.8604\n",
      "\n",
      "[Fold 8] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3057\n",
      "Val ACC: 0.9190, PRE: 0.9177, REC: 0.9205, F1: 0.9191, MCC: 0.8379\n",
      "[Fold 8] Best ACC: 0.9450\n",
      "\n",
      "========== Fold 9/10 ==========\n",
      "\n",
      "[Fold 9] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5858\n",
      "Val ACC: 0.9266, PRE: 0.9240, REC: 0.9297, F1: 0.9268, MCC: 0.8532\n",
      "Best model saved for fold 9 at epoch 1\n",
      "\n",
      "[Fold 9] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3787\n",
      "Val ACC: 0.9281, PRE: 0.9268, REC: 0.9297, F1: 0.9282, MCC: 0.8563\n",
      "Best model saved for fold 9 at epoch 2\n",
      "\n",
      "[Fold 9] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3666\n",
      "Val ACC: 0.9343, PRE: 0.9410, REC: 0.9266, F1: 0.9337, MCC: 0.8686\n",
      "Best model saved for fold 9 at epoch 3\n",
      "\n",
      "[Fold 9] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3516\n",
      "Val ACC: 0.9190, PRE: 0.9053, REC: 0.9358, F1: 0.9203, MCC: 0.8384\n",
      "\n",
      "[Fold 9] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3365\n",
      "Val ACC: 0.9297, PRE: 0.9120, REC: 0.9511, F1: 0.9311, MCC: 0.8601\n",
      "\n",
      "[Fold 9] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3327\n",
      "Val ACC: 0.9297, PRE: 0.9194, REC: 0.9419, F1: 0.9305, MCC: 0.8596\n",
      "\n",
      "[Fold 9] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3212\n",
      "Val ACC: 0.9251, PRE: 0.8971, REC: 0.9602, F1: 0.9276, MCC: 0.8523\n",
      "\n",
      "[Fold 9] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3083\n",
      "Val ACC: 0.9312, PRE: 0.8983, REC: 0.9725, F1: 0.9339, MCC: 0.8653\n",
      "\n",
      "[Fold 9] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3090\n",
      "Val ACC: 0.9235, PRE: 0.9134, REC: 0.9358, F1: 0.9245, MCC: 0.8473\n",
      "\n",
      "[Fold 9] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2986\n",
      "Val ACC: 0.9343, PRE: 0.9303, REC: 0.9388, F1: 0.9346, MCC: 0.8685\n",
      "[Fold 9] Best ACC: 0.9343\n",
      "\n",
      "========== Fold 10/10 ==========\n",
      "\n",
      "[Fold 10] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5124\n",
      "Val ACC: 0.9144, PRE: 0.9562, REC: 0.8685, F1: 0.9103, MCC: 0.8323\n",
      "Best model saved for fold 10 at epoch 1\n",
      "\n",
      "[Fold 10] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3734\n",
      "Val ACC: 0.9220, PRE: 0.9313, REC: 0.9113, F1: 0.9212, MCC: 0.8442\n",
      "Best model saved for fold 10 at epoch 2\n",
      "\n",
      "[Fold 10] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3590\n",
      "Val ACC: 0.9052, PRE: 0.9749, REC: 0.8318, F1: 0.8977, MCC: 0.8193\n",
      "\n",
      "[Fold 10] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3600\n",
      "Val ACC: 0.9235, PRE: 0.9397, REC: 0.9052, F1: 0.9221, MCC: 0.8477\n",
      "Best model saved for fold 10 at epoch 4\n",
      "\n",
      "[Fold 10] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3377\n",
      "Val ACC: 0.9190, PRE: 0.9308, REC: 0.9052, F1: 0.9178, MCC: 0.8382\n",
      "\n",
      "[Fold 10] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3370\n",
      "Val ACC: 0.9235, PRE: 0.9315, REC: 0.9144, F1: 0.9228, MCC: 0.8472\n",
      "\n",
      "[Fold 10] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3217\n",
      "Val ACC: 0.9159, PRE: 0.8757, REC: 0.9694, F1: 0.9202, MCC: 0.8366\n",
      "\n",
      "[Fold 10] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3195\n",
      "Val ACC: 0.9312, PRE: 0.9434, REC: 0.9174, F1: 0.9302, MCC: 0.8627\n",
      "Best model saved for fold 10 at epoch 8\n",
      "\n",
      "[Fold 10] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3070\n",
      "Val ACC: 0.9144, PRE: 0.9357, REC: 0.8899, F1: 0.9122, MCC: 0.8297\n",
      "\n",
      "[Fold 10] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3082\n",
      "Val ACC: 0.9235, PRE: 0.9369, REC: 0.9083, F1: 0.9224, MCC: 0.8475\n",
      "[Fold 10] Best ACC: 0.9312\n",
      "\n",
      "========== 10-Fold CV Results ==========\n",
      "Mean ACC: 0.9411 ± 0.0065\n",
      "Mean PRE: 0.9306± 0.0227\n",
      "Mean REC: 0.9208± 0.0366\n",
      "Mean F1:  0.9248± 0.0122\n",
      "Mean MCC: 0.8524± 0.0195\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:16:09.729953Z",
     "start_time": "2025-07-20T03:08:55.561334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "\n",
    "# 构建全体索引和标签\n",
    "pos_len = np.load(train_pos, mmap_mode='r').shape[0]\n",
    "neg_len = np.load(train_neg, mmap_mode='r').shape[0]\n",
    "all_indices = np.concatenate([np.arange(pos_len), np.arange(neg_len) + pos_len])\n",
    "all_labels = np.concatenate([np.ones(pos_len, dtype=int), np.zeros(neg_len, dtype=int)])\n",
    "\n",
    "# 数据集\n",
    "full_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "\n",
    "# K折分层\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_indices, all_labels), 1):\n",
    "    print(f\"\\n========== Fold {fold}/10 ==========\")\n",
    "    train_loader = DataLoader(Subset(full_dataset, train_idx), batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(Subset(full_dataset, val_idx), batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[Fold {fold}] Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                logits, lb_loss = model(x)\n",
    "                loss = criterion(logits, y) + 0.01 * lb_loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"训练损失: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        all_preds, all_labels_fold = [], []\n",
    "        all_probs = []  # 存储预测概率用于AUC和AUPRC计算\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits, _ = model(x)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels_fold.extend(y.cpu().numpy())\n",
    "                all_probs.extend(probs[:, 1].cpu().numpy())  # 正类的概率\n",
    "        \n",
    "        # 计算所有指标\n",
    "        acc = accuracy_score(all_labels_fold, all_preds)\n",
    "        pre = precision_score(all_labels_fold, all_preds)\n",
    "        rec = recall_score(all_labels_fold, all_preds)\n",
    "        f1 = f1_score(all_labels_fold, all_preds)\n",
    "        mcc = matthews_corrcoef(all_labels_fold, all_preds)\n",
    "        \n",
    "        # 计算SN（敏感性/召回率）和SP（特异性）\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels_fold, all_preds).ravel()\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # 敏感性\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # 特异性\n",
    "        \n",
    "        # 计算AUC和AUPRC\n",
    "        auc = roc_auc_score(all_labels_fold, all_probs)\n",
    "        auprc = average_precision_score(all_labels_fold, all_probs)\n",
    "        \n",
    "        print(f\"验证准确率: {acc:.4f}, 精确率: {pre:.4f}, 召回率: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "        print(f\"敏感性(SN): {sn:.4f}, 特异性(SP): {sp:.4f}, AUC: {auc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_state = model.state_dict()\n",
    "            # 确保保存目录存在\n",
    "            save_dir = \"/exp_data/sjx/star/main_transformer_moe_weight/cv_point\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            torch.save(best_state, f\"{save_dir}/best_fold{fold}.pth\")\n",
    "            print(f\"Fold {fold} 第 {epoch+1} 轮的最佳模型已保存\")\n",
    "\n",
    "    # 保存该fold的最佳指标\n",
    "    all_metrics.append((best_acc, pre, rec, f1, mcc, sn, sp, auc, auprc))\n",
    "    print(f\"[Fold {fold}] 最佳准确率: {best_acc:.4f}\")\n",
    "\n",
    "# 汇总结果\n",
    "all_metrics = np.array(all_metrics)\n",
    "print(\"\\n========== 10折交叉验证结果汇总 ==========\")\n",
    "print(f\"平均准确率: {all_metrics[:,0].mean():.4f} ± {all_metrics[:,0].std():.4f}\")\n",
    "print(f\"平均精确率: {all_metrics[:,1].mean():.4f} ± {all_metrics[:,1].std():.4f}\")\n",
    "print(f\"平均召回率: {all_metrics[:,2].mean():.4f} ± {all_metrics[:,2].std():.4f}\")\n",
    "print(f\"平均F1分数: {all_metrics[:,3].mean():.4f} ± {all_metrics[:,3].std():.4f}\")\n",
    "print(f\"平均MCC: {all_metrics[:,4].mean():.4f} ± {all_metrics[:,4].std():.4f}\")\n",
    "print(f\"平均敏感性(SN): {all_metrics[:,5].mean():.4f} ± {all_metrics[:,5].std():.4f}\")\n",
    "print(f\"平均特异性(SP): {all_metrics[:,6].mean():.4f} ± {all_metrics[:,6].std():.4f}\")\n",
    "print(f\"平均AUC: {all_metrics[:,7].mean():.4f} ± {all_metrics[:,7].std():.4f}\")\n",
    "print(f\"平均AUPRC: {all_metrics[:,8].mean():.4f} ± {all_metrics[:,8].std():.4f}\") "
   ],
   "id": "790e5abf7006612e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/10 ==========\n",
      "\n",
      "[Fold 1] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.7336\n",
      "验证准确率: 0.9176, 精确率: 0.8870, 召回率: 0.9573, F1: 0.9208, MCC: 0.8377\n",
      "敏感性(SN): 0.9573, 特异性(SP): 0.8777, AUC: 0.9727, AUPRC: 0.9660\n",
      "Fold 1 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 1] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3743\n",
      "验证准确率: 0.9206, 精确率: 0.9207, 召回率: 0.9207, F1: 0.9207, MCC: 0.8412\n",
      "敏感性(SN): 0.9207, 特异性(SP): 0.9205, AUC: 0.9791, AUPRC: 0.9777\n",
      "Fold 1 第 2 轮的最佳模型已保存\n",
      "\n",
      "[Fold 1] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3609\n",
      "验证准确率: 0.9130, 精确率: 0.9472, 召回率: 0.8750, F1: 0.9097, MCC: 0.8284\n",
      "敏感性(SN): 0.8750, 特异性(SP): 0.9511, AUC: 0.9787, AUPRC: 0.9764\n",
      "\n",
      "[Fold 1] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3552\n",
      "验证准确率: 0.9282, 精确率: 0.8871, 召回率: 0.9817, F1: 0.9320, MCC: 0.8614\n",
      "敏感性(SN): 0.9817, 特异性(SP): 0.8746, AUC: 0.9811, AUPRC: 0.9749\n",
      "Fold 1 第 4 轮的最佳模型已保存\n",
      "\n",
      "[Fold 1] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3404\n",
      "验证准确率: 0.9206, 精确率: 0.8943, 召回率: 0.9543, F1: 0.9233, MCC: 0.8431\n",
      "敏感性(SN): 0.9543, 特异性(SP): 0.8869, AUC: 0.9757, AUPRC: 0.9688\n",
      "\n",
      "[Fold 1] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3362\n",
      "验证准确率: 0.9313, 精确率: 0.9101, 召回率: 0.9573, F1: 0.9331, MCC: 0.8637\n",
      "敏感性(SN): 0.9573, 特异性(SP): 0.9052, AUC: 0.9782, AUPRC: 0.9701\n",
      "Fold 1 第 6 轮的最佳模型已保存\n",
      "\n",
      "[Fold 1] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3225\n",
      "验证准确率: 0.9328, 精确率: 0.9034, 召回率: 0.9695, F1: 0.9353, MCC: 0.8680\n",
      "敏感性(SN): 0.9695, 特异性(SP): 0.8960, AUC: 0.9756, AUPRC: 0.9600\n",
      "Fold 1 第 7 轮的最佳模型已保存\n",
      "\n",
      "[Fold 1] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3172\n",
      "验证准确率: 0.9176, 精确率: 0.9335, 召回率: 0.8994, F1: 0.9161, MCC: 0.8357\n",
      "敏感性(SN): 0.8994, 特异性(SP): 0.9358, AUC: 0.9776, AUPRC: 0.9726\n",
      "\n",
      "[Fold 1] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3054\n",
      "验证准确率: 0.9252, 精确率: 0.9043, 召回率: 0.9512, F1: 0.9272, MCC: 0.8515\n",
      "敏感性(SN): 0.9512, 特异性(SP): 0.8991, AUC: 0.9787, AUPRC: 0.9751\n",
      "\n",
      "[Fold 1] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.2861\n",
      "验证准确率: 0.9252, 精确率: 0.9240, 召回率: 0.9268, F1: 0.9254, MCC: 0.8504\n",
      "敏感性(SN): 0.9268, 特异性(SP): 0.9235, AUC: 0.9772, AUPRC: 0.9721\n",
      "[Fold 1] 最佳准确率: 0.9328\n",
      "\n",
      "========== Fold 2/10 ==========\n",
      "\n",
      "[Fold 2] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.6946\n",
      "验证准确率: 0.9420, 精确率: 0.9530, 召回率: 0.9297, F1: 0.9412, MCC: 0.8842\n",
      "敏感性(SN): 0.9297, 特异性(SP): 0.9543, AUC: 0.9855, AUPRC: 0.9776\n",
      "Fold 2 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 2] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3795\n",
      "验证准确率: 0.9115, 精确率: 0.8530, 召回率: 0.9939, F1: 0.9181, MCC: 0.8344\n",
      "敏感性(SN): 0.9939, 特异性(SP): 0.8293, AUC: 0.9870, AUPRC: 0.9821\n",
      "\n",
      "[Fold 2] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3732\n",
      "验证准确率: 0.9420, 精确率: 0.9140, 召回率: 0.9755, F1: 0.9438, MCC: 0.8860\n",
      "敏感性(SN): 0.9755, 特异性(SP): 0.9085, AUC: 0.9869, AUPRC: 0.9838\n",
      "\n",
      "[Fold 2] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3498\n",
      "验证准确率: 0.9527, 精确率: 0.9405, 召回率: 0.9664, F1: 0.9532, MCC: 0.9057\n",
      "敏感性(SN): 0.9664, 特异性(SP): 0.9390, AUC: 0.9869, AUPRC: 0.9841\n",
      "Fold 2 第 4 轮的最佳模型已保存\n",
      "\n",
      "[Fold 2] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3453\n",
      "验证准确率: 0.9496, 精确率: 0.9298, 召回率: 0.9725, F1: 0.9507, MCC: 0.9002\n",
      "敏感性(SN): 0.9725, 特异性(SP): 0.9268, AUC: 0.9849, AUPRC: 0.9817\n",
      "\n",
      "[Fold 2] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3256\n",
      "验证准确率: 0.8992, 精确率: 0.9336, 召回率: 0.8593, F1: 0.8949, MCC: 0.8010\n",
      "敏感性(SN): 0.8593, 特异性(SP): 0.9390, AUC: 0.9763, AUPRC: 0.9739\n",
      "\n",
      "[Fold 2] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3231\n",
      "验证准确率: 0.9191, 精确率: 0.9597, 召回率: 0.8746, F1: 0.9152, MCC: 0.8415\n",
      "敏感性(SN): 0.8746, 特异性(SP): 0.9634, AUC: 0.9836, AUPRC: 0.9813\n",
      "\n",
      "[Fold 2] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3168\n",
      "验证准确率: 0.9115, 精确率: 0.9622, 召回率: 0.8563, F1: 0.9061, MCC: 0.8279\n",
      "敏感性(SN): 0.8563, 特异性(SP): 0.9665, AUC: 0.9810, AUPRC: 0.9767\n",
      "\n",
      "[Fold 2] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3100\n",
      "验证准确率: 0.9344, 精确率: 0.9610, 召回率: 0.9052, F1: 0.9323, MCC: 0.8702\n",
      "敏感性(SN): 0.9052, 特异性(SP): 0.9634, AUC: 0.9816, AUPRC: 0.9771\n",
      "\n",
      "[Fold 2] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.2960\n",
      "验证准确率: 0.9176, 精确率: 0.9596, 召回率: 0.8716, F1: 0.9135, MCC: 0.8386\n",
      "敏感性(SN): 0.8716, 特异性(SP): 0.9634, AUC: 0.9817, AUPRC: 0.9795\n",
      "[Fold 2] 最佳准确率: 0.9527\n",
      "\n",
      "========== Fold 3/10 ==========\n",
      "\n",
      "[Fold 3] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.5004\n",
      "验证准确率: 0.9205, 精确率: 0.9568, 召回率: 0.8807, F1: 0.9172, MCC: 0.8436\n",
      "敏感性(SN): 0.8807, 特异性(SP): 0.9602, AUC: 0.9789, AUPRC: 0.9753\n",
      "Fold 3 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 3] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3890\n",
      "验证准确率: 0.9281, 精确率: 0.9430, 召回率: 0.9113, F1: 0.9269, MCC: 0.8568\n",
      "敏感性(SN): 0.9113, 特异性(SP): 0.9450, AUC: 0.9823, AUPRC: 0.9807\n",
      "Fold 3 第 2 轮的最佳模型已保存\n",
      "\n",
      "[Fold 3] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3592\n",
      "验证准确率: 0.9266, 精确率: 0.9515, 召回率: 0.8991, F1: 0.9245, MCC: 0.8545\n",
      "敏感性(SN): 0.8991, 特异性(SP): 0.9541, AUC: 0.9839, AUPRC: 0.9826\n",
      "\n",
      "[Fold 3] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3496\n",
      "验证准确率: 0.9266, 精确率: 0.9067, 召回率: 0.9511, F1: 0.9284, MCC: 0.8542\n",
      "敏感性(SN): 0.9511, 特异性(SP): 0.9021, AUC: 0.9811, AUPRC: 0.9791\n",
      "\n",
      "[Fold 3] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3535\n",
      "验证准确率: 0.9373, 精确率: 0.9441, 召回率: 0.9297, F1: 0.9368, MCC: 0.8747\n",
      "敏感性(SN): 0.9297, 特异性(SP): 0.9450, AUC: 0.9849, AUPRC: 0.9851\n",
      "Fold 3 第 5 轮的最佳模型已保存\n",
      "\n",
      "[Fold 3] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3345\n",
      "验证准确率: 0.9251, 精确率: 0.9572, 召回率: 0.8899, F1: 0.9223, MCC: 0.8523\n",
      "敏感性(SN): 0.8899, 特异性(SP): 0.9602, AUC: 0.9855, AUPRC: 0.9853\n",
      "\n",
      "[Fold 3] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3381\n",
      "验证准确率: 0.9159, 精确率: 0.9595, 召回率: 0.8685, F1: 0.9117, MCC: 0.8356\n",
      "敏感性(SN): 0.8685, 特异性(SP): 0.9633, AUC: 0.9798, AUPRC: 0.9792\n",
      "\n",
      "[Fold 3] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3212\n",
      "验证准确率: 0.9343, 精确率: 0.9494, 召回率: 0.9174, F1: 0.9331, MCC: 0.8690\n",
      "敏感性(SN): 0.9174, 特异性(SP): 0.9511, AUC: 0.9838, AUPRC: 0.9848\n",
      "\n",
      "[Fold 3] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3075\n",
      "验证准确率: 0.9297, 精确率: 0.9323, 召回率: 0.9266, F1: 0.9294, MCC: 0.8593\n",
      "敏感性(SN): 0.9266, 特异性(SP): 0.9327, AUC: 0.9821, AUPRC: 0.9821\n",
      "\n",
      "[Fold 3] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3073\n",
      "验证准确率: 0.9343, 精确率: 0.9465, 召回率: 0.9205, F1: 0.9333, MCC: 0.8688\n",
      "敏感性(SN): 0.9205, 特异性(SP): 0.9480, AUC: 0.9830, AUPRC: 0.9816\n",
      "[Fold 3] 最佳准确率: 0.9373\n",
      "\n",
      "========== Fold 4/10 ==========\n",
      "\n",
      "[Fold 4] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.5812\n",
      "验证准确率: 0.9419, 精确率: 0.9164, 召回率: 0.9725, F1: 0.9436, MCC: 0.8854\n",
      "敏感性(SN): 0.9725, 特异性(SP): 0.9113, AUC: 0.9821, AUPRC: 0.9787\n",
      "Fold 4 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 4] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3806\n",
      "验证准确率: 0.9205, 精确率: 0.8747, 召回率: 0.9817, F1: 0.9251, MCC: 0.8473\n",
      "敏感性(SN): 0.9817, 特异性(SP): 0.8593, AUC: 0.9844, AUPRC: 0.9801\n",
      "\n",
      "[Fold 4] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3636\n",
      "验证准确率: 0.9404, 精确率: 0.9500, 召回率: 0.9297, F1: 0.9397, MCC: 0.8809\n",
      "敏感性(SN): 0.9297, 特异性(SP): 0.9511, AUC: 0.9842, AUPRC: 0.9793\n",
      "\n",
      "[Fold 4] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3449\n",
      "验证准确率: 0.9404, 精确率: 0.9286, 召回率: 0.9541, F1: 0.9412, MCC: 0.8811\n",
      "敏感性(SN): 0.9541, 特异性(SP): 0.9266, AUC: 0.9844, AUPRC: 0.9814\n",
      "\n",
      "[Fold 4] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3446\n",
      "验证准确率: 0.9434, 精确率: 0.9265, 召回率: 0.9633, F1: 0.9445, MCC: 0.8876\n",
      "敏感性(SN): 0.9633, 特异性(SP): 0.9235, AUC: 0.9832, AUPRC: 0.9793\n",
      "Fold 4 第 5 轮的最佳模型已保存\n",
      "\n",
      "[Fold 4] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3329\n",
      "验证准确率: 0.9404, 精确率: 0.9311, 召回率: 0.9511, F1: 0.9410, MCC: 0.8809\n",
      "敏感性(SN): 0.9511, 特异性(SP): 0.9297, AUC: 0.9837, AUPRC: 0.9814\n",
      "\n",
      "[Fold 4] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3304\n",
      "验证准确率: 0.9266, 精确率: 0.9401, 召回率: 0.9113, F1: 0.9255, MCC: 0.8536\n",
      "敏感性(SN): 0.9113, 特异性(SP): 0.9419, AUC: 0.9778, AUPRC: 0.9736\n",
      "\n",
      "[Fold 4] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3171\n",
      "验证准确率: 0.9312, 精确率: 0.9462, 召回率: 0.9144, F1: 0.9300, MCC: 0.8629\n",
      "敏感性(SN): 0.9144, 特异性(SP): 0.9480, AUC: 0.9778, AUPRC: 0.9725\n",
      "\n",
      "[Fold 4] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3050\n",
      "验证准确率: 0.9266, 精确率: 0.9401, 召回率: 0.9113, F1: 0.9255, MCC: 0.8536\n",
      "敏感性(SN): 0.9113, 特异性(SP): 0.9419, AUC: 0.9766, AUPRC: 0.9697\n",
      "\n",
      "[Fold 4] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3006\n",
      "验证准确率: 0.9128, 精确率: 0.8668, 召回率: 0.9755, F1: 0.9180, MCC: 0.8323\n",
      "敏感性(SN): 0.9755, 特异性(SP): 0.8502, AUC: 0.9759, AUPRC: 0.9704\n",
      "[Fold 4] 最佳准确率: 0.9434\n",
      "\n",
      "========== Fold 5/10 ==========\n",
      "\n",
      "[Fold 5] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.5659\n",
      "验证准确率: 0.9251, 精确率: 0.9162, 召回率: 0.9358, F1: 0.9259, MCC: 0.8503\n",
      "敏感性(SN): 0.9358, 特异性(SP): 0.9144, AUC: 0.9800, AUPRC: 0.9751\n",
      "Fold 5 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 5] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3716\n",
      "验证准确率: 0.9266, 精确率: 0.8997, 召回率: 0.9602, F1: 0.9290, MCC: 0.8551\n",
      "敏感性(SN): 0.9602, 特异性(SP): 0.8930, AUC: 0.9813, AUPRC: 0.9779\n",
      "Fold 5 第 2 轮的最佳模型已保存\n",
      "\n",
      "[Fold 5] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3626\n",
      "验证准确率: 0.9205, 精确率: 0.8873, 召回率: 0.9633, F1: 0.9238, MCC: 0.8441\n",
      "敏感性(SN): 0.9633, 特异性(SP): 0.8777, AUC: 0.9802, AUPRC: 0.9761\n",
      "\n",
      "[Fold 5] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3556\n",
      "验证准确率: 0.9343, 精确率: 0.9034, 召回率: 0.9725, F1: 0.9367, MCC: 0.8711\n",
      "敏感性(SN): 0.9725, 特异性(SP): 0.8960, AUC: 0.9822, AUPRC: 0.9772\n",
      "Fold 5 第 4 轮的最佳模型已保存\n",
      "\n",
      "[Fold 5] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3380\n",
      "验证准确率: 0.9220, 精确率: 0.8898, 召回率: 0.9633, F1: 0.9251, MCC: 0.8469\n",
      "敏感性(SN): 0.9633, 特异性(SP): 0.8807, AUC: 0.9745, AUPRC: 0.9660\n",
      "\n",
      "[Fold 5] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3381\n",
      "验证准确率: 0.9404, 精确率: 0.9337, 召回率: 0.9480, F1: 0.9408, MCC: 0.8808\n",
      "敏感性(SN): 0.9480, 特异性(SP): 0.9327, AUC: 0.9838, AUPRC: 0.9816\n",
      "Fold 5 第 6 轮的最佳模型已保存\n",
      "\n",
      "[Fold 5] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3227\n",
      "验证准确率: 0.9144, 精确率: 0.8774, 召回率: 0.9633, F1: 0.9184, MCC: 0.8327\n",
      "敏感性(SN): 0.9633, 特异性(SP): 0.8654, AUC: 0.9790, AUPRC: 0.9707\n",
      "\n",
      "[Fold 5] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3131\n",
      "验证准确率: 0.9358, 精确率: 0.9204, 召回率: 0.9541, F1: 0.9369, MCC: 0.8721\n",
      "敏感性(SN): 0.9541, 特异性(SP): 0.9174, AUC: 0.9810, AUPRC: 0.9768\n",
      "\n",
      "[Fold 5] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3076\n",
      "验证准确率: 0.9358, 精确率: 0.9204, 召回率: 0.9541, F1: 0.9369, MCC: 0.8721\n",
      "敏感性(SN): 0.9541, 特异性(SP): 0.9174, AUC: 0.9842, AUPRC: 0.9814\n",
      "\n",
      "[Fold 5] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.2993\n",
      "验证准确率: 0.9281, 精确率: 0.9142, 召回率: 0.9450, F1: 0.9293, MCC: 0.8568\n",
      "敏感性(SN): 0.9450, 特异性(SP): 0.9113, AUC: 0.9815, AUPRC: 0.9791\n",
      "[Fold 5] 最佳准确率: 0.9404\n",
      "\n",
      "========== Fold 6/10 ==========\n",
      "\n",
      "[Fold 6] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.6475\n",
      "验证准确率: 0.9404, 精确率: 0.9586, 召回率: 0.9205, F1: 0.9392, MCC: 0.8814\n",
      "敏感性(SN): 0.9205, 特异性(SP): 0.9602, AUC: 0.9854, AUPRC: 0.9848\n",
      "Fold 6 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 6] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3829\n",
      "验证准确率: 0.9343, 精确率: 0.9201, 召回率: 0.9511, F1: 0.9353, MCC: 0.8690\n",
      "敏感性(SN): 0.9511, 特异性(SP): 0.9174, AUC: 0.9868, AUPRC: 0.9867\n",
      "\n",
      "[Fold 6] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3668\n",
      "验证准确率: 0.9373, 精确率: 0.9256, 召回率: 0.9511, F1: 0.9382, MCC: 0.8749\n",
      "敏感性(SN): 0.9511, 特异性(SP): 0.9235, AUC: 0.9868, AUPRC: 0.9863\n",
      "\n",
      "[Fold 6] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3562\n",
      "验证准确率: 0.9358, 精确率: 0.9495, 召回率: 0.9205, F1: 0.9348, MCC: 0.8720\n",
      "敏感性(SN): 0.9205, 特异性(SP): 0.9511, AUC: 0.9861, AUPRC: 0.9853\n",
      "\n",
      "[Fold 6] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3476\n",
      "验证准确率: 0.9450, 精确率: 0.9533, 召回率: 0.9358, F1: 0.9444, MCC: 0.8901\n",
      "敏感性(SN): 0.9358, 特异性(SP): 0.9541, AUC: 0.9885, AUPRC: 0.9884\n",
      "Fold 6 第 5 轮的最佳模型已保存\n",
      "\n",
      "[Fold 6] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3394\n",
      "验证准确率: 0.9312, 精确率: 0.9462, 召回率: 0.9144, F1: 0.9300, MCC: 0.8629\n",
      "敏感性(SN): 0.9144, 特异性(SP): 0.9480, AUC: 0.9861, AUPRC: 0.9857\n",
      "\n",
      "[Fold 6] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3310\n",
      "验证准确率: 0.9312, 精确率: 0.9548, 召回率: 0.9052, F1: 0.9294, MCC: 0.8636\n",
      "敏感性(SN): 0.9052, 特异性(SP): 0.9572, AUC: 0.9854, AUPRC: 0.9857\n",
      "\n",
      "[Fold 6] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3275\n",
      "验证准确率: 0.9434, 精确率: 0.9448, 召回率: 0.9419, F1: 0.9433, MCC: 0.8869\n",
      "敏感性(SN): 0.9419, 特异性(SP): 0.9450, AUC: 0.9827, AUPRC: 0.9823\n",
      "\n",
      "[Fold 6] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3171\n",
      "验证准确率: 0.9358, 精确率: 0.9582, 召回率: 0.9113, F1: 0.9342, MCC: 0.8726\n",
      "敏感性(SN): 0.9113, 特异性(SP): 0.9602, AUC: 0.9840, AUPRC: 0.9831\n",
      "\n",
      "[Fold 6] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3175\n",
      "验证准确率: 0.9388, 精确率: 0.9498, 召回率: 0.9266, F1: 0.9381, MCC: 0.8779\n",
      "敏感性(SN): 0.9266, 特异性(SP): 0.9511, AUC: 0.9849, AUPRC: 0.9856\n",
      "[Fold 6] 最佳准确率: 0.9450\n",
      "\n",
      "========== Fold 7/10 ==========\n",
      "\n",
      "[Fold 7] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.5406\n",
      "验证准确率: 0.9312, 精确率: 0.9029, 召回率: 0.9664, F1: 0.9335, MCC: 0.8645\n",
      "敏感性(SN): 0.9664, 特异性(SP): 0.8960, AUC: 0.9790, AUPRC: 0.9749\n",
      "Fold 7 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 7] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3863\n",
      "验证准确率: 0.9281, 精确率: 0.9046, 召回率: 0.9572, F1: 0.9302, MCC: 0.8577\n",
      "敏感性(SN): 0.9572, 特异性(SP): 0.8991, AUC: 0.9806, AUPRC: 0.9796\n",
      "\n",
      "[Fold 7] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3604\n",
      "验证准确率: 0.9220, 精确率: 0.9233, 召回率: 0.9205, F1: 0.9219, MCC: 0.8440\n",
      "敏感性(SN): 0.9205, 特异性(SP): 0.9235, AUC: 0.9798, AUPRC: 0.9764\n",
      "\n",
      "[Fold 7] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3554\n",
      "验证准确率: 0.9281, 精确率: 0.9242, 召回率: 0.9327, F1: 0.9285, MCC: 0.8563\n",
      "敏感性(SN): 0.9327, 特异性(SP): 0.9235, AUC: 0.9811, AUPRC: 0.9787\n",
      "\n",
      "[Fold 7] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3493\n",
      "验证准确率: 0.9388, 精确率: 0.9335, 召回率: 0.9450, F1: 0.9392, MCC: 0.8777\n",
      "敏感性(SN): 0.9450, 特异性(SP): 0.9327, AUC: 0.9796, AUPRC: 0.9749\n",
      "Fold 7 第 5 轮的最佳模型已保存\n",
      "\n",
      "[Fold 7] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3330\n",
      "验证准确率: 0.9281, 精确率: 0.9000, 召回率: 0.9633, F1: 0.9306, MCC: 0.8584\n",
      "敏感性(SN): 0.9633, 特异性(SP): 0.8930, AUC: 0.9805, AUPRC: 0.9783\n",
      "\n",
      "[Fold 7] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3320\n",
      "验证准确率: 0.9358, 精确率: 0.9412, 召回率: 0.9297, F1: 0.9354, MCC: 0.8716\n",
      "敏感性(SN): 0.9297, 特异性(SP): 0.9419, AUC: 0.9801, AUPRC: 0.9770\n",
      "\n",
      "[Fold 7] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3171\n",
      "验证准确率: 0.9144, 精确率: 0.9625, 召回率: 0.8624, F1: 0.9097, MCC: 0.8333\n",
      "敏感性(SN): 0.8624, 特异性(SP): 0.9664, AUC: 0.9808, AUPRC: 0.9729\n",
      "\n",
      "[Fold 7] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3141\n",
      "验证准确率: 0.9358, 精确率: 0.9130, 召回率: 0.9633, F1: 0.9375, MCC: 0.8729\n",
      "敏感性(SN): 0.9633, 特异性(SP): 0.9083, AUC: 0.9795, AUPRC: 0.9716\n",
      "\n",
      "[Fold 7] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.2964\n",
      "验证准确率: 0.9312, 精确率: 0.9147, 召回率: 0.9511, F1: 0.9325, MCC: 0.8631\n",
      "敏感性(SN): 0.9511, 特异性(SP): 0.9113, AUC: 0.9731, AUPRC: 0.9595\n",
      "[Fold 7] 最佳准确率: 0.9388\n",
      "\n",
      "========== Fold 8/10 ==========\n",
      "\n",
      "[Fold 8] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.5265\n",
      "验证准确率: 0.9281, 精确率: 0.8977, 召回率: 0.9664, F1: 0.9308, MCC: 0.8588\n",
      "敏感性(SN): 0.9664, 特异性(SP): 0.8899, AUC: 0.9798, AUPRC: 0.9784\n",
      "Fold 8 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 8] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3893\n",
      "验证准确率: 0.9297, 精确率: 0.9194, 召回率: 0.9419, F1: 0.9305, MCC: 0.8596\n",
      "敏感性(SN): 0.9419, 特异性(SP): 0.9174, AUC: 0.9829, AUPRC: 0.9817\n",
      "Fold 8 第 2 轮的最佳模型已保存\n",
      "\n",
      "[Fold 8] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3647\n",
      "验证准确率: 0.9358, 精确率: 0.9467, 召回率: 0.9235, F1: 0.9350, MCC: 0.8718\n",
      "敏感性(SN): 0.9235, 特异性(SP): 0.9480, AUC: 0.9826, AUPRC: 0.9817\n",
      "Fold 8 第 3 轮的最佳模型已保存\n",
      "\n",
      "[Fold 8] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3612\n",
      "验证准确率: 0.9312, 精确率: 0.8939, 召回率: 0.9786, F1: 0.9343, MCC: 0.8663\n",
      "敏感性(SN): 0.9786, 特异性(SP): 0.8838, AUC: 0.9815, AUPRC: 0.9764\n",
      "\n",
      "[Fold 8] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3441\n",
      "验证准确率: 0.9388, 精确率: 0.9159, 召回率: 0.9664, F1: 0.9405, MCC: 0.8790\n",
      "敏感性(SN): 0.9664, 特异性(SP): 0.9113, AUC: 0.9823, AUPRC: 0.9763\n",
      "Fold 8 第 5 轮的最佳模型已保存\n",
      "\n",
      "[Fold 8] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3541\n",
      "验证准确率: 0.9404, 精确率: 0.9186, 召回率: 0.9664, F1: 0.9419, MCC: 0.8819\n",
      "敏感性(SN): 0.9664, 特异性(SP): 0.9144, AUC: 0.9854, AUPRC: 0.9837\n",
      "Fold 8 第 6 轮的最佳模型已保存\n",
      "\n",
      "[Fold 8] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3265\n",
      "验证准确率: 0.9358, 精确率: 0.8969, 召回率: 0.9847, F1: 0.9388, MCC: 0.8758\n",
      "敏感性(SN): 0.9847, 特异性(SP): 0.8869, AUC: 0.9859, AUPRC: 0.9848\n",
      "\n",
      "[Fold 8] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3273\n",
      "验证准确率: 0.8930, 精确率: 0.9707, 召回率: 0.8104, F1: 0.8833, MCC: 0.7969\n",
      "敏感性(SN): 0.8104, 特异性(SP): 0.9755, AUC: 0.9847, AUPRC: 0.9838\n",
      "\n",
      "[Fold 8] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3130\n",
      "验证准确率: 0.9235, 精确率: 0.8946, 召回率: 0.9602, F1: 0.9263, MCC: 0.8494\n",
      "敏感性(SN): 0.9602, 特异性(SP): 0.8869, AUC: 0.9767, AUPRC: 0.9745\n",
      "\n",
      "[Fold 8] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3110\n",
      "验证准确率: 0.9220, 精确率: 0.8988, 召回率: 0.9511, F1: 0.9242, MCC: 0.8455\n",
      "敏感性(SN): 0.9511, 特异性(SP): 0.8930, AUC: 0.9763, AUPRC: 0.9706\n",
      "[Fold 8] 最佳准确率: 0.9404\n",
      "\n",
      "========== Fold 9/10 ==========\n",
      "\n",
      "[Fold 9] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.6587\n",
      "验证准确率: 0.9159, 精确率: 0.8820, 召回率: 0.9602, F1: 0.9195, MCC: 0.8351\n",
      "敏感性(SN): 0.9602, 特异性(SP): 0.8716, AUC: 0.9715, AUPRC: 0.9647\n",
      "Fold 9 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 9] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3730\n",
      "验证准确率: 0.9052, 精确率: 0.8591, 召回率: 0.9694, F1: 0.9109, MCC: 0.8172\n",
      "敏感性(SN): 0.9694, 特异性(SP): 0.8410, AUC: 0.9748, AUPRC: 0.9657\n",
      "\n",
      "[Fold 9] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3776\n",
      "验证准确率: 0.9327, 精确率: 0.9224, 召回率: 0.9450, F1: 0.9335, MCC: 0.8657\n",
      "敏感性(SN): 0.9450, 特异性(SP): 0.9205, AUC: 0.9776, AUPRC: 0.9671\n",
      "Fold 9 第 3 轮的最佳模型已保存\n",
      "\n",
      "[Fold 9] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3428\n",
      "验证准确率: 0.9388, 精确率: 0.9470, 召回率: 0.9297, F1: 0.9383, MCC: 0.8778\n",
      "敏感性(SN): 0.9297, 特异性(SP): 0.9480, AUC: 0.9754, AUPRC: 0.9630\n",
      "Fold 9 第 4 轮的最佳模型已保存\n",
      "\n",
      "[Fold 9] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3419\n",
      "验证准确率: 0.9251, 精确率: 0.9399, 召回率: 0.9083, F1: 0.9238, MCC: 0.8506\n",
      "敏感性(SN): 0.9083, 特异性(SP): 0.9419, AUC: 0.9759, AUPRC: 0.9640\n",
      "\n",
      "[Fold 9] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3293\n",
      "验证准确率: 0.9343, 精确率: 0.9303, 召回率: 0.9388, F1: 0.9346, MCC: 0.8685\n",
      "敏感性(SN): 0.9388, 特异性(SP): 0.9297, AUC: 0.9760, AUPRC: 0.9720\n",
      "\n",
      "[Fold 9] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3313\n",
      "验证准确率: 0.9343, 精确率: 0.9522, 召回率: 0.9144, F1: 0.9329, MCC: 0.8692\n",
      "敏感性(SN): 0.9144, 特异性(SP): 0.9541, AUC: 0.9764, AUPRC: 0.9611\n",
      "\n",
      "[Fold 9] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3145\n",
      "验证准确率: 0.9343, 精确率: 0.9551, 召回率: 0.9113, F1: 0.9327, MCC: 0.8694\n",
      "敏感性(SN): 0.9113, 特异性(SP): 0.9572, AUC: 0.9770, AUPRC: 0.9701\n",
      "\n",
      "[Fold 9] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3149\n",
      "验证准确率: 0.9174, 精确率: 0.8845, 召回率: 0.9602, F1: 0.9208, MCC: 0.8379\n",
      "敏感性(SN): 0.9602, 特异性(SP): 0.8746, AUC: 0.9751, AUPRC: 0.9644\n",
      "\n",
      "[Fold 9] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3095\n",
      "验证准确率: 0.9128, 精确率: 0.9623, 召回率: 0.8593, F1: 0.9079, MCC: 0.8305\n",
      "敏感性(SN): 0.8593, 特异性(SP): 0.9664, AUC: 0.9755, AUPRC: 0.9671\n",
      "[Fold 9] 最佳准确率: 0.9388\n",
      "\n",
      "========== Fold 10/10 ==========\n",
      "\n",
      "[Fold 10] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.5349\n",
      "验证准确率: 0.9251, 精确率: 0.9427, 召回率: 0.9052, F1: 0.9236, MCC: 0.8508\n",
      "敏感性(SN): 0.9052, 特异性(SP): 0.9450, AUC: 0.9797, AUPRC: 0.9790\n",
      "Fold 10 第 1 轮的最佳模型已保存\n",
      "\n",
      "[Fold 10] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3829\n",
      "验证准确率: 0.9297, 精确率: 0.9297, 召回率: 0.9297, F1: 0.9297, MCC: 0.8593\n",
      "敏感性(SN): 0.9297, 特异性(SP): 0.9297, AUC: 0.9822, AUPRC: 0.9825\n",
      "Fold 10 第 2 轮的最佳模型已保存\n",
      "\n",
      "[Fold 10] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3651\n",
      "验证准确率: 0.9235, 精确率: 0.9086, 召回率: 0.9419, F1: 0.9249, MCC: 0.8477\n",
      "敏感性(SN): 0.9419, 特异性(SP): 0.9052, AUC: 0.9818, AUPRC: 0.9822\n",
      "\n",
      "[Fold 10] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3534\n",
      "验证准确率: 0.9205, 精确率: 0.9393, 召回率: 0.8991, F1: 0.9187, MCC: 0.8418\n",
      "敏感性(SN): 0.8991, 特异性(SP): 0.9419, AUC: 0.9823, AUPRC: 0.9826\n",
      "\n",
      "[Fold 10] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3394\n",
      "验证准确率: 0.9312, 精确率: 0.9075, 召回率: 0.9602, F1: 0.9331, MCC: 0.8638\n",
      "敏感性(SN): 0.9602, 特异性(SP): 0.9021, AUC: 0.9817, AUPRC: 0.9816\n",
      "Fold 10 第 5 轮的最佳模型已保存\n",
      "\n",
      "[Fold 10] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3361\n",
      "验证准确率: 0.9190, 精确率: 0.8870, 召回率: 0.9602, F1: 0.9222, MCC: 0.8408\n",
      "敏感性(SN): 0.9602, 特异性(SP): 0.8777, AUC: 0.9823, AUPRC: 0.9829\n",
      "\n",
      "[Fold 10] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3184\n",
      "验证准确率: 0.9281, 精确率: 0.9321, 召回率: 0.9235, F1: 0.9278, MCC: 0.8563\n",
      "敏感性(SN): 0.9235, 特异性(SP): 0.9327, AUC: 0.9810, AUPRC: 0.9815\n",
      "\n",
      "[Fold 10] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3160\n",
      "验证准确率: 0.9174, 精确率: 0.9003, 召回率: 0.9388, F1: 0.9192, MCC: 0.8356\n",
      "敏感性(SN): 0.9388, 特异性(SP): 0.8960, AUC: 0.9783, AUPRC: 0.9768\n",
      "\n",
      "[Fold 10] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3104\n",
      "验证准确率: 0.9251, 精确率: 0.9137, 召回率: 0.9388, F1: 0.9261, MCC: 0.8505\n",
      "敏感性(SN): 0.9388, 特异性(SP): 0.9113, AUC: 0.9810, AUPRC: 0.9800\n",
      "\n",
      "[Fold 10] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 1.3063\n",
      "验证准确率: 0.9297, 精确率: 0.9271, 召回率: 0.9327, F1: 0.9299, MCC: 0.8593\n",
      "敏感性(SN): 0.9327, 特异性(SP): 0.9266, AUC: 0.9765, AUPRC: 0.9724\n",
      "[Fold 10] 最佳准确率: 0.9312\n",
      "\n",
      "========== 10折交叉验证结果汇总 ==========\n",
      "平均准确率: 0.9401 ± 0.0058\n",
      "平均精确率: 0.9264 ± 0.0282\n",
      "平均召回率: 0.9260 ± 0.0340\n",
      "平均F1分数: 0.9252 ± 0.0090\n",
      "平均MCC: 0.8523 ± 0.0149\n",
      "平均敏感性(SN): 0.9260 ± 0.0340\n",
      "平均特异性(SP): 0.9245 ± 0.0338\n",
      "平均AUC: 0.9786 ± 0.0037\n",
      "平均AUPRC: 0.9738 ± 0.0073\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 十折测试结果",
   "id": "89497dfa96a1f83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:38:22.872219Z",
     "start_time": "2025-07-09T10:30:46.923237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# 测试集\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    return acc, pre, rec, f1, mcc\n",
    "\n",
    "# 评估每一折\n",
    "all_metrics = []\n",
    "for fold in range(1, 11):\n",
    "    print(f\"\\n========== Test Fold {fold}/10 ==========\")\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(f\"/exp_data/sjx/star/main_transformer_moe_weight/cv_point/best_fold{fold}.pth\", map_location=device))\n",
    "    acc, pre, rec, f1, mcc = eval_model(model, test_loader, device)\n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    all_metrics.append((acc, pre, rec, f1, mcc))\n",
    "\n",
    "# 汇总平均\n",
    "all_metrics = np.array(all_metrics)\n",
    "print(\"\\n========== 10-Fold Test Results ==========\")\n",
    "print(f\"Mean ACC: {all_metrics[:,0].mean():.4f} ± {all_metrics[:,0].std():.4f}\")\n",
    "print(f\"Mean PRE: {all_metrics[:,1].mean():.4f}\")\n",
    "print(f\"Mean REC: {all_metrics[:,2].mean():.4f}\")\n",
    "print(f\"Mean F1:  {all_metrics[:,3].mean():.4f}\")\n",
    "print(f\"Mean MCC: {all_metrics[:,4].mean():.4f}\")"
   ],
   "id": "5d6b965da9085033",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 更多指标得测试",
   "id": "1eb067946eff7a17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:40:44.635943Z",
     "start_time": "2025-07-20T05:40:20.827228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设模型结构和ProteinNPYDataset已定义，device已设置\n",
    "import torch\n",
    "\n",
    "# 1. 加载模型\n",
    "model = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2. 加载测试集\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 3. 定义评估函数\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # 正类概率\n",
    "    \n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "        confusion_matrix, roc_auc_score, average_precision_score\n",
    "    )\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # 计算所有指标\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # 敏感性\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # 特异性\n",
    "    \n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}, AUPRC: {auprc:.4f}, SN: {sn:.4f}, SP: {sp:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc, auc, auprc, sn, sp\n",
    "\n",
    "# 4. 测试\n",
    "eval_model(model, test_loader, device)"
   ],
   "id": "3037e3e21d7ecd47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/1171368709.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
      "Test AUC: 0.9685, AUPRC: 0.9869, SN: 0.9425, SP: 0.8731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9225413402959095,\n",
       " 0.948339483394834,\n",
       " 0.9425427872860636,\n",
       " 0.9454322501532803,\n",
       " 0.8120485793877618,\n",
       " 0.9685438657398856,\n",
       " 0.9869455888266454,\n",
       " 0.9425427872860636,\n",
       " 0.8731117824773413)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
