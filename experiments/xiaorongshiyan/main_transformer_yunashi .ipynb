{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T05:06:51.110932Z",
     "start_time": "2025-07-23T05:06:51.102923Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)  # ä½ å¯ä»¥æ¢æˆå…¶å®ƒæ•°å­—\n",
    "# æ•°æ®é›†ç±»\n",
    "class ProteinNPYDataset(Dataset):\n",
    "    def __init__(self, pos_path, neg_path):\n",
    "        self.pos = np.load(pos_path, mmap_mode='r')\n",
    "        self.neg = np.load(neg_path, mmap_mode='r')\n",
    "        self.lengths = [len(self.pos), len(self.neg)]\n",
    "        self.total_len = self.lengths[0] + self.lengths[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.lengths[0]:\n",
    "            x = self.pos[idx]\n",
    "            y = 1\n",
    "        else:\n",
    "            x = self.neg[idx - self.lengths[0]]\n",
    "            y = 0\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "fc31fd06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.619737Z",
     "start_time": "2025-07-23T04:32:33.594914Z"
    }
   },
   "source": [
    "class MLPExperts(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.fc1 = nn.Linear(d_model, d_ff * num_experts, bias=True)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model, bias=True)\n",
    "        self.d_ff = d_ff\n",
    "    def forward(self, x, expert_idx):\n",
    "        # x: [B*L, d_model], expert_idx: [B*L, k]\n",
    "        all_hidden = self.fc1(x)  # [B*L, d_ff * num_experts]\n",
    "        all_hidden = all_hidden.view(x.size(0), self.num_experts, self.d_ff)  # [B*L, num_experts, d_ff]\n",
    "        out = []\n",
    "        for i in range(expert_idx.size(1)):\n",
    "            idx = expert_idx[:, i]  # [B*L]\n",
    "            hidden = all_hidden[torch.arange(x.size(0)), idx]  # [B*L, d_ff]\n",
    "            hidden = F.gelu(hidden)\n",
    "            out_i = self.fc2(hidden)  # [B*L, d_model]\n",
    "            out.append(out_i)\n",
    "        out = torch.stack(out, dim=1)  # [B*L, k, d_model]\n",
    "        return out\n",
    "class NoisyTopKMoE(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts=30, k=2, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.k = k\n",
    "        self.noisy_std = noisy_std\n",
    "        self.experts = MLPExperts(d_model, d_ff, num_experts)\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, d_model]\n",
    "        B, L, D = x.shape\n",
    "        x_flat = x.reshape(-1, D)  # [B*L, D]\n",
    "        gate_logits = self.gate(x_flat)  # [B*L, num_experts]\n",
    "        # Noisy gating\n",
    "        if self.training and self.noisy_std > 0:\n",
    "            noise = torch.randn_like(gate_logits) * self.noisy_std\n",
    "            gate_logits = gate_logits + noise\n",
    "        gate_scores = F.softmax(gate_logits, dim=-1)  # [B*L, num_experts]\n",
    "\n",
    "          # ç¨€ç–è·¯ç”±ï¼šåªé€‰top-k\n",
    "        topk_val, topk_idx = torch.topk(gate_scores, self.k, dim=-1)  # [B*L, k]\n",
    "        # è´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆæ–°ç‰ˆï¼Œé˜²æ­¢çˆ†ç‚¸ï¼‰\n",
    "        meangate = gate_scores.mean(dim=0)  # [num_experts]\n",
    "        load_balance_loss = (meangate * meangate).sum() * (self.num_experts ** 2)\n",
    "        # ä¸“å®¶å¹¶è¡Œè¾“å‡º\n",
    "        expert_outs = self.experts(x_flat, topk_idx)  # [B*L, k, d_model]\n",
    "        topk_val = topk_val / (topk_val.sum(dim=-1, keepdim=True) + 1e-9)\n",
    "        moe_out = (expert_outs * topk_val.unsqueeze(-1)).sum(dim=1)  # [B*L, d_model]\n",
    "        moe_out = moe_out.view(B, L, D)\n",
    "        return moe_out, load_balance_loss"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "21ee1baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.693276Z",
     "start_time": "2025-07-23T04:32:33.685629Z"
    }
   },
   "source": [
    "class TransformerMoEBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, num_experts=30, k=3, dropout=0.1, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.moe = NoisyTopKMoE(d_model, d_ff, num_experts, k, noisy_std)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        moe_out, load_balance_loss = self.moe(x)\n",
    "        x = x + self.dropout(moe_out)\n",
    "        x = self.norm2(x)\n",
    "        return x, load_balance_loss\n",
    "\n",
    "class TransformerMoE(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerMoEBlock(d_model, nhead, d_ff, num_experts, k, dropout, noisy_std)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        total_load_balance_loss = 0\n",
    "        for layer in self.layers:\n",
    "            x, lb_loss = layer(x)\n",
    "            total_load_balance_loss += lb_loss\n",
    "        x = x.mean(dim=1)  # æ± åŒ–\n",
    "        logits = self.classifier(x)\n",
    "        return logits, total_load_balance_loss"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a0b85430a6d3b6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### æ™®é€štransformer",
   "id": "f9b49e542d7deab4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.732983Z",
     "start_time": "2025-07-23T04:32:33.724555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(F.gelu(self.fc1(x))))\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # âœ… å®Œå…¨ç§»é™¤ä½ç½®ç¼–ç \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # âœ… ç›´æ¥å¤„ç†è¾“å…¥ï¼Œä¸æ·»åŠ ä½ç½®ç¼–ç \n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + self.dropout(ffn_out)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return x, 0.0\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, d_ff=2048, num_layers=4, dropout=0.1, num_classes=2):\n",
    "        super().__init__()\n",
    "        # âœ… ä¸ä½¿ç”¨ä½ç½®ç¼–ç ï¼Œä¸TransformerMoEä¿æŒä¸€è‡´\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, nhead, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        total_load_balance_loss = 0.0\n",
    "        for layer in self.layers:\n",
    "            x, _ = layer(x)\n",
    "        x = x.mean(dim=1)  # å…¨å±€å¹³å‡æ± åŒ–\n",
    "        logits = self.classifier(x)\n",
    "        return logits, total_load_balance_loss"
   ],
   "id": "ff172b9123c9d21c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.764158Z",
     "start_time": "2025-07-23T04:32:33.755317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # æ­£ç±»æ¦‚ç‡\n",
    "    \n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "        confusion_matrix, roc_auc_score, average_precision_score\n",
    "    )\n",
    "    \n",
    "    # è®¡ç®—æ··æ·†çŸ©é˜µ\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # æ•æ„Ÿæ€§\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # ç‰¹å¼‚æ€§\n",
    "    \n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}, AUPRC: {auprc:.4f}, SN: {sn:.4f}, SP: {sp:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc, auc, auprc, sn, sp\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, moe_loss_weight=0.01, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():  # å¼€å¯æ··åˆç²¾åº¦\n",
    "            logits, lb_loss = model(x)\n",
    "            loss = criterion(logits, y) + moe_loss_weight * lb_loss\n",
    "        scaler.scale(loss).backward()      # ç”¨scalerç¼©æ”¾lossåå‘ä¼ æ’­\n",
    "        scaler.step(optimizer)             # ç”¨scaler.stepæ›´æ–°å‚æ•°\n",
    "        scaler.update()                    # æ›´æ–°scalerçŠ¶æ€\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "id": "e1476e5594aa401d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:32:33.823037Z",
     "start_time": "2025-07-23T04:32:33.819857Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "92bbb75e5fe3ac2f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "dff51c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:34:29.460045Z",
     "start_time": "2025-07-23T04:32:35.080689Z"
    }
   },
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# æ•°æ®è·¯å¾„\n",
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "\n",
    "train_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4,dropout=0.1,num_classes=2\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = GradScaler()  # åœ¨è®­ç»ƒå‰åˆå§‹åŒ–\n",
    "\n",
    "\n",
    "def train_one_epoch_putong(model, loader, optimizer, criterion, device, moe_loss_weight=0.01, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            logits, lb_loss = model(x)\n",
    "            # âŒ æ™®é€šTransformerçš„lb_loss=0.0ï¼Œè¿™é‡Œåº”è¯¥è®¾ä¸º0\n",
    "            loss = criterion(logits, y)  \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "# åˆå§‹åŒ–scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# è®­ç»ƒä¸»å¾ªç¯\n",
    "epochs = 10\n",
    "best_acc = 0\n",
    "best_state = None\n",
    "best_path = \"/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_best.pth\"\n",
    "last_path = \"/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train_one_epoch_putong(model, train_loader, optimizer, criterion, device, scaler=scaler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    # ä¿å­˜æœ€åä¸€æ¬¡æ¨¡å‹æƒé‡\n",
    "    torch.save(model.state_dict(), last_path)\n",
    "    print(f\"Last model saved at epoch {epoch+1} ({last_path})\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/3699395688.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # åœ¨è®­ç»ƒå‰åˆå§‹åŒ–\n",
      "/tmp/ipykernel_3474920/3699395688.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3699395688.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3351\n",
      "Last model saved at epoch 1 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1839\n",
      "Last model saved at epoch 2 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1823\n",
      "Last model saved at epoch 3 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1536\n",
      "Last model saved at epoch 4 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1451\n",
      "Last model saved at epoch 5 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1527\n",
      "Last model saved at epoch 6 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1298\n",
      "Last model saved at epoch 7 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1249\n",
      "Last model saved at epoch 8 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1106\n",
      "Last model saved at epoch 9 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0936\n",
      "Last model saved at epoch 10 (/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "897d1af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:34:32.852595Z",
     "start_time": "2025-07-23T04:34:29.461842Z"
    }
   },
   "source": [
    "# 1. åŠ è½½æ¨¡å‹\n",
    "model = Transformer(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4,dropout=0.1,num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # æ­£ç±»æ¦‚ç‡\n",
    "    \n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "        confusion_matrix, roc_auc_score, average_precision_score\n",
    "    )\n",
    "    \n",
    "    # è®¡ç®—æ··æ·†çŸ©é˜µ\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # æ•æ„Ÿæ€§\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # ç‰¹å¼‚æ€§\n",
    "    \n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}, AUPRC: {auprc:.4f}, SN: {sn:.4f}, SP: {sp:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc, auc, auprc, sn, sp\n",
    "\n",
    "\n",
    "# æµ‹è¯•\n",
    "eval_model(model, test_loader, device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/3351279906.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9112, PRE: 0.9242, REC: 0.9535, F1: 0.9386, MCC: 0.7796\n",
      "Test AUC: 0.9664, AUPRC: 0.9862, SN: 0.9535, SP: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9112271540469974,\n",
       " 0.9241706161137441,\n",
       " 0.9535452322738386,\n",
       " 0.9386281588447654,\n",
       " 0.7796373962089861,\n",
       " 0.9663629514178713,\n",
       " 0.9862288602159184,\n",
       " 0.9535452322738386,\n",
       " 0.8066465256797583)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:06:51.100938Z",
     "start_time": "2025-07-23T05:05:00.330950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# é‡æ–°è®­ç»ƒæ™®é€šTransformer - ä¿®æ­£ç‰ˆæœ¬ï¼ˆä½¿ç”¨æœ€åè½®æƒé‡ï¼‰\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# æ•°æ®åŠ è½½\n",
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "\n",
    "train_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# åˆ›å»ºæ™®é€šTransformeræ¨¡å‹\n",
    "model = Transformer(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, dropout=0.1, num_classes=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "# ä¿®æ­£çš„è®­ç»ƒå‡½æ•°\n",
    "def train_one_epoch_transformer(model, loader, optimizer, criterion, device, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            logits, _ = model(x)  # æ™®é€šTransformerçš„lb_loss=0.0\n",
    "            loss = criterion(logits, y)  # âœ… åªä½¿ç”¨åˆ†ç±»æŸå¤±\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "print(\"=== é‡æ–°è®­ç»ƒæ™®é€šTransformer (æ¶ˆèå®éªŒbaseline) ===\")\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train_one_epoch_transformer(model, train_loader, optimizer, criterion, device, scaler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # âœ… ç§»é™¤æµ‹è¯•é›†éªŒè¯ï¼Œé¿å…è¿‡æ‹Ÿåˆ\n",
    "    # åªåœ¨è®­ç»ƒæœŸé—´æ‰“å°è®­ç»ƒæŸå¤±ï¼Œä¸åœ¨æµ‹è¯•é›†ä¸Šé€‰æ‹©æ¨¡å‹\n",
    "\n",
    "# âœ… ä¿å­˜æœ€åä¸€è½®è®­ç»ƒåçš„æ¨¡å‹æƒé‡\n",
    "save_path = \"/exp_data/sjx/star/experiments/xiaorongshiyan/transformer_baseline_final.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\nâœ… æ™®é€šTransformeræœ€ç»ˆæƒé‡ä¿å­˜è‡³: {save_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”¥ æ¶ˆèå®éªŒå¯¹æ¯”ç»“æœ\")\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š TransformerMoE (ä½ çš„SOTAæ–¹æ³•):\")\n",
    "print(\"   ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\")\n",
    "print(\"   AUC: 0.9685, AUPRC: 0.9869, SN: 0.9425, SP: 0.8731\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ™®é€šTransformer (è®­ç»ƒ15è½®åçš„æœ€ç»ˆæ¨¡å‹):\")\n",
    "# âœ… ä½¿ç”¨è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆæ¨¡å‹è¿›è¡Œæµ‹è¯•\n",
    "final_results = eval_model(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nğŸš€ MoEæ¶æ„å¸¦æ¥çš„æ€§èƒ½æå‡:\")\n",
    "f1_improvement = 0.9454 - final_results[3]\n",
    "mcc_improvement = 0.8120 - final_results[4]\n",
    "auc_improvement = 0.9685 - final_results[5]\n",
    "\n",
    "print(f\"   F1æå‡: +{f1_improvement:.4f} ({(f1_improvement/final_results[3]*100):.1f}%)\")\n",
    "print(f\"   MCCæå‡: +{mcc_improvement:.4f}\")\n",
    "print(f\"   AUCæå‡: +{auc_improvement:.4f}\")\n",
    "\n",
    "if f1_improvement > 0.02:\n",
    "    print(\"   âœ¨ MoEæ¶æ„æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½!\")\n",
    "elif f1_improvement > 0.005:\n",
    "    print(\"   ğŸ‘ MoEæ¶æ„æœ‰ä¸€å®šæ€§èƒ½æå‡\")\n",
    "else:\n",
    "    print(\"   ğŸ¤” MoEæ¶æ„æå‡æœ‰é™ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ å®éªŒè®¾ç½®è¯´æ˜:\")\n",
    "print(f\"   - æ™®é€šTransformer: è®­ç»ƒ{epochs}è½®ï¼Œä½¿ç”¨æœ€ç»ˆæƒé‡æµ‹è¯•\")\n",
    "print(f\"   - TransformerMoE: è®­ç»ƒ10è½®ï¼Œä½¿ç”¨æœ€ç»ˆæƒé‡æµ‹è¯•\")\n",
    "print(f\"   - ä¸¤è€…ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒæ•°æ®å’Œè¶…å‚æ•°\")\n",
    "print(f\"   - é¿å…åŸºäºæµ‹è¯•é›†é€‰æ‹©æ¨¡å‹ï¼Œç¡®ä¿å…¬å¹³å¯¹æ¯”\")"
   ],
   "id": "fd5ab8474f47d187",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1694275328.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== é‡æ–°è®­ç»ƒæ™®é€šTransformer (æ¶ˆèå®éªŒbaseline) ===\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/1694275328.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3558\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1823\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1662\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1516\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1483\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1452\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1369\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1247\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1181\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1033\n",
      "\n",
      "âœ… æ™®é€šTransformeræœ€ç»ˆæƒé‡ä¿å­˜è‡³: /exp_data/sjx/star/experiments/xiaorongshiyan/transformer_baseline_final.pth\n",
      "\n",
      "======================================================================\n",
      "ğŸ”¥ æ¶ˆèå®éªŒå¯¹æ¯”ç»“æœ\n",
      "======================================================================\n",
      "ğŸ“Š TransformerMoE (ä½ çš„SOTAæ–¹æ³•):\n",
      "   ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
      "   AUC: 0.9685, AUPRC: 0.9869, SN: 0.9425, SP: 0.8731\n",
      "\n",
      "ğŸ“ˆ æ™®é€šTransformer (è®­ç»ƒ15è½®åçš„æœ€ç»ˆæ¨¡å‹):\n",
      "Test ACC: 0.9199, PRE: 0.9211, REC: 0.9707, F1: 0.9452, MCC: 0.8005\n",
      "Test AUC: 0.9631, AUPRC: 0.9831, SN: 0.9707, SP: 0.7946\n",
      "\n",
      "ğŸš€ MoEæ¶æ„å¸¦æ¥çš„æ€§èƒ½æå‡:\n",
      "   F1æå‡: +0.0002 (0.0%)\n",
      "   MCCæå‡: +0.0115\n",
      "   AUCæå‡: +0.0054\n",
      "   ğŸ¤” MoEæ¶æ„æå‡æœ‰é™ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ\n",
      "\n",
      "ğŸ“‹ å®éªŒè®¾ç½®è¯´æ˜:\n",
      "   - æ™®é€šTransformer: è®­ç»ƒ10è½®ï¼Œä½¿ç”¨æœ€ç»ˆæƒé‡æµ‹è¯•\n",
      "   - TransformerMoE: è®­ç»ƒ10è½®ï¼Œä½¿ç”¨æœ€ç»ˆæƒé‡æµ‹è¯•\n",
      "   - ä¸¤è€…ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒæ•°æ®å’Œè¶…å‚æ•°\n",
      "   - é¿å…åŸºäºæµ‹è¯•é›†é€‰æ‹©æ¨¡å‹ï¼Œç¡®ä¿å…¬å¹³å¯¹æ¯”\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ä¸åŒå±‚æ•°",
   "id": "4dd7b3027ea8d728"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:54:03.622318Z",
     "start_time": "2025-07-23T04:34:32.853986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ•°æ®åŠ è½½\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "\n",
    "train_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# å®éªŒä¸åŒå±‚æ•°\n",
    "layer_configs = [1, 2, 3, 4]\n",
    "results = {}\n",
    "\n",
    "for num_layers in layer_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"è®­ç»ƒ {num_layers}å±‚ TransformerMoE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # åˆ›å»ºæ¨¡å‹\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, \n",
    "        nhead=8, \n",
    "        d_ff=2048, \n",
    "        num_layers=num_layers, \n",
    "        num_experts=30, \n",
    "        k=3, \n",
    "        dropout=0.1, \n",
    "        noisy_std=1.0, \n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "    \n",
    "    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    epochs = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, 0.01, scaler)\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # ä¿å­˜è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆæ¨¡å‹æƒé‡\n",
    "    save_path = f\"/exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_{num_layers}layer_final.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"\\n{num_layers}å±‚æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæƒé‡ä¿å­˜è‡³: {save_path}\")\n",
    "    \n",
    "    # æµ‹è¯•æœ€ç»ˆæ¨¡å‹æ€§èƒ½\n",
    "    print(f\"\\n{num_layers}å±‚TransformerMoEæœ€ç»ˆæµ‹è¯•ç»“æœ:\")\n",
    "    final_metrics = eval_model(model, test_loader, device)\n",
    "    results[num_layers] = {\n",
    "        'acc': final_metrics[0], 'pre': final_metrics[1], 'rec': final_metrics[2],\n",
    "        'f1': final_metrics[3], 'mcc': final_metrics[4], 'auc': final_metrics[5],\n",
    "        'auprc': final_metrics[6], 'sn': final_metrics[7], 'sp': final_metrics[8]\n",
    "    }\n",
    "\n",
    "# æ±‡æ€»æ‰€æœ‰ç»“æœ\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"æ‰€æœ‰å±‚æ•°TransformerMoEç»“æœæ±‡æ€»\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Layers':<8}{'ACC':<8}{'PRE':<8}{'REC':<8}{'F1':<8}{'MCC':<8}{'AUC':<8}{'AUPRC':<8}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "for layers in layer_configs:\n",
    "    r = results[layers]\n",
    "    print(f\"{layers:<8}{r['acc']:<8.4f}{r['pre']:<8.4f}{r['rec']:<8.4f}{r['f1']:<8.4f}{r['mcc']:<8.4f}{r['auc']:<8.4f}{r['auprc']:<8.4f}\")\n",
    "  \n"
   ],
   "id": "6068229d909d9a9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "è®­ç»ƒ 1å±‚ TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # å¼€å¯æ··åˆç²¾åº¦\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6056\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4693\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4554\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4467\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4434\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4344\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4238\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4130\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4137\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3933\n",
      "\n",
      "1å±‚æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæƒé‡ä¿å­˜è‡³: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_1layer_final.pth\n",
      "\n",
      "1å±‚TransformerMoEæœ€ç»ˆæµ‹è¯•ç»“æœ:\n",
      "Test ACC: 0.9051, PRE: 0.9297, REC: 0.9377, F1: 0.9337, MCC: 0.7673\n",
      "Test AUC: 0.9543, AUPRC: 0.9804, SN: 0.9377, SP: 0.8248\n",
      "\n",
      "==================================================\n",
      "è®­ç»ƒ 2å±‚ TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # å¼€å¯æ··åˆç²¾åº¦\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8998\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7754\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7541\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7466\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7405\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7311\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7093\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7040\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6904\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6726\n",
      "\n",
      "2å±‚æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæƒé‡ä¿å­˜è‡³: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_2layer_final.pth\n",
      "\n",
      "2å±‚TransformerMoEæœ€ç»ˆæµ‹è¯•ç»“æœ:\n",
      "Test ACC: 0.9034, PRE: 0.9645, REC: 0.8973, F1: 0.9297, MCC: 0.7811\n",
      "Test AUC: 0.9621, AUPRC: 0.9852, SN: 0.8973, SP: 0.9184\n",
      "\n",
      "==================================================\n",
      "è®­ç»ƒ 3å±‚ TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # å¼€å¯æ··åˆç²¾åº¦\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2840\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0787\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0686\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0517\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0491\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0400\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0369\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0193\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0160\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9982\n",
      "\n",
      "3å±‚æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæƒé‡ä¿å­˜è‡³: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_3layer_final.pth\n",
      "\n",
      "3å±‚TransformerMoEæœ€ç»ˆæµ‹è¯•ç»“æœ:\n",
      "Test ACC: 0.9182, PRE: 0.9458, REC: 0.9389, F1: 0.9423, MCC: 0.8017\n",
      "Test AUC: 0.9611, AUPRC: 0.9820, SN: 0.9389, SP: 0.8671\n",
      "\n",
      "==================================================\n",
      "è®­ç»ƒ 4å±‚ TransformerMoE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1005215202.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # å¼€å¯æ··åˆç²¾åº¦\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5557\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3823\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3616\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3555\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3458\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3378\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3211\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3190\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3105\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3073\n",
      "\n",
      "4å±‚æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæƒé‡ä¿å­˜è‡³: /exp_data/sjx/star/experiments/xiaorongshiyan/cegnshu/transformer_moe_4layer_final.pth\n",
      "\n",
      "4å±‚TransformerMoEæœ€ç»ˆæµ‹è¯•ç»“æœ:\n",
      "Test ACC: 0.9191, PRE: 0.9300, REC: 0.9584, F1: 0.9440, MCC: 0.7993\n",
      "Test AUC: 0.9329, AUPRC: 0.9480, SN: 0.9584, SP: 0.8218\n",
      "\n",
      "======================================================================\n",
      "æ‰€æœ‰å±‚æ•°TransformerMoEç»“æœæ±‡æ€»\n",
      "======================================================================\n",
      "Layers  ACC     PRE     REC     F1      MCC     AUC     AUPRC   \n",
      "----------------------------------------------------------------------\n",
      "1       0.9051  0.9297  0.9377  0.9337  0.7673  0.9543  0.9804  \n",
      "2       0.9034  0.9645  0.8973  0.9297  0.7811  0.9621  0.9852  \n",
      "3       0.9182  0.9458  0.9389  0.9423  0.8017  0.9611  0.9820  \n",
      "4       0.9191  0.9300  0.9584  0.9440  0.7993  0.9329  0.9480  \n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:41:07.510753Z",
     "start_time": "2025-07-23T06:32:45.773065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä¸¥æ ¼æ§åˆ¶éšæœºæ€§çš„è®­ç»ƒå¯¹æ¯”\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_deterministic_seed(seed=42):\n",
    "    \"\"\"è®¾ç½®æ›´ä¸¥æ ¼çš„ç¡®å®šæ€§ç§å­\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    # æ›´ä¸¥æ ¼çš„ç¡®å®šæ€§è®¾ç½®\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# é‡æ–°è®­ç»ƒ4å±‚æ¨¡å‹ï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„éšæœºæ§åˆ¶\n",
    "set_deterministic_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model_new = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, \n",
    "    num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "\n",
    "# ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒè®¾ç½®\n",
    "optimizer = torch.optim.AdamW(model_new.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"=== é‡æ–°è®­ç»ƒ4å±‚TransformerMoE (ä¸¥æ ¼éšæœºæ§åˆ¶) ===\")\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train_one_epoch(model_new, train_loader, optimizer, criterion, device, 0.01, scaler)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "# æµ‹è¯•æ–°è®­ç»ƒçš„æ¨¡å‹\n",
    "print(\"\\n=== æ–°è®­ç»ƒçš„4å±‚æ¨¡å‹æµ‹è¯•ç»“æœ ===\")\n",
    "new_results = eval_model(model_new, test_loader, device)\n",
    "\n",
    "# åŠ è½½ä½ çš„SOTAæ¨¡å‹è¿›è¡Œå¯¹æ¯”\n",
    "model_sota = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, \n",
    "    num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "model_sota.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n",
    "\n",
    "print(\"\\n=== SOTAæ¨¡å‹æµ‹è¯•ç»“æœ ===\")\n",
    "sota_results = eval_model(model_sota, test_loader, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ç»“æœå¯¹æ¯”åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"SOTAæ¨¡å‹ F1: {sota_results[3]:.4f}\")\n",
    "print(f\"æ–°è®­ç»ƒæ¨¡å‹ F1: {new_results[3]:.4f}\")\n",
    "print(f\"F1å·®å¼‚: {abs(sota_results[3] - new_results[3]):.4f}\")\n",
    "\n",
    "if abs(sota_results[3] - new_results[3]) < 0.01:\n",
    "    print(\"âœ… ç»“æœåŸºæœ¬ä¸€è‡´ï¼Œå·®å¼‚åœ¨åˆç†èŒƒå›´å†…\")\n",
    "elif abs(sota_results[3] - new_results[3]) < 0.02:\n",
    "    print(\"âš ï¸ æœ‰ä¸€å®šå·®å¼‚ï¼Œä½†ä»åœ¨å¯æ¥å—èŒƒå›´\")\n",
    "else:\n",
    "    print(\"â— å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨å…¶ä»–å› ç´ \")"
   ],
   "id": "25ff0aed7353db71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1809652477.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== é‡æ–°è®­ç»ƒ4å±‚TransformerMoE (ä¸¥æ ¼éšæœºæ§åˆ¶) ===\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/103 [00:00<?, ?it/s]/tmp/ipykernel_3474920/3515783599.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # å¼€å¯æ··åˆç²¾åº¦\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/functional.py:5501: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  proj = linear(q, w, b)\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/functional.py:6241: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  attn_output_weights = torch.bmm(q_scaled, k.transpose(-2, -1))\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/functional.py:6246: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  attn_output = torch.bmm(attn_output_weights, v)\n",
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/autograd/graph.py:825: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6783\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3769\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3604\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3480\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3414\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3197\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3178\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2931\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2949\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2835\n",
      "\n",
      "=== æ–°è®­ç»ƒçš„4å±‚æ¨¡å‹æµ‹è¯•ç»“æœ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/modules/activation.py:1308: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9104, PRE: 0.9441, REC: 0.9291, F1: 0.9365, MCC: 0.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/1809652477.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_sota.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SOTAæ¨¡å‹æµ‹è¯•ç»“æœ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songjiaxing/.conda/envs/PEL-PVP/lib/python3.9/site-packages/torch/nn/modules/activation.py:1308: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:208.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š ç»“æœå¯¹æ¯”åˆ†æ\n",
      "============================================================\n",
      "SOTAæ¨¡å‹ F1: 0.9454\n",
      "æ–°è®­ç»ƒæ¨¡å‹ F1: 0.9365\n",
      "F1å·®å¼‚: 0.0089\n",
      "âœ… ç»“æœåŸºæœ¬ä¸€è‡´ï¼Œå·®å¼‚åœ¨åˆç†èŒƒå›´å†…\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:09:50.183440Z",
     "start_time": "2025-07-23T04:09:50.183050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "  # ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•\n",
    "    model.load_state_dict(best_state)\n",
    "    final_metrics = eval_model(model, test_loader, device)\n",
    "    results[num_layers] = {\n",
    "        'acc': final_metrics[0], 'pre': final_metrics[1], 'rec': final_metrics[2],\n",
    "        'f1': final_metrics[3], 'mcc': final_metrics[4], 'auc': final_metrics[5],\n",
    "        'auprc': final_metrics[6], 'sn': final_metrics[7], 'sp': final_metrics[8]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{num_layers}å±‚TransformerMoEæœ€ç»ˆæµ‹è¯•ç»“æœ:\")\n",
    "    print(f\"ACC: {final_metrics[0]:.4f}, PRE: {final_metrics[1]:.4f}, REC: {final_metrics[2]:.4f}\")\n",
    "    print(f\"F1: {final_metrics[3]:.4f}, MCC: {final_metrics[4]:.4f}\")\n",
    "    print(f\"AUC: {final_metrics[5]:.4f}, AUPRC: {final_metrics[6]:.4f}\")\n",
    "    print(f\"SN: {final_metrics[7]:.4f}, SP: {final_metrics[8]:.4f}\")\n",
    "\n",
    "# æ±‡æ€»æ‰€æœ‰ç»“æœ\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"æ‰€æœ‰å±‚æ•°TransformerMoEç»“æœæ±‡æ€»\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Layers':<8}{'ACC':<8}{'PRE':<8}{'REC':<8}{'F1':<8}{'MCC':<8}{'AUC':<8}{'AUPRC':<8}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "for layers in layer_configs:\n",
    "    r = results[layers]\n",
    "    print(f\"{layers:<8}{r['acc']:<8.4f}{r['pre']:<8.4f}{r['rec']:<8.4f}{r['f1']:<8.4f}{r['mcc']:<8.4f}{r['auc']:<8.4f}{r['auprc']:<8.4f}\")"
   ],
   "id": "9b0ad23965ff0253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### æˆ‘çš„æœ€ä½³æ¨¡å‹æµ‹è¯•é›†æ€§èƒ½",
   "id": "f0197c0e04fc26d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:31:28.102348Z",
     "start_time": "2025-07-23T06:31:09.749478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# å‡è®¾æ¨¡å‹ç»“æ„å’ŒProteinNPYDatasetå·²å®šä¹‰ï¼Œdeviceå·²è®¾ç½®\n",
    "import torch\n",
    "\n",
    "# 1. åŠ è½½æ¨¡å‹\n",
    "model = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2. åŠ è½½æµ‹è¯•é›†\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 3. å®šä¹‰è¯„ä¼°å‡½æ•°\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc\n",
    "\n",
    "# 4. æµ‹è¯•\n",
    "eval_model(model, test_loader, device)"
   ],
   "id": "176b7cb9a5004cf2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474920/4116043199.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9225413402959095,\n",
       " 0.948339483394834,\n",
       " 0.9425427872860636,\n",
       " 0.9454322501532803,\n",
       " 0.8120485793877618)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# è®°å½•\n",
    "ç¬¬ä¸€æ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "\n",
    "ç»“æœ Test ACC: 0.9173, PRE: 0.9199, REC: 0.9682, F1: 0.9434, MCC: 0.7939\n",
    "\n",
    "ç¬¬äºŒæ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=5, num_experts=30, k=2, dropout=0.2, noisy_std=1.0, num_classes=2 epoch=20\n",
    "\n",
    "ç»“æœ Test ACC: 0.8973, PRE: 0.9464, REC: 0.9071, F1: 0.9263, MCC: 0.7589\n",
    "\n",
    "ç¬¬ä¸‰æ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=15\n",
    "ç»“æœTest ACC: 0.9121, PRE: 0.9544, REC: 0.9205, F1: 0.9371, MCC: 0.7926\n",
    "\n",
    "ç¬¬å››æ¬¡å‚æ•°è®¾ç½®d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "æ•°æ®é›†å˜æˆä¸åŠ gan\n",
    "\n",
    "ç»“æœï¼šTest ACC: 0.8808, PRE: 0.9570, REC: 0.8716, F1: 0.9123, MCC: 0.7350\n",
    "\n",
    "ç¬¬äº”æ¬¡å‚æ•°è®¾ç½®d_model=1152, nhead=8, d_ff=2048, num_layers=3, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "\n",
    "ç»“æœï¼šTest ACC: 0.9017, PRE: 0.9094, REC: 0.9572, F1: 0.9327, MCC: 0.7540\n",
    "\n",
    "ç¬¬å…­æ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10 åŠ ä¸Šäº†ä¸€ä¸ªkamingåˆå§‹åŒ–\n",
    "\n",
    "ç»“æœï¼šTest ACC: 0.9130, PRE: 0.9367, REC: 0.9413, F1: 0.9390, MCC: 0.7871\n",
    "\n",
    "ç¬¬ä¸ƒæ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=40, k=2, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "ç»“æœï¼šTest ACC: 0.8782, PRE: 0.9508, REC: 0.8741, F1: 0.9108, MCC: 0.7260\n",
    "\n",
    "ç¬¬å…«æ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=35, k=2, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "ç»“æœTest ACC: 0.9112, PRE: 0.9409, REC: 0.9340, F1: 0.9374, MCC: 0.7848\n",
    "\n",
    "ç¬¬ä¹æ¬¡å‚æ•°è®¾ç½®d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=25, k=2, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "ç»“æœTest ACC: 0.8982, PRE: 0.8899, REC: 0.9780, F1: 0.9319, MCC: 0.7452\n",
    "\n",
    "ç¬¬åæ¬¡å‚æ•°è®¾ç½® d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=1, dropout=0.1, noisy_std=1.0, num_classes=2 epoch=10\n",
    "\n",
    "ç»“æœï¼šTest ACC: 0.9017, PRE: 0.9657, REC: 0.8936, F1: 0.9283, MCC: 0.7786\n",
    "\n",
    "ç¬¬åä¸€æ¬¡å‚æ•°è®¾ç½®d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "\n",
    "ç»“æœTest ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
    "\n",
    "\n",
    "### åæŠ˜éªŒè¯é›†\n",
    "å‚æ•°å‡ä½¿ç”¨å‰è¾¹çš„æœ€ä½³æ¨¡å‹çš„å‚æ•°\n",
    "\n",
    "ç»“æœï¼š========== 10-Fold CV Results ==========\n",
    "Mean ACC: 0.9401 Â± 0.0058\n",
    "Mean PRE: 0.9264\n",
    "Mean REC: 0.9260\n",
    "Mean F1:  0.9252\n",
    "Mean MCC: 0.8523\n",
    "\n",
    "### åæŠ˜æµ‹è¯•é›†\n",
    "ç»“æœï¼š========== 10-Fold Test Results ==========\n",
    "Mean ACC: 0.9155 Â± 0.0048\n",
    "Mean PRE: 0.9338\n",
    "Mean REC: 0.9488\n",
    "Mean F1:  0.9411\n",
    "Mean MCC: 0.7925"
   ],
   "id": "20df39fc2248804a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### sotaåæŠ˜è®­ç»ƒé›†\n",
    " æ¯ä¸€æŠ˜å¾—åˆ†ï¼š\n",
    "        ACC        F1       MCC        SN        SP    Recall  Precision  \\\n",
    "0  0.884783  0.918836  0.720346  0.917431  0.804511  0.917431   0.920245   \n",
    "1  0.876087  0.915052  0.689696  0.938838  0.721805  0.938838   0.892442   \n",
    "2  0.891304  0.923313  0.736793  0.920489  0.819549  0.920489   0.926154   \n",
    "3  0.895425  0.927273  0.741669  0.935780  0.795455  0.935780   0.918919   \n",
    "4  0.895425  0.928144  0.738638  0.948012  0.765152  0.948012   0.909091   \n",
    "5  0.877996  0.913846  0.705075  0.908257  0.803030  0.908257   0.919505   \n",
    "6  0.901961  0.932127  0.756676  0.944954  0.795455  0.944954   0.919643   \n",
    "7  0.880174  0.917541  0.700500  0.935780  0.742424  0.935780   0.900000   \n",
    "8  0.886710  0.920973  0.721165  0.926606  0.787879  0.926606   0.915408   \n",
    "9  0.895425  0.928571  0.737651  0.954128  0.750000  0.954128   0.904348   \n",
    " AUC     AUPRC  \n",
    "0  0.958152  0.983695  \n",
    "1  0.936746  0.972714  \n",
    "2  0.944264  0.974113  \n",
    "3  0.946958  0.978492  \n",
    "4  0.965110  0.986893  \n",
    "5  0.922667  0.964155  \n",
    "6  0.942174  0.974796  \n",
    "7  0.942591  0.976072  \n",
    "8  0.944213  0.976352  \n",
    "9  0.932583  0.959434  \n",
    "\n",
    "ğŸ“ˆ å„æŒ‡æ ‡å¹³å‡ Â± æ ‡å‡†å·®ï¼š\n",
    "ACC: 0.8885 Â± 0.0087\n",
    "F1: 0.9226 Â± 0.0063\n",
    "MCC: 0.7248 Â± 0.0212\n",
    "SN: 0.9330 Â± 0.0146\n",
    "SP: 0.7785 Â± 0.0319\n",
    "Recall: 0.9330 Â± 0.0146\n",
    "Precision: 0.9126 Â± 0.0107\n",
    "AUC: 0.9435 Â± 0.0120\n",
    "AUPRC: 0.9747 Â± 0.0081"
   ],
   "id": "acd92ac1664ca339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### åæŠ˜äº¤å‰éªŒè¯",
   "id": "ce8481db9fb0292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T03:08:39.450535Z",
     "start_time": "2025-07-20T03:08:39.444790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, average_precision_score\n",
    "\n",
    "import os\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ],
   "id": "d046bb7ba803721d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T03:08:41.397485Z",
     "start_time": "2025-07-20T03:08:41.390460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, moe_loss_weight=0.01, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            logits, lb_loss = model(x)\n",
    "            loss = criterion(logits, y) + moe_loss_weight * lb_loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    print(f\"Val ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc"
   ],
   "id": "cc7e459aef30a0bc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-19T19:45:53.281928Z",
     "start_time": "2025-07-19T16:31:18.844487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "\n",
    "# æ„å»ºå…¨ä½“ç´¢å¼•å’Œæ ‡ç­¾\n",
    "pos_len = np.load(train_pos, mmap_mode='r').shape[0]\n",
    "neg_len = np.load(train_neg, mmap_mode='r').shape[0]\n",
    "all_indices = np.concatenate([np.arange(pos_len), np.arange(neg_len) + pos_len])\n",
    "all_labels = np.concatenate([np.ones(pos_len, dtype=int), np.zeros(neg_len, dtype=int)])\n",
    "\n",
    "# æ•°æ®é›†\n",
    "full_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "\n",
    "# KæŠ˜åˆ†å±‚\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_indices, all_labels), 1):\n",
    "    print(f\"\\n========== Fold {fold}/10 ==========\")\n",
    "    train_loader = DataLoader(Subset(full_dataset, train_idx), batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(Subset(full_dataset, val_idx), batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[Fold {fold}] Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                logits, lb_loss = model(x)\n",
    "                loss = criterion(logits, y) + 0.01 * lb_loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # éªŒè¯\n",
    "        model.eval()\n",
    "        all_preds, all_labels_fold = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits, _ = model(x)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels_fold.extend(y.cpu().numpy())\n",
    "        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "        acc = accuracy_score(all_labels_fold, all_preds)\n",
    "        pre = precision_score(all_labels_fold, all_preds)\n",
    "        rec = recall_score(all_labels_fold, all_preds)\n",
    "        f1 = f1_score(all_labels_fold, all_preds)\n",
    "        mcc = matthews_corrcoef(all_labels_fold, all_preds)\n",
    "        print(f\"Val ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_state = model.state_dict()\n",
    "            torch.save(best_state, f\"/exp_data/sjx/star/main_transformer_moe_weight/cv_point/best_fold{fold}.pth\")\n",
    "            print(f\"Best model saved for fold {fold} at epoch {epoch+1}\")\n",
    "\n",
    "    all_metrics.append((best_acc, pre, rec, f1, mcc))\n",
    "    print(f\"[Fold {fold}] Best ACC: {best_acc:.4f}\")\n",
    "\n",
    "# æ±‡æ€»ç»“æœ\n",
    "all_metrics = np.array(all_metrics)\n",
    "print(\"\\n========== 10-Fold CV Results ==========\")\n",
    "print(f\"Mean ACC: {all_metrics[:,0].mean():.4f} Â± {all_metrics[:,0].std():.4f}\")\n",
    "print(f\"Mean PRE: {all_metrics[:,1].mean():.4f}Â± {all_metrics[:,1].std():.4f}\")\n",
    "print(f\"Mean REC: {all_metrics[:,2].mean():.4f}Â± {all_metrics[:,2].std():.4f}\")\n",
    "print(f\"Mean F1:  {all_metrics[:,3].mean():.4f}Â± {all_metrics[:,3].std():.4f}\")\n",
    "print(f\"Mean MCC: {all_metrics[:,4].mean():.4f}Â± {all_metrics[:,4].std():.4f}\")"
   ],
   "id": "cde6cd3f45854fd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/10 ==========\n",
      "\n",
      "[Fold 1] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5652\n",
      "Val ACC: 0.9115, PRE: 0.9327, REC: 0.8872, F1: 0.9094, MCC: 0.8239\n",
      "Best model saved for fold 1 at epoch 1\n",
      "\n",
      "[Fold 1] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3694\n",
      "Val ACC: 0.9252, PRE: 0.9215, REC: 0.9299, F1: 0.9256, MCC: 0.8504\n",
      "Best model saved for fold 1 at epoch 2\n",
      "\n",
      "[Fold 1] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3596\n",
      "Val ACC: 0.9328, PRE: 0.9383, REC: 0.9268, F1: 0.9325, MCC: 0.8657\n",
      "Best model saved for fold 1 at epoch 3\n",
      "\n",
      "[Fold 1] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3524\n",
      "Val ACC: 0.9252, PRE: 0.9515, REC: 0.8963, F1: 0.9231, MCC: 0.8518\n",
      "\n",
      "[Fold 1] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3447\n",
      "Val ACC: 0.9298, PRE: 0.9462, REC: 0.9116, F1: 0.9286, MCC: 0.8601\n",
      "\n",
      "[Fold 1] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3282\n",
      "Val ACC: 0.9176, PRE: 0.8743, REC: 0.9756, F1: 0.9222, MCC: 0.8408\n",
      "\n",
      "[Fold 1] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3202\n",
      "Val ACC: 0.9237, PRE: 0.8798, REC: 0.9817, F1: 0.9280, MCC: 0.8531\n",
      "\n",
      "[Fold 1] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3109\n",
      "Val ACC: 0.9405, PRE: 0.9313, REC: 0.9512, F1: 0.9412, MCC: 0.8811\n",
      "Best model saved for fold 1 at epoch 8\n",
      "\n",
      "[Fold 1] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3105\n",
      "Val ACC: 0.9191, PRE: 0.9231, REC: 0.9146, F1: 0.9188, MCC: 0.8382\n",
      "\n",
      "[Fold 1] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3017\n",
      "Val ACC: 0.9267, PRE: 0.9142, REC: 0.9421, F1: 0.9279, MCC: 0.8538\n",
      "[Fold 1] Best ACC: 0.9405\n",
      "\n",
      "========== Fold 2/10 ==========\n",
      "\n",
      "[Fold 2] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6760\n",
      "Val ACC: 0.9405, PRE: 0.9706, REC: 0.9083, F1: 0.9384, MCC: 0.8827\n",
      "Best model saved for fold 2 at epoch 1\n",
      "\n",
      "[Fold 2] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3859\n",
      "Val ACC: 0.9237, PRE: 0.9663, REC: 0.8777, F1: 0.9199, MCC: 0.8509\n",
      "\n",
      "[Fold 2] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3672\n",
      "Val ACC: 0.9313, PRE: 0.8895, REC: 0.9847, F1: 0.9347, MCC: 0.8676\n",
      "\n",
      "[Fold 2] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3574\n",
      "Val ACC: 0.9496, PRE: 0.9428, REC: 0.9572, F1: 0.9499, MCC: 0.8993\n",
      "Best model saved for fold 2 at epoch 4\n",
      "\n",
      "[Fold 2] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3480\n",
      "Val ACC: 0.9481, PRE: 0.9681, REC: 0.9266, F1: 0.9469, MCC: 0.8970\n",
      "\n",
      "[Fold 2] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3399\n",
      "Val ACC: 0.9221, PRE: 0.9539, REC: 0.8869, F1: 0.9192, MCC: 0.8463\n",
      "\n",
      "[Fold 2] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3293\n",
      "Val ACC: 0.9145, PRE: 0.9721, REC: 0.8532, F1: 0.9088, MCC: 0.8352\n",
      "\n",
      "[Fold 2] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3222\n",
      "Val ACC: 0.9496, PRE: 0.9509, REC: 0.9480, F1: 0.9495, MCC: 0.8992\n",
      "\n",
      "[Fold 2] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3238\n",
      "Val ACC: 0.9237, PRE: 0.9425, REC: 0.9021, F1: 0.9219, MCC: 0.8481\n",
      "\n",
      "[Fold 2] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3088\n",
      "Val ACC: 0.9450, PRE: 0.9396, REC: 0.9511, F1: 0.9453, MCC: 0.8901\n",
      "[Fold 2] Best ACC: 0.9496\n",
      "\n",
      "========== Fold 3/10 ==========\n",
      "\n",
      "[Fold 3] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6411\n",
      "Val ACC: 0.9312, PRE: 0.9490, REC: 0.9113, F1: 0.9298, MCC: 0.8631\n",
      "Best model saved for fold 3 at epoch 1\n",
      "\n",
      "[Fold 3] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3839\n",
      "Val ACC: 0.9327, PRE: 0.9275, REC: 0.9388, F1: 0.9331, MCC: 0.8655\n",
      "Best model saved for fold 3 at epoch 2\n",
      "\n",
      "[Fold 3] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3561\n",
      "Val ACC: 0.9358, PRE: 0.9331, REC: 0.9388, F1: 0.9360, MCC: 0.8716\n",
      "Best model saved for fold 3 at epoch 3\n",
      "\n",
      "[Fold 3] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3534\n",
      "Val ACC: 0.9159, PRE: 0.9359, REC: 0.8930, F1: 0.9139, MCC: 0.8327\n",
      "\n",
      "[Fold 3] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3500\n",
      "Val ACC: 0.9297, PRE: 0.9049, REC: 0.9602, F1: 0.9318, MCC: 0.8609\n",
      "\n",
      "[Fold 3] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3373\n",
      "Val ACC: 0.9327, PRE: 0.9464, REC: 0.9174, F1: 0.9317, MCC: 0.8658\n",
      "\n",
      "[Fold 3] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3219\n",
      "Val ACC: 0.9235, PRE: 0.9511, REC: 0.8930, F1: 0.9211, MCC: 0.8487\n",
      "\n",
      "[Fold 3] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3185\n",
      "Val ACC: 0.9235, PRE: 0.9184, REC: 0.9297, F1: 0.9240, MCC: 0.8472\n",
      "\n",
      "[Fold 3] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3068\n",
      "Val ACC: 0.9297, PRE: 0.9404, REC: 0.9174, F1: 0.9288, MCC: 0.8596\n",
      "\n",
      "[Fold 3] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3044\n",
      "Val ACC: 0.9052, PRE: 0.9585, REC: 0.8471, F1: 0.8994, MCC: 0.8159\n",
      "[Fold 3] Best ACC: 0.9358\n",
      "\n",
      "========== Fold 4/10 ==========\n",
      "\n",
      "[Fold 4] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6252\n",
      "Val ACC: 0.9495, PRE: 0.9401, REC: 0.9602, F1: 0.9501, MCC: 0.8993\n",
      "Best model saved for fold 4 at epoch 1\n",
      "\n",
      "[Fold 4] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3803\n",
      "Val ACC: 0.9480, PRE: 0.9564, REC: 0.9388, F1: 0.9475, MCC: 0.8962\n",
      "\n",
      "[Fold 4] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3782\n",
      "Val ACC: 0.9251, PRE: 0.8819, REC: 0.9817, F1: 0.9291, MCC: 0.8556\n",
      "\n",
      "[Fold 4] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3507\n",
      "Val ACC: 0.9434, PRE: 0.9475, REC: 0.9388, F1: 0.9432, MCC: 0.8869\n",
      "\n",
      "[Fold 4] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3403\n",
      "Val ACC: 0.9343, PRE: 0.9226, REC: 0.9480, F1: 0.9351, MCC: 0.8688\n",
      "\n",
      "[Fold 4] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3386\n",
      "Val ACC: 0.9450, PRE: 0.9477, REC: 0.9419, F1: 0.9448, MCC: 0.8899\n",
      "\n",
      "[Fold 4] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3254\n",
      "Val ACC: 0.9037, PRE: 0.9074, REC: 0.8991, F1: 0.9032, MCC: 0.8074\n",
      "\n",
      "[Fold 4] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3125\n",
      "Val ACC: 0.9205, PRE: 0.9310, REC: 0.9083, F1: 0.9195, MCC: 0.8412\n",
      "\n",
      "[Fold 4] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3007\n",
      "Val ACC: 0.9343, PRE: 0.9176, REC: 0.9541, F1: 0.9355, MCC: 0.8692\n",
      "\n",
      "[Fold 4] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3137\n",
      "Val ACC: 0.9327, PRE: 0.9174, REC: 0.9511, F1: 0.9339, MCC: 0.8660\n",
      "[Fold 4] Best ACC: 0.9495\n",
      "\n",
      "========== Fold 5/10 ==========\n",
      "\n",
      "[Fold 5] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6743\n",
      "Val ACC: 0.9220, PRE: 0.8966, REC: 0.9541, F1: 0.9244, MCC: 0.8458\n",
      "Best model saved for fold 5 at epoch 1\n",
      "\n",
      "[Fold 5] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3820\n",
      "Val ACC: 0.9281, PRE: 0.9403, REC: 0.9144, F1: 0.9271, MCC: 0.8566\n",
      "Best model saved for fold 5 at epoch 2\n",
      "\n",
      "[Fold 5] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3556\n",
      "Val ACC: 0.9373, PRE: 0.9206, REC: 0.9572, F1: 0.9385, MCC: 0.8753\n",
      "Best model saved for fold 5 at epoch 3\n",
      "\n",
      "[Fold 5] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3469\n",
      "Val ACC: 0.9327, PRE: 0.9174, REC: 0.9511, F1: 0.9339, MCC: 0.8660\n",
      "\n",
      "[Fold 5] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3418\n",
      "Val ACC: 0.9266, PRE: 0.8974, REC: 0.9633, F1: 0.9292, MCC: 0.8555\n",
      "\n",
      "[Fold 5] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3314\n",
      "Val ACC: 0.9266, PRE: 0.8952, REC: 0.9664, F1: 0.9294, MCC: 0.8559\n",
      "\n",
      "[Fold 5] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3155\n",
      "Val ACC: 0.9098, PRE: 0.9408, REC: 0.8746, F1: 0.9065, MCC: 0.8216\n",
      "\n",
      "[Fold 5] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3304\n",
      "Val ACC: 0.9144, PRE: 0.8712, REC: 0.9725, F1: 0.9191, MCC: 0.8344\n",
      "\n",
      "[Fold 5] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3061\n",
      "Val ACC: 0.9220, PRE: 0.8988, REC: 0.9511, F1: 0.9242, MCC: 0.8455\n",
      "\n",
      "[Fold 5] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3054\n",
      "Val ACC: 0.9312, PRE: 0.9379, REC: 0.9235, F1: 0.9307, MCC: 0.8625\n",
      "[Fold 5] Best ACC: 0.9373\n",
      "\n",
      "========== Fold 6/10 ==========\n",
      "\n",
      "[Fold 6] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6754\n",
      "Val ACC: 0.9251, PRE: 0.9696, REC: 0.8777, F1: 0.9213, MCC: 0.8540\n",
      "Best model saved for fold 6 at epoch 1\n",
      "\n",
      "[Fold 6] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3838\n",
      "Val ACC: 0.9358, PRE: 0.9582, REC: 0.9113, F1: 0.9342, MCC: 0.8726\n",
      "Best model saved for fold 6 at epoch 2\n",
      "\n",
      "[Fold 6] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3685\n",
      "Val ACC: 0.9373, PRE: 0.9583, REC: 0.9144, F1: 0.9358, MCC: 0.8755\n",
      "Best model saved for fold 6 at epoch 3\n",
      "\n",
      "[Fold 6] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3521\n",
      "Val ACC: 0.9220, PRE: 0.8730, REC: 0.9878, F1: 0.9268, MCC: 0.8514\n",
      "\n",
      "[Fold 6] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3478\n",
      "Val ACC: 0.9434, PRE: 0.9290, REC: 0.9602, F1: 0.9444, MCC: 0.8874\n",
      "Best model saved for fold 6 at epoch 5\n",
      "\n",
      "[Fold 6] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3415\n",
      "Val ACC: 0.9312, PRE: 0.9548, REC: 0.9052, F1: 0.9294, MCC: 0.8636\n",
      "\n",
      "[Fold 6] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3325\n",
      "Val ACC: 0.9251, PRE: 0.9696, REC: 0.8777, F1: 0.9213, MCC: 0.8540\n",
      "\n",
      "[Fold 6] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3147\n",
      "Val ACC: 0.9434, PRE: 0.9290, REC: 0.9602, F1: 0.9444, MCC: 0.8874\n",
      "\n",
      "[Fold 6] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3241\n",
      "Val ACC: 0.9495, PRE: 0.9623, REC: 0.9358, F1: 0.9488, MCC: 0.8994\n",
      "Best model saved for fold 6 at epoch 9\n",
      "\n",
      "[Fold 6] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3082\n",
      "Val ACC: 0.9174, PRE: 0.9691, REC: 0.8624, F1: 0.9126, MCC: 0.8400\n",
      "[Fold 6] Best ACC: 0.9495\n",
      "\n",
      "========== Fold 7/10 ==========\n",
      "\n",
      "[Fold 7] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5767\n",
      "Val ACC: 0.9312, PRE: 0.9147, REC: 0.9511, F1: 0.9325, MCC: 0.8631\n",
      "Best model saved for fold 7 at epoch 1\n",
      "\n",
      "[Fold 7] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3784\n",
      "Val ACC: 0.9388, PRE: 0.9184, REC: 0.9633, F1: 0.9403, MCC: 0.8787\n",
      "Best model saved for fold 7 at epoch 2\n",
      "\n",
      "[Fold 7] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3571\n",
      "Val ACC: 0.9190, PRE: 0.8806, REC: 0.9694, F1: 0.9229, MCC: 0.8422\n",
      "\n",
      "[Fold 7] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3518\n",
      "Val ACC: 0.9281, PRE: 0.9217, REC: 0.9358, F1: 0.9287, MCC: 0.8564\n",
      "\n",
      "[Fold 7] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3414\n",
      "Val ACC: 0.9297, PRE: 0.9460, REC: 0.9113, F1: 0.9283, MCC: 0.8599\n",
      "\n",
      "[Fold 7] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3384\n",
      "Val ACC: 0.9113, PRE: 0.8587, REC: 0.9847, F1: 0.9174, MCC: 0.8316\n",
      "\n",
      "[Fold 7] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3220\n",
      "Val ACC: 0.9297, PRE: 0.9377, REC: 0.9205, F1: 0.9290, MCC: 0.8595\n",
      "\n",
      "[Fold 7] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3190\n",
      "Val ACC: 0.9312, PRE: 0.9352, REC: 0.9266, F1: 0.9309, MCC: 0.8624\n",
      "\n",
      "[Fold 7] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3087\n",
      "Val ACC: 0.9373, PRE: 0.9333, REC: 0.9419, F1: 0.9376, MCC: 0.8747\n",
      "\n",
      "[Fold 7] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3073\n",
      "Val ACC: 0.9190, PRE: 0.8848, REC: 0.9633, F1: 0.9224, MCC: 0.8412\n",
      "[Fold 7] Best ACC: 0.9388\n",
      "\n",
      "========== Fold 8/10 ==========\n",
      "\n",
      "[Fold 8] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5816\n",
      "Val ACC: 0.9343, PRE: 0.9410, REC: 0.9266, F1: 0.9337, MCC: 0.8686\n",
      "Best model saved for fold 8 at epoch 1\n",
      "\n",
      "[Fold 8] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3854\n",
      "Val ACC: 0.9266, PRE: 0.8974, REC: 0.9633, F1: 0.9292, MCC: 0.8555\n",
      "\n",
      "[Fold 8] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3647\n",
      "Val ACC: 0.9220, PRE: 0.8730, REC: 0.9878, F1: 0.9268, MCC: 0.8514\n",
      "\n",
      "[Fold 8] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3515\n",
      "Val ACC: 0.9220, PRE: 0.9395, REC: 0.9021, F1: 0.9204, MCC: 0.8447\n",
      "\n",
      "[Fold 8] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3449\n",
      "Val ACC: 0.9159, PRE: 0.8676, REC: 0.9817, F1: 0.9211, MCC: 0.8391\n",
      "\n",
      "[Fold 8] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3329\n",
      "Val ACC: 0.9388, PRE: 0.9388, REC: 0.9388, F1: 0.9388, MCC: 0.8777\n",
      "Best model saved for fold 8 at epoch 6\n",
      "\n",
      "[Fold 8] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3322\n",
      "Val ACC: 0.9450, PRE: 0.9396, REC: 0.9511, F1: 0.9453, MCC: 0.8900\n",
      "Best model saved for fold 8 at epoch 7\n",
      "\n",
      "[Fold 8] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3325\n",
      "Val ACC: 0.9312, PRE: 0.9172, REC: 0.9480, F1: 0.9323, MCC: 0.8629\n",
      "\n",
      "[Fold 8] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3134\n",
      "Val ACC: 0.9297, PRE: 0.9518, REC: 0.9052, F1: 0.9279, MCC: 0.8604\n",
      "\n",
      "[Fold 8] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3057\n",
      "Val ACC: 0.9190, PRE: 0.9177, REC: 0.9205, F1: 0.9191, MCC: 0.8379\n",
      "[Fold 8] Best ACC: 0.9450\n",
      "\n",
      "========== Fold 9/10 ==========\n",
      "\n",
      "[Fold 9] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5858\n",
      "Val ACC: 0.9266, PRE: 0.9240, REC: 0.9297, F1: 0.9268, MCC: 0.8532\n",
      "Best model saved for fold 9 at epoch 1\n",
      "\n",
      "[Fold 9] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3787\n",
      "Val ACC: 0.9281, PRE: 0.9268, REC: 0.9297, F1: 0.9282, MCC: 0.8563\n",
      "Best model saved for fold 9 at epoch 2\n",
      "\n",
      "[Fold 9] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3666\n",
      "Val ACC: 0.9343, PRE: 0.9410, REC: 0.9266, F1: 0.9337, MCC: 0.8686\n",
      "Best model saved for fold 9 at epoch 3\n",
      "\n",
      "[Fold 9] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3516\n",
      "Val ACC: 0.9190, PRE: 0.9053, REC: 0.9358, F1: 0.9203, MCC: 0.8384\n",
      "\n",
      "[Fold 9] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3365\n",
      "Val ACC: 0.9297, PRE: 0.9120, REC: 0.9511, F1: 0.9311, MCC: 0.8601\n",
      "\n",
      "[Fold 9] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3327\n",
      "Val ACC: 0.9297, PRE: 0.9194, REC: 0.9419, F1: 0.9305, MCC: 0.8596\n",
      "\n",
      "[Fold 9] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3212\n",
      "Val ACC: 0.9251, PRE: 0.8971, REC: 0.9602, F1: 0.9276, MCC: 0.8523\n",
      "\n",
      "[Fold 9] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3083\n",
      "Val ACC: 0.9312, PRE: 0.8983, REC: 0.9725, F1: 0.9339, MCC: 0.8653\n",
      "\n",
      "[Fold 9] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3090\n",
      "Val ACC: 0.9235, PRE: 0.9134, REC: 0.9358, F1: 0.9245, MCC: 0.8473\n",
      "\n",
      "[Fold 9] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2986\n",
      "Val ACC: 0.9343, PRE: 0.9303, REC: 0.9388, F1: 0.9346, MCC: 0.8685\n",
      "[Fold 9] Best ACC: 0.9343\n",
      "\n",
      "========== Fold 10/10 ==========\n",
      "\n",
      "[Fold 10] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5124\n",
      "Val ACC: 0.9144, PRE: 0.9562, REC: 0.8685, F1: 0.9103, MCC: 0.8323\n",
      "Best model saved for fold 10 at epoch 1\n",
      "\n",
      "[Fold 10] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3734\n",
      "Val ACC: 0.9220, PRE: 0.9313, REC: 0.9113, F1: 0.9212, MCC: 0.8442\n",
      "Best model saved for fold 10 at epoch 2\n",
      "\n",
      "[Fold 10] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3590\n",
      "Val ACC: 0.9052, PRE: 0.9749, REC: 0.8318, F1: 0.8977, MCC: 0.8193\n",
      "\n",
      "[Fold 10] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3600\n",
      "Val ACC: 0.9235, PRE: 0.9397, REC: 0.9052, F1: 0.9221, MCC: 0.8477\n",
      "Best model saved for fold 10 at epoch 4\n",
      "\n",
      "[Fold 10] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3377\n",
      "Val ACC: 0.9190, PRE: 0.9308, REC: 0.9052, F1: 0.9178, MCC: 0.8382\n",
      "\n",
      "[Fold 10] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3370\n",
      "Val ACC: 0.9235, PRE: 0.9315, REC: 0.9144, F1: 0.9228, MCC: 0.8472\n",
      "\n",
      "[Fold 10] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3217\n",
      "Val ACC: 0.9159, PRE: 0.8757, REC: 0.9694, F1: 0.9202, MCC: 0.8366\n",
      "\n",
      "[Fold 10] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3195\n",
      "Val ACC: 0.9312, PRE: 0.9434, REC: 0.9174, F1: 0.9302, MCC: 0.8627\n",
      "Best model saved for fold 10 at epoch 8\n",
      "\n",
      "[Fold 10] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3070\n",
      "Val ACC: 0.9144, PRE: 0.9357, REC: 0.8899, F1: 0.9122, MCC: 0.8297\n",
      "\n",
      "[Fold 10] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3981349929.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3082\n",
      "Val ACC: 0.9235, PRE: 0.9369, REC: 0.9083, F1: 0.9224, MCC: 0.8475\n",
      "[Fold 10] Best ACC: 0.9312\n",
      "\n",
      "========== 10-Fold CV Results ==========\n",
      "Mean ACC: 0.9411 Â± 0.0065\n",
      "Mean PRE: 0.9306Â± 0.0227\n",
      "Mean REC: 0.9208Â± 0.0366\n",
      "Mean F1:  0.9248Â± 0.0122\n",
      "Mean MCC: 0.8524Â± 0.0195\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:16:09.729953Z",
     "start_time": "2025-07-20T03:08:55.561334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/gan_data/negative_train_all_combined.npy'\n",
    "\n",
    "# æ„å»ºå…¨ä½“ç´¢å¼•å’Œæ ‡ç­¾\n",
    "pos_len = np.load(train_pos, mmap_mode='r').shape[0]\n",
    "neg_len = np.load(train_neg, mmap_mode='r').shape[0]\n",
    "all_indices = np.concatenate([np.arange(pos_len), np.arange(neg_len) + pos_len])\n",
    "all_labels = np.concatenate([np.ones(pos_len, dtype=int), np.zeros(neg_len, dtype=int)])\n",
    "\n",
    "# æ•°æ®é›†\n",
    "full_dataset = ProteinNPYDataset(train_pos, train_neg)\n",
    "\n",
    "# KæŠ˜åˆ†å±‚\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_indices, all_labels), 1):\n",
    "    print(f\"\\n========== Fold {fold}/10 ==========\")\n",
    "    train_loader = DataLoader(Subset(full_dataset, train_idx), batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(Subset(full_dataset, val_idx), batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_state = None\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n[Fold {fold}] Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                logits, lb_loss = model(x)\n",
    "                loss = criterion(logits, y) + 0.01 * lb_loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"è®­ç»ƒæŸå¤±: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # éªŒè¯\n",
    "        model.eval()\n",
    "        all_preds, all_labels_fold = [], []\n",
    "        all_probs = []  # å­˜å‚¨é¢„æµ‹æ¦‚ç‡ç”¨äºAUCå’ŒAUPRCè®¡ç®—\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits, _ = model(x)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels_fold.extend(y.cpu().numpy())\n",
    "                all_probs.extend(probs[:, 1].cpu().numpy())  # æ­£ç±»çš„æ¦‚ç‡\n",
    "        \n",
    "        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡\n",
    "        acc = accuracy_score(all_labels_fold, all_preds)\n",
    "        pre = precision_score(all_labels_fold, all_preds)\n",
    "        rec = recall_score(all_labels_fold, all_preds)\n",
    "        f1 = f1_score(all_labels_fold, all_preds)\n",
    "        mcc = matthews_corrcoef(all_labels_fold, all_preds)\n",
    "        \n",
    "        # è®¡ç®—SNï¼ˆæ•æ„Ÿæ€§/å¬å›ç‡ï¼‰å’ŒSPï¼ˆç‰¹å¼‚æ€§ï¼‰\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels_fold, all_preds).ravel()\n",
    "        sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # æ•æ„Ÿæ€§\n",
    "        sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # ç‰¹å¼‚æ€§\n",
    "        \n",
    "        # è®¡ç®—AUCå’ŒAUPRC\n",
    "        auc = roc_auc_score(all_labels_fold, all_probs)\n",
    "        auprc = average_precision_score(all_labels_fold, all_probs)\n",
    "        \n",
    "        print(f\"éªŒè¯å‡†ç¡®ç‡: {acc:.4f}, ç²¾ç¡®ç‡: {pre:.4f}, å¬å›ç‡: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "        print(f\"æ•æ„Ÿæ€§(SN): {sn:.4f}, ç‰¹å¼‚æ€§(SP): {sp:.4f}, AUC: {auc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_state = model.state_dict()\n",
    "            # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨\n",
    "            save_dir = \"/exp_data/sjx/star/main_transformer_moe_weight/cv_point\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            torch.save(best_state, f\"{save_dir}/best_fold{fold}.pth\")\n",
    "            print(f\"Fold {fold} ç¬¬ {epoch+1} è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\")\n",
    "\n",
    "    # ä¿å­˜è¯¥foldçš„æœ€ä½³æŒ‡æ ‡\n",
    "    all_metrics.append((best_acc, pre, rec, f1, mcc, sn, sp, auc, auprc))\n",
    "    print(f\"[Fold {fold}] æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}\")\n",
    "\n",
    "# æ±‡æ€»ç»“æœ\n",
    "all_metrics = np.array(all_metrics)\n",
    "print(\"\\n========== 10æŠ˜äº¤å‰éªŒè¯ç»“æœæ±‡æ€» ==========\")\n",
    "print(f\"å¹³å‡å‡†ç¡®ç‡: {all_metrics[:,0].mean():.4f} Â± {all_metrics[:,0].std():.4f}\")\n",
    "print(f\"å¹³å‡ç²¾ç¡®ç‡: {all_metrics[:,1].mean():.4f} Â± {all_metrics[:,1].std():.4f}\")\n",
    "print(f\"å¹³å‡å¬å›ç‡: {all_metrics[:,2].mean():.4f} Â± {all_metrics[:,2].std():.4f}\")\n",
    "print(f\"å¹³å‡F1åˆ†æ•°: {all_metrics[:,3].mean():.4f} Â± {all_metrics[:,3].std():.4f}\")\n",
    "print(f\"å¹³å‡MCC: {all_metrics[:,4].mean():.4f} Â± {all_metrics[:,4].std():.4f}\")\n",
    "print(f\"å¹³å‡æ•æ„Ÿæ€§(SN): {all_metrics[:,5].mean():.4f} Â± {all_metrics[:,5].std():.4f}\")\n",
    "print(f\"å¹³å‡ç‰¹å¼‚æ€§(SP): {all_metrics[:,6].mean():.4f} Â± {all_metrics[:,6].std():.4f}\")\n",
    "print(f\"å¹³å‡AUC: {all_metrics[:,7].mean():.4f} Â± {all_metrics[:,7].std():.4f}\")\n",
    "print(f\"å¹³å‡AUPRC: {all_metrics[:,8].mean():.4f} Â± {all_metrics[:,8].std():.4f}\") "
   ],
   "id": "790e5abf7006612e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/10 ==========\n",
      "\n",
      "[Fold 1] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.7336\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9176, ç²¾ç¡®ç‡: 0.8870, å¬å›ç‡: 0.9573, F1: 0.9208, MCC: 0.8377\n",
      "æ•æ„Ÿæ€§(SN): 0.9573, ç‰¹å¼‚æ€§(SP): 0.8777, AUC: 0.9727, AUPRC: 0.9660\n",
      "Fold 1 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 1] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3743\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9206, ç²¾ç¡®ç‡: 0.9207, å¬å›ç‡: 0.9207, F1: 0.9207, MCC: 0.8412\n",
      "æ•æ„Ÿæ€§(SN): 0.9207, ç‰¹å¼‚æ€§(SP): 0.9205, AUC: 0.9791, AUPRC: 0.9777\n",
      "Fold 1 ç¬¬ 2 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 1] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3609\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9130, ç²¾ç¡®ç‡: 0.9472, å¬å›ç‡: 0.8750, F1: 0.9097, MCC: 0.8284\n",
      "æ•æ„Ÿæ€§(SN): 0.8750, ç‰¹å¼‚æ€§(SP): 0.9511, AUC: 0.9787, AUPRC: 0.9764\n",
      "\n",
      "[Fold 1] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3552\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9282, ç²¾ç¡®ç‡: 0.8871, å¬å›ç‡: 0.9817, F1: 0.9320, MCC: 0.8614\n",
      "æ•æ„Ÿæ€§(SN): 0.9817, ç‰¹å¼‚æ€§(SP): 0.8746, AUC: 0.9811, AUPRC: 0.9749\n",
      "Fold 1 ç¬¬ 4 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 1] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3404\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9206, ç²¾ç¡®ç‡: 0.8943, å¬å›ç‡: 0.9543, F1: 0.9233, MCC: 0.8431\n",
      "æ•æ„Ÿæ€§(SN): 0.9543, ç‰¹å¼‚æ€§(SP): 0.8869, AUC: 0.9757, AUPRC: 0.9688\n",
      "\n",
      "[Fold 1] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3362\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9313, ç²¾ç¡®ç‡: 0.9101, å¬å›ç‡: 0.9573, F1: 0.9331, MCC: 0.8637\n",
      "æ•æ„Ÿæ€§(SN): 0.9573, ç‰¹å¼‚æ€§(SP): 0.9052, AUC: 0.9782, AUPRC: 0.9701\n",
      "Fold 1 ç¬¬ 6 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 1] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3225\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9328, ç²¾ç¡®ç‡: 0.9034, å¬å›ç‡: 0.9695, F1: 0.9353, MCC: 0.8680\n",
      "æ•æ„Ÿæ€§(SN): 0.9695, ç‰¹å¼‚æ€§(SP): 0.8960, AUC: 0.9756, AUPRC: 0.9600\n",
      "Fold 1 ç¬¬ 7 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 1] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3172\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9176, ç²¾ç¡®ç‡: 0.9335, å¬å›ç‡: 0.8994, F1: 0.9161, MCC: 0.8357\n",
      "æ•æ„Ÿæ€§(SN): 0.8994, ç‰¹å¼‚æ€§(SP): 0.9358, AUC: 0.9776, AUPRC: 0.9726\n",
      "\n",
      "[Fold 1] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3054\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9252, ç²¾ç¡®ç‡: 0.9043, å¬å›ç‡: 0.9512, F1: 0.9272, MCC: 0.8515\n",
      "æ•æ„Ÿæ€§(SN): 0.9512, ç‰¹å¼‚æ€§(SP): 0.8991, AUC: 0.9787, AUPRC: 0.9751\n",
      "\n",
      "[Fold 1] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.2861\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9252, ç²¾ç¡®ç‡: 0.9240, å¬å›ç‡: 0.9268, F1: 0.9254, MCC: 0.8504\n",
      "æ•æ„Ÿæ€§(SN): 0.9268, ç‰¹å¼‚æ€§(SP): 0.9235, AUC: 0.9772, AUPRC: 0.9721\n",
      "[Fold 1] æœ€ä½³å‡†ç¡®ç‡: 0.9328\n",
      "\n",
      "========== Fold 2/10 ==========\n",
      "\n",
      "[Fold 2] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.6946\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9420, ç²¾ç¡®ç‡: 0.9530, å¬å›ç‡: 0.9297, F1: 0.9412, MCC: 0.8842\n",
      "æ•æ„Ÿæ€§(SN): 0.9297, ç‰¹å¼‚æ€§(SP): 0.9543, AUC: 0.9855, AUPRC: 0.9776\n",
      "Fold 2 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 2] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3795\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9115, ç²¾ç¡®ç‡: 0.8530, å¬å›ç‡: 0.9939, F1: 0.9181, MCC: 0.8344\n",
      "æ•æ„Ÿæ€§(SN): 0.9939, ç‰¹å¼‚æ€§(SP): 0.8293, AUC: 0.9870, AUPRC: 0.9821\n",
      "\n",
      "[Fold 2] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3732\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9420, ç²¾ç¡®ç‡: 0.9140, å¬å›ç‡: 0.9755, F1: 0.9438, MCC: 0.8860\n",
      "æ•æ„Ÿæ€§(SN): 0.9755, ç‰¹å¼‚æ€§(SP): 0.9085, AUC: 0.9869, AUPRC: 0.9838\n",
      "\n",
      "[Fold 2] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3498\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9527, ç²¾ç¡®ç‡: 0.9405, å¬å›ç‡: 0.9664, F1: 0.9532, MCC: 0.9057\n",
      "æ•æ„Ÿæ€§(SN): 0.9664, ç‰¹å¼‚æ€§(SP): 0.9390, AUC: 0.9869, AUPRC: 0.9841\n",
      "Fold 2 ç¬¬ 4 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 2] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3453\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9496, ç²¾ç¡®ç‡: 0.9298, å¬å›ç‡: 0.9725, F1: 0.9507, MCC: 0.9002\n",
      "æ•æ„Ÿæ€§(SN): 0.9725, ç‰¹å¼‚æ€§(SP): 0.9268, AUC: 0.9849, AUPRC: 0.9817\n",
      "\n",
      "[Fold 2] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3256\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.8992, ç²¾ç¡®ç‡: 0.9336, å¬å›ç‡: 0.8593, F1: 0.8949, MCC: 0.8010\n",
      "æ•æ„Ÿæ€§(SN): 0.8593, ç‰¹å¼‚æ€§(SP): 0.9390, AUC: 0.9763, AUPRC: 0.9739\n",
      "\n",
      "[Fold 2] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3231\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9191, ç²¾ç¡®ç‡: 0.9597, å¬å›ç‡: 0.8746, F1: 0.9152, MCC: 0.8415\n",
      "æ•æ„Ÿæ€§(SN): 0.8746, ç‰¹å¼‚æ€§(SP): 0.9634, AUC: 0.9836, AUPRC: 0.9813\n",
      "\n",
      "[Fold 2] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3168\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9115, ç²¾ç¡®ç‡: 0.9622, å¬å›ç‡: 0.8563, F1: 0.9061, MCC: 0.8279\n",
      "æ•æ„Ÿæ€§(SN): 0.8563, ç‰¹å¼‚æ€§(SP): 0.9665, AUC: 0.9810, AUPRC: 0.9767\n",
      "\n",
      "[Fold 2] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3100\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9344, ç²¾ç¡®ç‡: 0.9610, å¬å›ç‡: 0.9052, F1: 0.9323, MCC: 0.8702\n",
      "æ•æ„Ÿæ€§(SN): 0.9052, ç‰¹å¼‚æ€§(SP): 0.9634, AUC: 0.9816, AUPRC: 0.9771\n",
      "\n",
      "[Fold 2] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.2960\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9176, ç²¾ç¡®ç‡: 0.9596, å¬å›ç‡: 0.8716, F1: 0.9135, MCC: 0.8386\n",
      "æ•æ„Ÿæ€§(SN): 0.8716, ç‰¹å¼‚æ€§(SP): 0.9634, AUC: 0.9817, AUPRC: 0.9795\n",
      "[Fold 2] æœ€ä½³å‡†ç¡®ç‡: 0.9527\n",
      "\n",
      "========== Fold 3/10 ==========\n",
      "\n",
      "[Fold 3] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.5004\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9205, ç²¾ç¡®ç‡: 0.9568, å¬å›ç‡: 0.8807, F1: 0.9172, MCC: 0.8436\n",
      "æ•æ„Ÿæ€§(SN): 0.8807, ç‰¹å¼‚æ€§(SP): 0.9602, AUC: 0.9789, AUPRC: 0.9753\n",
      "Fold 3 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 3] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3890\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.9430, å¬å›ç‡: 0.9113, F1: 0.9269, MCC: 0.8568\n",
      "æ•æ„Ÿæ€§(SN): 0.9113, ç‰¹å¼‚æ€§(SP): 0.9450, AUC: 0.9823, AUPRC: 0.9807\n",
      "Fold 3 ç¬¬ 2 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 3] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3592\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9266, ç²¾ç¡®ç‡: 0.9515, å¬å›ç‡: 0.8991, F1: 0.9245, MCC: 0.8545\n",
      "æ•æ„Ÿæ€§(SN): 0.8991, ç‰¹å¼‚æ€§(SP): 0.9541, AUC: 0.9839, AUPRC: 0.9826\n",
      "\n",
      "[Fold 3] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3496\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9266, ç²¾ç¡®ç‡: 0.9067, å¬å›ç‡: 0.9511, F1: 0.9284, MCC: 0.8542\n",
      "æ•æ„Ÿæ€§(SN): 0.9511, ç‰¹å¼‚æ€§(SP): 0.9021, AUC: 0.9811, AUPRC: 0.9791\n",
      "\n",
      "[Fold 3] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3535\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9373, ç²¾ç¡®ç‡: 0.9441, å¬å›ç‡: 0.9297, F1: 0.9368, MCC: 0.8747\n",
      "æ•æ„Ÿæ€§(SN): 0.9297, ç‰¹å¼‚æ€§(SP): 0.9450, AUC: 0.9849, AUPRC: 0.9851\n",
      "Fold 3 ç¬¬ 5 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 3] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3345\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9251, ç²¾ç¡®ç‡: 0.9572, å¬å›ç‡: 0.8899, F1: 0.9223, MCC: 0.8523\n",
      "æ•æ„Ÿæ€§(SN): 0.8899, ç‰¹å¼‚æ€§(SP): 0.9602, AUC: 0.9855, AUPRC: 0.9853\n",
      "\n",
      "[Fold 3] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3381\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9159, ç²¾ç¡®ç‡: 0.9595, å¬å›ç‡: 0.8685, F1: 0.9117, MCC: 0.8356\n",
      "æ•æ„Ÿæ€§(SN): 0.8685, ç‰¹å¼‚æ€§(SP): 0.9633, AUC: 0.9798, AUPRC: 0.9792\n",
      "\n",
      "[Fold 3] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3212\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9494, å¬å›ç‡: 0.9174, F1: 0.9331, MCC: 0.8690\n",
      "æ•æ„Ÿæ€§(SN): 0.9174, ç‰¹å¼‚æ€§(SP): 0.9511, AUC: 0.9838, AUPRC: 0.9848\n",
      "\n",
      "[Fold 3] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3075\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9297, ç²¾ç¡®ç‡: 0.9323, å¬å›ç‡: 0.9266, F1: 0.9294, MCC: 0.8593\n",
      "æ•æ„Ÿæ€§(SN): 0.9266, ç‰¹å¼‚æ€§(SP): 0.9327, AUC: 0.9821, AUPRC: 0.9821\n",
      "\n",
      "[Fold 3] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3073\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9465, å¬å›ç‡: 0.9205, F1: 0.9333, MCC: 0.8688\n",
      "æ•æ„Ÿæ€§(SN): 0.9205, ç‰¹å¼‚æ€§(SP): 0.9480, AUC: 0.9830, AUPRC: 0.9816\n",
      "[Fold 3] æœ€ä½³å‡†ç¡®ç‡: 0.9373\n",
      "\n",
      "========== Fold 4/10 ==========\n",
      "\n",
      "[Fold 4] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.5812\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9419, ç²¾ç¡®ç‡: 0.9164, å¬å›ç‡: 0.9725, F1: 0.9436, MCC: 0.8854\n",
      "æ•æ„Ÿæ€§(SN): 0.9725, ç‰¹å¼‚æ€§(SP): 0.9113, AUC: 0.9821, AUPRC: 0.9787\n",
      "Fold 4 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 4] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3806\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9205, ç²¾ç¡®ç‡: 0.8747, å¬å›ç‡: 0.9817, F1: 0.9251, MCC: 0.8473\n",
      "æ•æ„Ÿæ€§(SN): 0.9817, ç‰¹å¼‚æ€§(SP): 0.8593, AUC: 0.9844, AUPRC: 0.9801\n",
      "\n",
      "[Fold 4] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3636\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9404, ç²¾ç¡®ç‡: 0.9500, å¬å›ç‡: 0.9297, F1: 0.9397, MCC: 0.8809\n",
      "æ•æ„Ÿæ€§(SN): 0.9297, ç‰¹å¼‚æ€§(SP): 0.9511, AUC: 0.9842, AUPRC: 0.9793\n",
      "\n",
      "[Fold 4] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3449\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9404, ç²¾ç¡®ç‡: 0.9286, å¬å›ç‡: 0.9541, F1: 0.9412, MCC: 0.8811\n",
      "æ•æ„Ÿæ€§(SN): 0.9541, ç‰¹å¼‚æ€§(SP): 0.9266, AUC: 0.9844, AUPRC: 0.9814\n",
      "\n",
      "[Fold 4] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3446\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9434, ç²¾ç¡®ç‡: 0.9265, å¬å›ç‡: 0.9633, F1: 0.9445, MCC: 0.8876\n",
      "æ•æ„Ÿæ€§(SN): 0.9633, ç‰¹å¼‚æ€§(SP): 0.9235, AUC: 0.9832, AUPRC: 0.9793\n",
      "Fold 4 ç¬¬ 5 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 4] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3329\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9404, ç²¾ç¡®ç‡: 0.9311, å¬å›ç‡: 0.9511, F1: 0.9410, MCC: 0.8809\n",
      "æ•æ„Ÿæ€§(SN): 0.9511, ç‰¹å¼‚æ€§(SP): 0.9297, AUC: 0.9837, AUPRC: 0.9814\n",
      "\n",
      "[Fold 4] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3304\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9266, ç²¾ç¡®ç‡: 0.9401, å¬å›ç‡: 0.9113, F1: 0.9255, MCC: 0.8536\n",
      "æ•æ„Ÿæ€§(SN): 0.9113, ç‰¹å¼‚æ€§(SP): 0.9419, AUC: 0.9778, AUPRC: 0.9736\n",
      "\n",
      "[Fold 4] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3171\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.9462, å¬å›ç‡: 0.9144, F1: 0.9300, MCC: 0.8629\n",
      "æ•æ„Ÿæ€§(SN): 0.9144, ç‰¹å¼‚æ€§(SP): 0.9480, AUC: 0.9778, AUPRC: 0.9725\n",
      "\n",
      "[Fold 4] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3050\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9266, ç²¾ç¡®ç‡: 0.9401, å¬å›ç‡: 0.9113, F1: 0.9255, MCC: 0.8536\n",
      "æ•æ„Ÿæ€§(SN): 0.9113, ç‰¹å¼‚æ€§(SP): 0.9419, AUC: 0.9766, AUPRC: 0.9697\n",
      "\n",
      "[Fold 4] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3006\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9128, ç²¾ç¡®ç‡: 0.8668, å¬å›ç‡: 0.9755, F1: 0.9180, MCC: 0.8323\n",
      "æ•æ„Ÿæ€§(SN): 0.9755, ç‰¹å¼‚æ€§(SP): 0.8502, AUC: 0.9759, AUPRC: 0.9704\n",
      "[Fold 4] æœ€ä½³å‡†ç¡®ç‡: 0.9434\n",
      "\n",
      "========== Fold 5/10 ==========\n",
      "\n",
      "[Fold 5] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.5659\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9251, ç²¾ç¡®ç‡: 0.9162, å¬å›ç‡: 0.9358, F1: 0.9259, MCC: 0.8503\n",
      "æ•æ„Ÿæ€§(SN): 0.9358, ç‰¹å¼‚æ€§(SP): 0.9144, AUC: 0.9800, AUPRC: 0.9751\n",
      "Fold 5 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 5] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3716\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9266, ç²¾ç¡®ç‡: 0.8997, å¬å›ç‡: 0.9602, F1: 0.9290, MCC: 0.8551\n",
      "æ•æ„Ÿæ€§(SN): 0.9602, ç‰¹å¼‚æ€§(SP): 0.8930, AUC: 0.9813, AUPRC: 0.9779\n",
      "Fold 5 ç¬¬ 2 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 5] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3626\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9205, ç²¾ç¡®ç‡: 0.8873, å¬å›ç‡: 0.9633, F1: 0.9238, MCC: 0.8441\n",
      "æ•æ„Ÿæ€§(SN): 0.9633, ç‰¹å¼‚æ€§(SP): 0.8777, AUC: 0.9802, AUPRC: 0.9761\n",
      "\n",
      "[Fold 5] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3556\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9034, å¬å›ç‡: 0.9725, F1: 0.9367, MCC: 0.8711\n",
      "æ•æ„Ÿæ€§(SN): 0.9725, ç‰¹å¼‚æ€§(SP): 0.8960, AUC: 0.9822, AUPRC: 0.9772\n",
      "Fold 5 ç¬¬ 4 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 5] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3380\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9220, ç²¾ç¡®ç‡: 0.8898, å¬å›ç‡: 0.9633, F1: 0.9251, MCC: 0.8469\n",
      "æ•æ„Ÿæ€§(SN): 0.9633, ç‰¹å¼‚æ€§(SP): 0.8807, AUC: 0.9745, AUPRC: 0.9660\n",
      "\n",
      "[Fold 5] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3381\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9404, ç²¾ç¡®ç‡: 0.9337, å¬å›ç‡: 0.9480, F1: 0.9408, MCC: 0.8808\n",
      "æ•æ„Ÿæ€§(SN): 0.9480, ç‰¹å¼‚æ€§(SP): 0.9327, AUC: 0.9838, AUPRC: 0.9816\n",
      "Fold 5 ç¬¬ 6 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 5] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3227\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9144, ç²¾ç¡®ç‡: 0.8774, å¬å›ç‡: 0.9633, F1: 0.9184, MCC: 0.8327\n",
      "æ•æ„Ÿæ€§(SN): 0.9633, ç‰¹å¼‚æ€§(SP): 0.8654, AUC: 0.9790, AUPRC: 0.9707\n",
      "\n",
      "[Fold 5] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3131\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9204, å¬å›ç‡: 0.9541, F1: 0.9369, MCC: 0.8721\n",
      "æ•æ„Ÿæ€§(SN): 0.9541, ç‰¹å¼‚æ€§(SP): 0.9174, AUC: 0.9810, AUPRC: 0.9768\n",
      "\n",
      "[Fold 5] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3076\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9204, å¬å›ç‡: 0.9541, F1: 0.9369, MCC: 0.8721\n",
      "æ•æ„Ÿæ€§(SN): 0.9541, ç‰¹å¼‚æ€§(SP): 0.9174, AUC: 0.9842, AUPRC: 0.9814\n",
      "\n",
      "[Fold 5] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.2993\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.9142, å¬å›ç‡: 0.9450, F1: 0.9293, MCC: 0.8568\n",
      "æ•æ„Ÿæ€§(SN): 0.9450, ç‰¹å¼‚æ€§(SP): 0.9113, AUC: 0.9815, AUPRC: 0.9791\n",
      "[Fold 5] æœ€ä½³å‡†ç¡®ç‡: 0.9404\n",
      "\n",
      "========== Fold 6/10 ==========\n",
      "\n",
      "[Fold 6] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.6475\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9404, ç²¾ç¡®ç‡: 0.9586, å¬å›ç‡: 0.9205, F1: 0.9392, MCC: 0.8814\n",
      "æ•æ„Ÿæ€§(SN): 0.9205, ç‰¹å¼‚æ€§(SP): 0.9602, AUC: 0.9854, AUPRC: 0.9848\n",
      "Fold 6 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 6] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3829\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9201, å¬å›ç‡: 0.9511, F1: 0.9353, MCC: 0.8690\n",
      "æ•æ„Ÿæ€§(SN): 0.9511, ç‰¹å¼‚æ€§(SP): 0.9174, AUC: 0.9868, AUPRC: 0.9867\n",
      "\n",
      "[Fold 6] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3668\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9373, ç²¾ç¡®ç‡: 0.9256, å¬å›ç‡: 0.9511, F1: 0.9382, MCC: 0.8749\n",
      "æ•æ„Ÿæ€§(SN): 0.9511, ç‰¹å¼‚æ€§(SP): 0.9235, AUC: 0.9868, AUPRC: 0.9863\n",
      "\n",
      "[Fold 6] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3562\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9495, å¬å›ç‡: 0.9205, F1: 0.9348, MCC: 0.8720\n",
      "æ•æ„Ÿæ€§(SN): 0.9205, ç‰¹å¼‚æ€§(SP): 0.9511, AUC: 0.9861, AUPRC: 0.9853\n",
      "\n",
      "[Fold 6] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3476\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9450, ç²¾ç¡®ç‡: 0.9533, å¬å›ç‡: 0.9358, F1: 0.9444, MCC: 0.8901\n",
      "æ•æ„Ÿæ€§(SN): 0.9358, ç‰¹å¼‚æ€§(SP): 0.9541, AUC: 0.9885, AUPRC: 0.9884\n",
      "Fold 6 ç¬¬ 5 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 6] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3394\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.9462, å¬å›ç‡: 0.9144, F1: 0.9300, MCC: 0.8629\n",
      "æ•æ„Ÿæ€§(SN): 0.9144, ç‰¹å¼‚æ€§(SP): 0.9480, AUC: 0.9861, AUPRC: 0.9857\n",
      "\n",
      "[Fold 6] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3310\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.9548, å¬å›ç‡: 0.9052, F1: 0.9294, MCC: 0.8636\n",
      "æ•æ„Ÿæ€§(SN): 0.9052, ç‰¹å¼‚æ€§(SP): 0.9572, AUC: 0.9854, AUPRC: 0.9857\n",
      "\n",
      "[Fold 6] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3275\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9434, ç²¾ç¡®ç‡: 0.9448, å¬å›ç‡: 0.9419, F1: 0.9433, MCC: 0.8869\n",
      "æ•æ„Ÿæ€§(SN): 0.9419, ç‰¹å¼‚æ€§(SP): 0.9450, AUC: 0.9827, AUPRC: 0.9823\n",
      "\n",
      "[Fold 6] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3171\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9582, å¬å›ç‡: 0.9113, F1: 0.9342, MCC: 0.8726\n",
      "æ•æ„Ÿæ€§(SN): 0.9113, ç‰¹å¼‚æ€§(SP): 0.9602, AUC: 0.9840, AUPRC: 0.9831\n",
      "\n",
      "[Fold 6] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3175\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9388, ç²¾ç¡®ç‡: 0.9498, å¬å›ç‡: 0.9266, F1: 0.9381, MCC: 0.8779\n",
      "æ•æ„Ÿæ€§(SN): 0.9266, ç‰¹å¼‚æ€§(SP): 0.9511, AUC: 0.9849, AUPRC: 0.9856\n",
      "[Fold 6] æœ€ä½³å‡†ç¡®ç‡: 0.9450\n",
      "\n",
      "========== Fold 7/10 ==========\n",
      "\n",
      "[Fold 7] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.5406\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.9029, å¬å›ç‡: 0.9664, F1: 0.9335, MCC: 0.8645\n",
      "æ•æ„Ÿæ€§(SN): 0.9664, ç‰¹å¼‚æ€§(SP): 0.8960, AUC: 0.9790, AUPRC: 0.9749\n",
      "Fold 7 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 7] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3863\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.9046, å¬å›ç‡: 0.9572, F1: 0.9302, MCC: 0.8577\n",
      "æ•æ„Ÿæ€§(SN): 0.9572, ç‰¹å¼‚æ€§(SP): 0.8991, AUC: 0.9806, AUPRC: 0.9796\n",
      "\n",
      "[Fold 7] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3604\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9220, ç²¾ç¡®ç‡: 0.9233, å¬å›ç‡: 0.9205, F1: 0.9219, MCC: 0.8440\n",
      "æ•æ„Ÿæ€§(SN): 0.9205, ç‰¹å¼‚æ€§(SP): 0.9235, AUC: 0.9798, AUPRC: 0.9764\n",
      "\n",
      "[Fold 7] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3554\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.9242, å¬å›ç‡: 0.9327, F1: 0.9285, MCC: 0.8563\n",
      "æ•æ„Ÿæ€§(SN): 0.9327, ç‰¹å¼‚æ€§(SP): 0.9235, AUC: 0.9811, AUPRC: 0.9787\n",
      "\n",
      "[Fold 7] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3493\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9388, ç²¾ç¡®ç‡: 0.9335, å¬å›ç‡: 0.9450, F1: 0.9392, MCC: 0.8777\n",
      "æ•æ„Ÿæ€§(SN): 0.9450, ç‰¹å¼‚æ€§(SP): 0.9327, AUC: 0.9796, AUPRC: 0.9749\n",
      "Fold 7 ç¬¬ 5 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 7] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3330\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.9000, å¬å›ç‡: 0.9633, F1: 0.9306, MCC: 0.8584\n",
      "æ•æ„Ÿæ€§(SN): 0.9633, ç‰¹å¼‚æ€§(SP): 0.8930, AUC: 0.9805, AUPRC: 0.9783\n",
      "\n",
      "[Fold 7] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3320\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9412, å¬å›ç‡: 0.9297, F1: 0.9354, MCC: 0.8716\n",
      "æ•æ„Ÿæ€§(SN): 0.9297, ç‰¹å¼‚æ€§(SP): 0.9419, AUC: 0.9801, AUPRC: 0.9770\n",
      "\n",
      "[Fold 7] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3171\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9144, ç²¾ç¡®ç‡: 0.9625, å¬å›ç‡: 0.8624, F1: 0.9097, MCC: 0.8333\n",
      "æ•æ„Ÿæ€§(SN): 0.8624, ç‰¹å¼‚æ€§(SP): 0.9664, AUC: 0.9808, AUPRC: 0.9729\n",
      "\n",
      "[Fold 7] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3141\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9130, å¬å›ç‡: 0.9633, F1: 0.9375, MCC: 0.8729\n",
      "æ•æ„Ÿæ€§(SN): 0.9633, ç‰¹å¼‚æ€§(SP): 0.9083, AUC: 0.9795, AUPRC: 0.9716\n",
      "\n",
      "[Fold 7] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.2964\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.9147, å¬å›ç‡: 0.9511, F1: 0.9325, MCC: 0.8631\n",
      "æ•æ„Ÿæ€§(SN): 0.9511, ç‰¹å¼‚æ€§(SP): 0.9113, AUC: 0.9731, AUPRC: 0.9595\n",
      "[Fold 7] æœ€ä½³å‡†ç¡®ç‡: 0.9388\n",
      "\n",
      "========== Fold 8/10 ==========\n",
      "\n",
      "[Fold 8] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.5265\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.8977, å¬å›ç‡: 0.9664, F1: 0.9308, MCC: 0.8588\n",
      "æ•æ„Ÿæ€§(SN): 0.9664, ç‰¹å¼‚æ€§(SP): 0.8899, AUC: 0.9798, AUPRC: 0.9784\n",
      "Fold 8 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 8] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3893\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9297, ç²¾ç¡®ç‡: 0.9194, å¬å›ç‡: 0.9419, F1: 0.9305, MCC: 0.8596\n",
      "æ•æ„Ÿæ€§(SN): 0.9419, ç‰¹å¼‚æ€§(SP): 0.9174, AUC: 0.9829, AUPRC: 0.9817\n",
      "Fold 8 ç¬¬ 2 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 8] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3647\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.9467, å¬å›ç‡: 0.9235, F1: 0.9350, MCC: 0.8718\n",
      "æ•æ„Ÿæ€§(SN): 0.9235, ç‰¹å¼‚æ€§(SP): 0.9480, AUC: 0.9826, AUPRC: 0.9817\n",
      "Fold 8 ç¬¬ 3 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 8] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3612\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.8939, å¬å›ç‡: 0.9786, F1: 0.9343, MCC: 0.8663\n",
      "æ•æ„Ÿæ€§(SN): 0.9786, ç‰¹å¼‚æ€§(SP): 0.8838, AUC: 0.9815, AUPRC: 0.9764\n",
      "\n",
      "[Fold 8] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3441\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9388, ç²¾ç¡®ç‡: 0.9159, å¬å›ç‡: 0.9664, F1: 0.9405, MCC: 0.8790\n",
      "æ•æ„Ÿæ€§(SN): 0.9664, ç‰¹å¼‚æ€§(SP): 0.9113, AUC: 0.9823, AUPRC: 0.9763\n",
      "Fold 8 ç¬¬ 5 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 8] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3541\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9404, ç²¾ç¡®ç‡: 0.9186, å¬å›ç‡: 0.9664, F1: 0.9419, MCC: 0.8819\n",
      "æ•æ„Ÿæ€§(SN): 0.9664, ç‰¹å¼‚æ€§(SP): 0.9144, AUC: 0.9854, AUPRC: 0.9837\n",
      "Fold 8 ç¬¬ 6 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 8] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3265\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9358, ç²¾ç¡®ç‡: 0.8969, å¬å›ç‡: 0.9847, F1: 0.9388, MCC: 0.8758\n",
      "æ•æ„Ÿæ€§(SN): 0.9847, ç‰¹å¼‚æ€§(SP): 0.8869, AUC: 0.9859, AUPRC: 0.9848\n",
      "\n",
      "[Fold 8] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3273\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.8930, ç²¾ç¡®ç‡: 0.9707, å¬å›ç‡: 0.8104, F1: 0.8833, MCC: 0.7969\n",
      "æ•æ„Ÿæ€§(SN): 0.8104, ç‰¹å¼‚æ€§(SP): 0.9755, AUC: 0.9847, AUPRC: 0.9838\n",
      "\n",
      "[Fold 8] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3130\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9235, ç²¾ç¡®ç‡: 0.8946, å¬å›ç‡: 0.9602, F1: 0.9263, MCC: 0.8494\n",
      "æ•æ„Ÿæ€§(SN): 0.9602, ç‰¹å¼‚æ€§(SP): 0.8869, AUC: 0.9767, AUPRC: 0.9745\n",
      "\n",
      "[Fold 8] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3110\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9220, ç²¾ç¡®ç‡: 0.8988, å¬å›ç‡: 0.9511, F1: 0.9242, MCC: 0.8455\n",
      "æ•æ„Ÿæ€§(SN): 0.9511, ç‰¹å¼‚æ€§(SP): 0.8930, AUC: 0.9763, AUPRC: 0.9706\n",
      "[Fold 8] æœ€ä½³å‡†ç¡®ç‡: 0.9404\n",
      "\n",
      "========== Fold 9/10 ==========\n",
      "\n",
      "[Fold 9] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.6587\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9159, ç²¾ç¡®ç‡: 0.8820, å¬å›ç‡: 0.9602, F1: 0.9195, MCC: 0.8351\n",
      "æ•æ„Ÿæ€§(SN): 0.9602, ç‰¹å¼‚æ€§(SP): 0.8716, AUC: 0.9715, AUPRC: 0.9647\n",
      "Fold 9 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 9] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3730\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9052, ç²¾ç¡®ç‡: 0.8591, å¬å›ç‡: 0.9694, F1: 0.9109, MCC: 0.8172\n",
      "æ•æ„Ÿæ€§(SN): 0.9694, ç‰¹å¼‚æ€§(SP): 0.8410, AUC: 0.9748, AUPRC: 0.9657\n",
      "\n",
      "[Fold 9] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3776\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9327, ç²¾ç¡®ç‡: 0.9224, å¬å›ç‡: 0.9450, F1: 0.9335, MCC: 0.8657\n",
      "æ•æ„Ÿæ€§(SN): 0.9450, ç‰¹å¼‚æ€§(SP): 0.9205, AUC: 0.9776, AUPRC: 0.9671\n",
      "Fold 9 ç¬¬ 3 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 9] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3428\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9388, ç²¾ç¡®ç‡: 0.9470, å¬å›ç‡: 0.9297, F1: 0.9383, MCC: 0.8778\n",
      "æ•æ„Ÿæ€§(SN): 0.9297, ç‰¹å¼‚æ€§(SP): 0.9480, AUC: 0.9754, AUPRC: 0.9630\n",
      "Fold 9 ç¬¬ 4 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 9] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3419\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9251, ç²¾ç¡®ç‡: 0.9399, å¬å›ç‡: 0.9083, F1: 0.9238, MCC: 0.8506\n",
      "æ•æ„Ÿæ€§(SN): 0.9083, ç‰¹å¼‚æ€§(SP): 0.9419, AUC: 0.9759, AUPRC: 0.9640\n",
      "\n",
      "[Fold 9] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3293\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9303, å¬å›ç‡: 0.9388, F1: 0.9346, MCC: 0.8685\n",
      "æ•æ„Ÿæ€§(SN): 0.9388, ç‰¹å¼‚æ€§(SP): 0.9297, AUC: 0.9760, AUPRC: 0.9720\n",
      "\n",
      "[Fold 9] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3313\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9522, å¬å›ç‡: 0.9144, F1: 0.9329, MCC: 0.8692\n",
      "æ•æ„Ÿæ€§(SN): 0.9144, ç‰¹å¼‚æ€§(SP): 0.9541, AUC: 0.9764, AUPRC: 0.9611\n",
      "\n",
      "[Fold 9] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3145\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9343, ç²¾ç¡®ç‡: 0.9551, å¬å›ç‡: 0.9113, F1: 0.9327, MCC: 0.8694\n",
      "æ•æ„Ÿæ€§(SN): 0.9113, ç‰¹å¼‚æ€§(SP): 0.9572, AUC: 0.9770, AUPRC: 0.9701\n",
      "\n",
      "[Fold 9] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3149\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9174, ç²¾ç¡®ç‡: 0.8845, å¬å›ç‡: 0.9602, F1: 0.9208, MCC: 0.8379\n",
      "æ•æ„Ÿæ€§(SN): 0.9602, ç‰¹å¼‚æ€§(SP): 0.8746, AUC: 0.9751, AUPRC: 0.9644\n",
      "\n",
      "[Fold 9] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3095\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9128, ç²¾ç¡®ç‡: 0.9623, å¬å›ç‡: 0.8593, F1: 0.9079, MCC: 0.8305\n",
      "æ•æ„Ÿæ€§(SN): 0.8593, ç‰¹å¼‚æ€§(SP): 0.9664, AUC: 0.9755, AUPRC: 0.9671\n",
      "[Fold 9] æœ€ä½³å‡†ç¡®ç‡: 0.9388\n",
      "\n",
      "========== Fold 10/10 ==========\n",
      "\n",
      "[Fold 10] Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.5349\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9251, ç²¾ç¡®ç‡: 0.9427, å¬å›ç‡: 0.9052, F1: 0.9236, MCC: 0.8508\n",
      "æ•æ„Ÿæ€§(SN): 0.9052, ç‰¹å¼‚æ€§(SP): 0.9450, AUC: 0.9797, AUPRC: 0.9790\n",
      "Fold 10 ç¬¬ 1 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 10] Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3829\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9297, ç²¾ç¡®ç‡: 0.9297, å¬å›ç‡: 0.9297, F1: 0.9297, MCC: 0.8593\n",
      "æ•æ„Ÿæ€§(SN): 0.9297, ç‰¹å¼‚æ€§(SP): 0.9297, AUC: 0.9822, AUPRC: 0.9825\n",
      "Fold 10 ç¬¬ 2 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 10] Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3651\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9235, ç²¾ç¡®ç‡: 0.9086, å¬å›ç‡: 0.9419, F1: 0.9249, MCC: 0.8477\n",
      "æ•æ„Ÿæ€§(SN): 0.9419, ç‰¹å¼‚æ€§(SP): 0.9052, AUC: 0.9818, AUPRC: 0.9822\n",
      "\n",
      "[Fold 10] Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3534\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9205, ç²¾ç¡®ç‡: 0.9393, å¬å›ç‡: 0.8991, F1: 0.9187, MCC: 0.8418\n",
      "æ•æ„Ÿæ€§(SN): 0.8991, ç‰¹å¼‚æ€§(SP): 0.9419, AUC: 0.9823, AUPRC: 0.9826\n",
      "\n",
      "[Fold 10] Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3394\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9312, ç²¾ç¡®ç‡: 0.9075, å¬å›ç‡: 0.9602, F1: 0.9331, MCC: 0.8638\n",
      "æ•æ„Ÿæ€§(SN): 0.9602, ç‰¹å¼‚æ€§(SP): 0.9021, AUC: 0.9817, AUPRC: 0.9816\n",
      "Fold 10 ç¬¬ 5 è½®çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜\n",
      "\n",
      "[Fold 10] Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3361\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9190, ç²¾ç¡®ç‡: 0.8870, å¬å›ç‡: 0.9602, F1: 0.9222, MCC: 0.8408\n",
      "æ•æ„Ÿæ€§(SN): 0.9602, ç‰¹å¼‚æ€§(SP): 0.8777, AUC: 0.9823, AUPRC: 0.9829\n",
      "\n",
      "[Fold 10] Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3184\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9281, ç²¾ç¡®ç‡: 0.9321, å¬å›ç‡: 0.9235, F1: 0.9278, MCC: 0.8563\n",
      "æ•æ„Ÿæ€§(SN): 0.9235, ç‰¹å¼‚æ€§(SP): 0.9327, AUC: 0.9810, AUPRC: 0.9815\n",
      "\n",
      "[Fold 10] Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3160\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9174, ç²¾ç¡®ç‡: 0.9003, å¬å›ç‡: 0.9388, F1: 0.9192, MCC: 0.8356\n",
      "æ•æ„Ÿæ€§(SN): 0.9388, ç‰¹å¼‚æ€§(SP): 0.8960, AUC: 0.9783, AUPRC: 0.9768\n",
      "\n",
      "[Fold 10] Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3104\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9251, ç²¾ç¡®ç‡: 0.9137, å¬å›ç‡: 0.9388, F1: 0.9261, MCC: 0.8505\n",
      "æ•æ„Ÿæ€§(SN): 0.9388, ç‰¹å¼‚æ€§(SP): 0.9113, AUC: 0.9810, AUPRC: 0.9800\n",
      "\n",
      "[Fold 10] Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/3640366437.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒæŸå¤±: 1.3063\n",
      "éªŒè¯å‡†ç¡®ç‡: 0.9297, ç²¾ç¡®ç‡: 0.9271, å¬å›ç‡: 0.9327, F1: 0.9299, MCC: 0.8593\n",
      "æ•æ„Ÿæ€§(SN): 0.9327, ç‰¹å¼‚æ€§(SP): 0.9266, AUC: 0.9765, AUPRC: 0.9724\n",
      "[Fold 10] æœ€ä½³å‡†ç¡®ç‡: 0.9312\n",
      "\n",
      "========== 10æŠ˜äº¤å‰éªŒè¯ç»“æœæ±‡æ€» ==========\n",
      "å¹³å‡å‡†ç¡®ç‡: 0.9401 Â± 0.0058\n",
      "å¹³å‡ç²¾ç¡®ç‡: 0.9264 Â± 0.0282\n",
      "å¹³å‡å¬å›ç‡: 0.9260 Â± 0.0340\n",
      "å¹³å‡F1åˆ†æ•°: 0.9252 Â± 0.0090\n",
      "å¹³å‡MCC: 0.8523 Â± 0.0149\n",
      "å¹³å‡æ•æ„Ÿæ€§(SN): 0.9260 Â± 0.0340\n",
      "å¹³å‡ç‰¹å¼‚æ€§(SP): 0.9245 Â± 0.0338\n",
      "å¹³å‡AUC: 0.9786 Â± 0.0037\n",
      "å¹³å‡AUPRC: 0.9738 Â± 0.0073\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### åæŠ˜æµ‹è¯•ç»“æœ",
   "id": "89497dfa96a1f83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T10:38:22.872219Z",
     "start_time": "2025-07-09T10:30:46.923237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# æµ‹è¯•é›†\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    return acc, pre, rec, f1, mcc\n",
    "\n",
    "# è¯„ä¼°æ¯ä¸€æŠ˜\n",
    "all_metrics = []\n",
    "for fold in range(1, 11):\n",
    "    print(f\"\\n========== Test Fold {fold}/10 ==========\")\n",
    "    model = TransformerMoE(\n",
    "        d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    "    ).to(device)\n",
    "    model.load_state_dict(torch.load(f\"/exp_data/sjx/star/main_transformer_moe_weight/cv_point/best_fold{fold}.pth\", map_location=device))\n",
    "    acc, pre, rec, f1, mcc = eval_model(model, test_loader, device)\n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    all_metrics.append((acc, pre, rec, f1, mcc))\n",
    "\n",
    "# æ±‡æ€»å¹³å‡\n",
    "all_metrics = np.array(all_metrics)\n",
    "print(\"\\n========== 10-Fold Test Results ==========\")\n",
    "print(f\"Mean ACC: {all_metrics[:,0].mean():.4f} Â± {all_metrics[:,0].std():.4f}\")\n",
    "print(f\"Mean PRE: {all_metrics[:,1].mean():.4f}\")\n",
    "print(f\"Mean REC: {all_metrics[:,2].mean():.4f}\")\n",
    "print(f\"Mean F1:  {all_metrics[:,3].mean():.4f}\")\n",
    "print(f\"Mean MCC: {all_metrics[:,4].mean():.4f}\")"
   ],
   "id": "5d6b965da9085033",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### æ›´å¤šæŒ‡æ ‡å¾—æµ‹è¯•",
   "id": "1eb067946eff7a17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:40:44.635943Z",
     "start_time": "2025-07-20T05:40:20.827228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# å‡è®¾æ¨¡å‹ç»“æ„å’ŒProteinNPYDatasetå·²å®šä¹‰ï¼Œdeviceå·²è®¾ç½®\n",
    "import torch\n",
    "\n",
    "# 1. åŠ è½½æ¨¡å‹\n",
    "model = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2. åŠ è½½æµ‹è¯•é›†\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 3. å®šä¹‰è¯„ä¼°å‡½æ•°\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # æ­£ç±»æ¦‚ç‡\n",
    "    \n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef,\n",
    "        confusion_matrix, roc_auc_score, average_precision_score\n",
    "    )\n",
    "    \n",
    "    # è®¡ç®—æ··æ·†çŸ©é˜µ\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    sn = tp / (tp + fn) if (tp + fn) > 0 else 0  # æ•æ„Ÿæ€§\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0  # ç‰¹å¼‚æ€§\n",
    "    \n",
    "    print(f\"Test ACC: {acc:.4f}, PRE: {pre:.4f}, REC: {rec:.4f}, F1: {f1:.4f}, MCC: {mcc:.4f}\")\n",
    "    print(f\"Test AUC: {auc:.4f}, AUPRC: {auprc:.4f}, SN: {sn:.4f}, SP: {sp:.4f}\")\n",
    "    return acc, pre, rec, f1, mcc, auc, auprc, sn, sp\n",
    "\n",
    "# 4. æµ‹è¯•\n",
    "eval_model(model, test_loader, device)"
   ],
   "id": "3037e3e21d7ecd47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_471072/1171368709.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9225, PRE: 0.9483, REC: 0.9425, F1: 0.9454, MCC: 0.8120\n",
      "Test AUC: 0.9685, AUPRC: 0.9869, SN: 0.9425, SP: 0.8731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9225413402959095,\n",
       " 0.948339483394834,\n",
       " 0.9425427872860636,\n",
       " 0.9454322501532803,\n",
       " 0.8120485793877618,\n",
       " 0.9685438657398856,\n",
       " 0.9869455888266454,\n",
       " 0.9425427872860636,\n",
       " 0.8731117824773413)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
