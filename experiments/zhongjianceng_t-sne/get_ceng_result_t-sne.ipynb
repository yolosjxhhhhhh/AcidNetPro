{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-21T14:23:49.814930Z",
     "start_time": "2025-07-21T14:23:24.405063Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置中文字体\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "# 自动检测可用的中文字体\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 创建保存目录\n",
    "save_dir = '/exp_data/sjx/star/experiments/zhongjianceng_umap/ceng_results/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "73e9d5fcb460467c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:23:49.823651Z",
     "start_time": "2025-07-21T14:23:49.817994Z"
    }
   },
   "source": [
    "class ProteinNPYDataset(Dataset):\n",
    "    def __init__(self, pos_path, neg_path):\n",
    "        self.pos = np.load(pos_path, mmap_mode='r')\n",
    "        self.neg = np.load(neg_path, mmap_mode='r')\n",
    "        self.lengths = [len(self.pos), len(self.neg)]\n",
    "        self.total_len = self.lengths[0] + self.lengths[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.lengths[0]:\n",
    "            x = self.pos[idx]\n",
    "            y = 1\n",
    "        else:\n",
    "            x = self.neg[idx - self.lengths[0]]\n",
    "            y = 0\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e664146bf515010d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:23:49.866882Z",
     "start_time": "2025-07-21T14:23:49.825217Z"
    }
   },
   "source": [
    "class MLPExperts(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.fc1 = nn.Linear(d_model, d_ff * num_experts, bias=True)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model, bias=True)\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "    def forward(self, x, expert_idx):\n",
    "        all_hidden = self.fc1(x)\n",
    "        all_hidden = all_hidden.view(x.size(0), self.num_experts, self.d_ff)\n",
    "        out = []\n",
    "        for i in range(expert_idx.size(1)):\n",
    "            idx = expert_idx[:, i]\n",
    "            hidden = all_hidden[torch.arange(x.size(0)), idx]\n",
    "            hidden = F.gelu(hidden)\n",
    "            out_i = self.fc2(hidden)\n",
    "            out.append(out_i)\n",
    "        out = torch.stack(out, dim=1)\n",
    "        return out\n",
    "\n",
    "class NoisyTopKMoE(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts=30, k=2, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.k = k\n",
    "        self.noisy_std = noisy_std\n",
    "        self.experts = MLPExperts(d_model, d_ff, num_experts)\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, L, D = x.shape\n",
    "        x_flat = x.reshape(-1, D)\n",
    "        gate_logits = self.gate(x_flat)\n",
    "        if self.training and self.noisy_std > 0:\n",
    "            noise = torch.randn_like(gate_logits) * self.noisy_std\n",
    "            gate_logits = gate_logits + noise\n",
    "        gate_scores = F.softmax(gate_logits, dim=-1)\n",
    "        topk_val, topk_idx = torch.topk(gate_scores, self.k, dim=-1)\n",
    "        meangate = gate_scores.mean(dim=0)\n",
    "        load_balance_loss = (meangate * meangate).sum() * (self.num_experts ** 2)\n",
    "        expert_outs = self.experts(x_flat, topk_idx)\n",
    "        topk_val = topk_val / (topk_val.sum(dim=-1, keepdim=True) + 1e-9)\n",
    "        moe_out = (expert_outs * topk_val.unsqueeze(-1)).sum(dim=1)\n",
    "        moe_out = moe_out.view(B, L, D)\n",
    "        return moe_out, load_balance_loss\n",
    "\n",
    "class TransformerMoEBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, num_experts=30, k=2, dropout=0.1, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.moe = NoisyTopKMoE(d_model, d_ff, num_experts, k, noisy_std)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        moe_out, load_balance_loss = self.moe(x)\n",
    "        x = x + self.dropout(moe_out)\n",
    "        x = self.norm2(x)\n",
    "        return x, load_balance_loss\n",
    "\n",
    "class TransformerMoE(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerMoEBlock(d_model, nhead, d_ff, num_experts, k, dropout, noisy_std)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        total_load_balance_loss = 0\n",
    "        for layer in self.layers:\n",
    "            x, lb_loss = layer(x)\n",
    "            total_load_balance_loss += lb_loss\n",
    "        x = x.mean(dim=1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits, total_load_balance_loss"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ef09144e937304d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:23:49.876332Z",
     "start_time": "2025-07-21T14:23:49.870021Z"
    }
   },
   "source": [
    "class LayerOutputHook:\n",
    "    def __init__(self):\n",
    "        self.layer_outputs = []\n",
    "        self.hooks = []\n",
    "        \n",
    "    def register_hooks(self, model):\n",
    "        \"\"\"为模型注册hooks，不修改原始模型\"\"\"\n",
    "        self.clear_hooks()\n",
    "        \n",
    "        # 为每层注册hook\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            def make_hook(layer_idx):\n",
    "                def hook(module, input, output):\n",
    "                    # output是(x, load_balance_loss)的元组\n",
    "                    layer_output = output[0].detach().cpu()  # 只取x，不要loss\n",
    "                    self.layer_outputs.append(layer_output)\n",
    "                return hook\n",
    "            \n",
    "            hook = layer.register_forward_hook(make_hook(i))\n",
    "            self.hooks.append(hook)\n",
    "    \n",
    "    def clear_hooks(self):\n",
    "        \"\"\"清除所有hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "        self.layer_outputs = []\n",
    "    \n",
    "    def get_outputs(self):\n",
    "        \"\"\"获取当前batch的层输出\"\"\"\n",
    "        outputs = self.layer_outputs.copy()\n",
    "        self.layer_outputs = []  # 清空，为下一个batch准备\n",
    "        return outputs"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "eeebc3a16d2d8bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:24:06.457719Z",
     "start_time": "2025-07-21T14:23:49.877399Z"
    }
   },
   "source": [
    "# 加载原始模型（不修改架构）\n",
    "model = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, \n",
    "    dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "\n",
    "# 加载权重\n",
    "weight_path = '/exp_data/sjx/star/main_transformer_moe_weight/best_transformer_moe_last.pth'\n",
    "model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 创建hook管理器\n",
    "hook_manager = LayerOutputHook()\n",
    "\n",
    "# 加载测试数据\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "test_dataset = ProteinNPYDataset(test_pos, test_neg)\n",
    "\n",
    "# 使用小batch_size减少内存占用\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"模型加载完成\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"正样本: {len(test_dataset.pos)}, 负样本: {len(test_dataset.neg)}\")"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4536966d026ce218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:26:18.295886Z",
     "start_time": "2025-07-21T14:24:06.459158Z"
    }
   },
   "source": [
    "# 注册hooks\n",
    "hook_manager.register_hooks(model)\n",
    "\n",
    "# 提取每层输出\n",
    "all_layer_outputs = [[] for _ in range(5)]  # 0: 原始输入, 1-4: 4层输出\n",
    "all_labels = []\n",
    "\n",
    "print(\"开始提取每层输出...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(test_loader, desc=\"提取层输出\")):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # 保存原始输入（第0层）\n",
    "        all_layer_outputs[0].append(x.cpu().numpy())\n",
    "        \n",
    "        # 前向传播，hooks会自动捕获每层输出\n",
    "        _ = model(x)\n",
    "        \n",
    "        # 获取当前batch的层输出\n",
    "        batch_layer_outputs = hook_manager.get_outputs()\n",
    "        \n",
    "        # 保存每层输出\n",
    "        for layer_idx, layer_output in enumerate(batch_layer_outputs):\n",
    "            all_layer_outputs[layer_idx + 1].append(layer_output.numpy())\n",
    "        \n",
    "        # 保存标签\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "        \n",
    "        # 每处理几个batch就清理一次内存\n",
    "        if batch_idx % 10 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "# 移除hooks（重要！）\n",
    "hook_manager.clear_hooks()\n",
    "\n",
    "print(\"层输出提取完成！\")\n",
    "print(\"Hooks已清除，模型架构未改变\")"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "43a28e48894fc329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:26:58.685488Z",
     "start_time": "2025-07-21T14:26:18.297128Z"
    }
   },
   "source": [
    "# 内存优化的层输出处理\n",
    "print(\"处理层输出数据...\")\n",
    "\n",
    "processed_outputs = []\n",
    "total_samples = len(all_labels)\n",
    "\n",
    "for layer_idx, layer_outputs in enumerate(all_layer_outputs):\n",
    "    print(f\"处理第{layer_idx}层输出...\")\n",
    "    \n",
    "    # 预分配内存，避免concatenate\n",
    "    layer_representations = np.zeros((total_samples, 1152), dtype=np.float32)\n",
    "    \n",
    "    # 逐个batch处理，避免大内存操作\n",
    "    start_idx = 0\n",
    "    for batch_idx, batch_output in enumerate(tqdm(layer_outputs, desc=f\"处理第{layer_idx}层\")):\n",
    "        batch_size = batch_output.shape[0]\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        # 直接对batch做mean pooling\n",
    "        batch_representations = batch_output.mean(axis=1)  # (batch_size, 1152)\n",
    "        \n",
    "        # 填充到预分配的数组中\n",
    "        layer_representations[start_idx:end_idx] = batch_representations\n",
    "        \n",
    "        start_idx = end_idx\n",
    "        \n",
    "        # 及时清理batch数据\n",
    "        del batch_output, batch_representations\n",
    "        if batch_idx % 5 == 0:  # 每5个batch清理一次内存\n",
    "            gc.collect()\n",
    "    \n",
    "    print(f\"第{layer_idx}层表示形状: {layer_representations.shape}\")\n",
    "    processed_outputs.append(layer_representations)\n",
    "    \n",
    "    # 清理原始batch数据\n",
    "    del layer_outputs\n",
    "    gc.collect()\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "print(f\"标签形状: {all_labels.shape}\")\n",
    "print(f\"正样本数量: {np.sum(all_labels == 1)}\")\n",
    "print(f\"负样本数量: {np.sum(all_labels == 0)}\")"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7c04d1d3573dcaf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:26:58.743095Z",
     "start_time": "2025-07-21T14:26:58.687926Z"
    }
   },
   "source": [
    "print(\"=== 数据预处理和检查 ===\")\n",
    "\n",
    "# 检查第一个样本的数据\n",
    "sample_data = processed_outputs[0]\n",
    "print(f\"数据形状: {sample_data.shape}\")\n",
    "print(f\"数据类型: {sample_data.dtype}\")\n",
    "print(f\"数据范围: [{sample_data.min():.3f}, {sample_data.max():.3f}]\")\n",
    "\n",
    "# 检查异常值\n",
    "print(f\"NaN数量: {np.isnan(sample_data).sum()}\")\n",
    "print(f\"无穷大数量: {np.isinf(sample_data).sum()}\")\n",
    "print(f\"零值数量: {(sample_data == 0).sum()}\")\n",
    "\n",
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "sample_data_clean = scaler.fit_transform(sample_data)\n",
    "\n",
    "print(\"数据标准化完成\")\n",
    "print(f\"标准化后范围: [{sample_data_clean.min():.3f}, {sample_data_clean.max():.3f}]\")"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dea9b75e7689a602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:27:08.064116Z",
     "start_time": "2025-07-21T14:26:58.745696Z"
    }
   },
   "source": [
    "# 添加线性降维层\n",
    "class LinearReducer(nn.Module):\n",
    "    def __init__(self, input_dim=1152, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 创建降维器\n",
    "reducer = LinearReducer(1152, 256).to(device)\n",
    "reducer.eval()\n",
    "\n",
    "print(\"开始线性降维处理...\")\n",
    "reduced_outputs = []\n",
    "\n",
    "for layer_idx, layer_representations in enumerate(processed_outputs):\n",
    "    print(f\"处理第{layer_idx}层线性降维...\")\n",
    "    \n",
    "    # 分批处理，避免内存溢出\n",
    "    batch_size = 100  # 更小的batch size\n",
    "    reduced_layer = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(layer_representations), batch_size), desc=f\"降维第{layer_idx}层\"):\n",
    "        batch_data = layer_representations[i:i+batch_size]\n",
    "        batch_tensor = torch.tensor(batch_data, dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            reduced_batch = reducer(batch_tensor)\n",
    "            reduced_layer.append(reduced_batch.cpu().numpy())\n",
    "        \n",
    "        # 及时清理\n",
    "        del batch_tensor, reduced_batch\n",
    "        if i % 500 == 0:\n",
    "            gc.collect()\n",
    "    \n",
    "    # 合并所有batch\n",
    "    reduced_layer = np.vstack(reduced_layer)\n",
    "    reduced_outputs.append(reduced_layer)\n",
    "    \n",
    "    print(f\"第{layer_idx}层降维完成: {layer_representations.shape} -> {reduced_layer.shape}\")\n",
    "    \n",
    "    # 清理原始数据\n",
    "    del layer_representations\n",
    "    gc.collect()\n",
    "\n",
    "print(\"线性降维完成！\")"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## umap降维",
   "id": "3c556200aeade8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:27:08.072599Z",
     "start_time": "2025-07-21T14:27:08.066413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "\n",
    "# Hook机制\n",
    "class LayerOutputHook:\n",
    "    def __init__(self):\n",
    "        self.layer_outputs = []\n",
    "        self.hooks = []\n",
    "        \n",
    "    def register_hooks(self, model):\n",
    "        self.clear_hooks()\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            def make_hook(layer_idx):\n",
    "                def hook(module, input, output):\n",
    "                    layer_output = output[0].detach().cpu()\n",
    "                    self.layer_outputs.append(layer_output)\n",
    "                return hook\n",
    "            hook = layer.register_forward_hook(make_hook(i))\n",
    "            self.hooks.append(hook)\n",
    "    def clear_hooks(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "        self.layer_outputs = []\n",
    "    def get_outputs(self):\n",
    "        outputs = self.layer_outputs.copy()\n",
    "        self.layer_outputs = []\n",
    "        return outputs\n",
    "\n",
    "# 线性降维层\n",
    "class LinearReducer(nn.Module):\n",
    "    def __init__(self, input_dim=1152, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "id": "760463996147bc7e",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:29:10.187569Z",
     "start_time": "2025-07-21T14:27:08.073965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假设model已加载，test_loader已准备好\n",
    "hook_manager = LayerOutputHook()\n",
    "hook_manager.register_hooks(model)\n",
    "\n",
    "reducer = LinearReducer(1152, 256).to(device)\n",
    "reducer.eval()\n",
    "\n",
    "all_layer_outputs = [[] for _ in range(5)]  # 0: 原始输入, 1-4: 4层输出\n",
    "all_labels = []\n",
    "\n",
    "print(\"开始分批提取和降维...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, y) in enumerate(tqdm(test_loader, desc=\"提取层输出\")):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # 原始输入降维\n",
    "        batch_input = x.mean(dim=1)  # (batch, 1152)\n",
    "        reduced_input = reducer(batch_input).cpu().numpy()\n",
    "        all_layer_outputs[0].append(reduced_input)\n",
    "        # 前向传播，hooks会自动捕获每层输出\n",
    "        _ = model(x)\n",
    "        batch_layer_outputs = hook_manager.get_outputs()\n",
    "        for layer_idx, layer_output in enumerate(batch_layer_outputs):\n",
    "            # layer_output: (batch, seq, 1152) -> mean pool\n",
    "            pooled = layer_output.mean(dim=1)\n",
    "            reduced = reducer(pooled.to(device)).cpu().numpy()\n",
    "            all_layer_outputs[layer_idx + 1].append(reduced)\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "        if batch_idx % 10 == 0:\n",
    "            gc.collect()\n",
    "hook_manager.clear_hooks()\n",
    "print(\"分批降维完成！\")"
   ],
   "id": "661126ac64ffcf83",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:31:49.291037Z",
     "start_time": "2025-07-21T14:29:10.190330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"合并每层降维结果...\")\n",
    "processed_outputs = []\n",
    "total_samples = len(all_labels)\n",
    "for layer_idx, layer_outputs in enumerate(all_layer_outputs):\n",
    "    layer_representations = np.zeros((total_samples, 256), dtype=np.float32)\n",
    "    start_idx = 0\n",
    "    for batch_output in layer_outputs:\n",
    "        batch_size = batch_output.shape[0]\n",
    "        end_idx = start_idx + batch_size\n",
    "        layer_representations[start_idx:end_idx] = batch_output\n",
    "        start_idx = end_idx\n",
    "        del batch_output\n",
    "        gc.collect()\n",
    "    processed_outputs.append(layer_representations)\n",
    "    del layer_outputs\n",
    "    gc.collect()\n",
    "all_labels = np.array(all_labels)\n",
    "print(\"合并完成！\")"
   ],
   "id": "b66f8f758f4fbb2e",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:31:49.304019Z",
     "start_time": "2025-07-21T14:31:49.293737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import umap\n",
    "\n",
    "def sample_features(features, labels, max_samples=2000):\n",
    "    if len(features) > max_samples:\n",
    "        np.random.seed(42)\n",
    "        sample_indices = np.random.choice(len(features), max_samples, replace=False)\n",
    "        return features[sample_indices], labels[sample_indices]\n",
    "    else:\n",
    "        return features, labels\n",
    "\n",
    "def umap_reduce(features, n_neighbors=100, min_dist=0.1, random_state=42):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    return reducer.fit_transform(features)"
   ],
   "id": "b01dbf169f3a5f6a",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:32:35.779988Z",
     "start_time": "2025-07-21T14:31:49.305570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(0,5):\n",
    "    # 原始输入\n",
    "    features = processed_outputs[i]\n",
    "    labels = all_labels\n",
    "    sampled_features, sampled_labels = sample_features(features, labels)\n",
    "    embedding_2d = umap_reduce(sampled_features)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos_mask = sampled_labels == 1\n",
    "    neg_mask = sampled_labels == 0\n",
    "    plt.scatter(embedding_2d[pos_mask, 0], embedding_2d[pos_mask, 1], c='red', s=20, alpha=0.6, label='Positive samples', edgecolors='none')\n",
    "    plt.scatter(embedding_2d[neg_mask, 0], embedding_2d[neg_mask, 1], c='blue', s=20, alpha=0.6, label='Negative samples', edgecolors='none')\n",
    "    plt.title('Input Embedding UMAP')\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/exp_data/sjx/star/experiments/zhongjianceng_umap/ceng_results/input_umap{i}.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "9d3883373c020a97",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T14:33:15.005143Z",
     "start_time": "2025-07-21T14:32:35.781273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# label映射，便于图例显示\n",
    "label_map = {1: 'Positive samples', 0: 'Negative samples'}\n",
    "palette = {'Positive samples': 'red', 'Negative samples': 'blue'}\n",
    "\n",
    "# 图标题\n",
    "layer_names = [\n",
    "    \"Input Embedding\",\n",
    "    \"Layer 1 Output\",\n",
    "    \"Layer 2 Output\",\n",
    "    \"Layer 3 Output\",\n",
    "    \"Layer 4 Output\"\n",
    "]\n",
    "\n",
    "for i in range(5):  # 画第0~4层\n",
    "    # 1. 数据准备\n",
    "    features = processed_outputs[i]\n",
    "    labels = all_labels\n",
    "    sampled_features, sampled_labels = sample_features(features, labels)\n",
    "    embedding_2d = umap_reduce(sampled_features)\n",
    "    df = pd.DataFrame({\n",
    "        'UMAP 1': embedding_2d[:, 0],\n",
    "        'UMAP 2': embedding_2d[:, 1],\n",
    "        'label': [label_map[l] for l in sampled_labels]\n",
    "    })\n",
    "\n",
    "    # 2. JointGrid绘图\n",
    "    g = sns.JointGrid(data=df, x=\"UMAP 1\", y=\"UMAP 2\", hue=\"label\", palette=palette, height=8, ratio=5)\n",
    "    g.plot_joint(sns.scatterplot, s=20, alpha=0.6, edgecolor='none')\n",
    "    g.plot_marginals(sns.kdeplot, fill=True, alpha=0.5)\n",
    "    plt.suptitle(f'{layer_names[i]} UMAP with Marginal KDE Distributions', y=1.02, fontsize=16)\n",
    "    plt.savefig(f'/exp_data/sjx/star/experiments/zhongjianceng_umap/ceng_results/joint_umap_{i}.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "id": "68898eb3e457b67c",
   "execution_count": 15,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
