{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T08:33:36.633104Z",
     "start_time": "2025-07-22T08:33:36.610947Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加 model_main.py 所在目录到 sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"..\")))  # 加入 E:/模型/star/\n",
    "\n",
    "# 现在可以导入了\n",
    "from model_main import TransformerMoE\n"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1e88600cfc057d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:33:42.408279Z",
     "start_time": "2025-07-22T08:33:37.000705Z"
    }
   },
   "source": [
    "model = TransformerMoE()\n",
    "print(model)\n"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d3f3bc8b5b1e68e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:33:42.413646Z",
     "start_time": "2025-07-22T08:33:42.411128Z"
    }
   },
   "source": [],
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8115ff6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:33:42.418813Z",
     "start_time": "2025-07-22T08:33:42.414782Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 设置保存路径\n",
    "fig_save_dir = \"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/\"\n",
    "data_save_dir = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/\"\n",
    "os.makedirs(fig_save_dir, exist_ok=True)\n",
    "os.makedirs(data_save_dir, exist_ok=True)"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "719cf3db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:34:16.776719Z",
     "start_time": "2025-07-22T08:33:42.420275Z"
    }
   },
   "source": [
    "# 文件路径\n",
    "attn_weights_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/attn_weights.npy\"\n",
    "gate_scores_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/gate_scores.npy\"\n",
    "labels_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/labels.npy\"\n",
    "topk_idx_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/topk_idx.npy\"\n",
    "\n",
    "# 加载\n",
    "attn_weights = np.load(attn_weights_path)\n",
    "gate_scores = np.load(gate_scores_path)\n",
    "labels = np.load(labels_path)\n",
    "topk_idx = np.load(topk_idx_path)\n",
    "\n",
    "# 打印shape和部分内容\n",
    "print(\"attn_weights.shape:\", attn_weights.shape)\n",
    "print(\"attn_weights sample:\", attn_weights.ravel()[:10])\n",
    "print(\"gate_scores.shape:\", gate_scores.shape)\n",
    "print(\"gate_scores sample:\", gate_scores.ravel()[:10])\n",
    "print(\"labels.shape:\", labels.shape)\n",
    "print(\"labels sample:\", labels[:10])\n",
    "print(\"topk_idx.shape:\", topk_idx.shape)\n",
    "print(\"topk_idx sample:\", topk_idx.ravel()[:10])"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e763d29",
   "metadata": {},
   "source": [
    "## 统计各个专家的使用频率"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d506be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:34:19.156178Z",
     "start_time": "2025-07-22T08:34:16.779212Z"
    }
   },
   "source": [
    "all_expert_ids = topk_idx.reshape(-1)\n",
    "num_experts = gate_scores.shape[-1]\n",
    "expert_ids, counts = np.unique(all_expert_ids, return_counts=True)\n",
    "expert_freq = np.zeros(num_experts, dtype=int)\n",
    "for eid, cnt in zip(expert_ids, counts):\n",
    "    expert_freq[eid] = cnt\n",
    "print(\"专家使用频率:\", expert_freq)\n",
    "\n",
    "df_expert_freq = pd.DataFrame({\"expert_id\": np.arange(num_experts), \"count\": expert_freq})\n",
    "df_expert_freq.to_csv(os.path.join(data_save_dir, \"expert_usage_freq.csv\"), index=False)\n",
    "display(df_expert_freq)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x=np.arange(num_experts), y=expert_freq)\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Usage Count\")\n",
    "plt.title(\"Expert Usage Frequency (All Layers)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_save_dir, \"expert_usage_freq.pdf\"),format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a3c5b437",
   "metadata": {},
   "source": [
    "## 统计门控分数分布"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:34:39.276950Z",
     "start_time": "2025-07-22T08:34:19.159046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 gate_scores: (num_layers, num_seqs, seq_len, num_experts)\n",
    "# topk_idx: (num_layers, num_seqs, seq_len, topk)\n",
    "num_layers, num_seqs, seq_len, num_experts = gate_scores.shape\n",
    "topk = topk_idx.shape[-1]\n",
    "\n",
    "# 收集每个专家被分配到的所有非零分数\n",
    "expert_gate_scores = [[] for _ in range(num_experts)]\n",
    "for layer in range(num_layers):\n",
    "    for i in range(num_seqs):\n",
    "        for t in range(seq_len):\n",
    "            for k in range(topk):\n",
    "                eid = topk_idx[layer, i, t, k]\n",
    "                score = gate_scores[layer, i, t, eid]\n",
    "                expert_gate_scores[eid].append(score)\n",
    "\n",
    "# 转为DataFrame，方便画图\n",
    "df_expert_gate_scores = pd.DataFrame(dict([(f\"Expert_{i}\", pd.Series(scores)) for i, scores in enumerate(expert_gate_scores)]))\n",
    "\n",
    "# 画箱型图\n",
    "plt.figure(figsize=(14,6))\n",
    "ax = sns.boxplot(data=df_expert_gate_scores, showfliers=True)\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Gate Score\")\n",
    "plt.title(\"Gate Score Distribution per Expert (Assigned Tokens Only)\")\n",
    "step = max(1, num_experts // 10)\n",
    "ax.set_xticks(np.arange(0, num_experts, step))\n",
    "ax.set_xticklabels([f\"Expert_{i}\" for i in range(0, num_experts, step)], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_save_dir, \"gate_score_distribution_assigned_only.pdf\"), format='pdf', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "cbf8e3400b6bb185",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:35:06.634611Z",
     "start_time": "2025-07-22T08:34:39.278038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "topk_vals = []\n",
    "for layer in range(num_layers):\n",
    "    for i in range(num_seqs):\n",
    "        for t in range(seq_len):\n",
    "            vals = []\n",
    "            for k in range(topk_idx.shape[-1]):\n",
    "                eid = topk_idx[layer, i, t, k]\n",
    "                vals.append(gate_scores[layer, i, t, eid])\n",
    "            vals = np.array(vals)\n",
    "            vals_norm = vals / (vals.sum() + 1e-9)\n",
    "            topk_vals.append(vals_norm)\n",
    "topk_vals = np.vstack(topk_vals)  # shape: [N, 3]\n",
    "# 假设 topk_vals 是 shape [N, 3] 的 numpy 数组\n",
    "df_topk = pd.DataFrame(topk_vals, columns=['top1', 'top2', 'top3'])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.boxplot(data=df_topk, width=0.5, showfliers=True, boxprops=dict(alpha=0.7, linewidth=1.2))\n",
    "# 采样每列3000个点\n",
    "sample_n = 3000\n",
    "df_sampled = pd.concat([\n",
    "    df_topk[col].sample(n=sample_n, random_state=42).reset_index(drop=True)\n",
    "    for col in df_topk.columns\n",
    "], axis=1)\n",
    "sns.stripplot(data=df_sampled, size=0.5, color=\"k\", alpha=0.05, jitter=0.2, ax=ax)\n",
    "\n",
    "plt.title(\"Top3归一化后门控分数分布\")\n",
    "plt.ylabel(\"Gate Score\")\n",
    "plt.xlabel(\"Top-k Rank\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f2ea551adce026e3",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:35:07.581428Z",
     "start_time": "2025-07-22T08:35:06.636115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n",
    "\n",
    "# 假设 topk_vals 是 shape [N, 3] 的 numpy 数组\n",
    "df_topk = pd.DataFrame(topk_vals, columns=['top1', 'top2', 'top3'])\n",
    "\n",
    "# 采样每列3000个点，减少点数和PDF体积\n",
    "sample_n = 1000\n",
    "df_sampled = pd.concat([\n",
    "    df_topk[col].sample(n=sample_n, random_state=42).reset_index(drop=True)\n",
    "    for col in df_topk.columns\n",
    "], axis=1)\n",
    "df_long = df_sampled.melt(var_name=\"Top-k Rank\", value_name=\"Gate Score\")\n",
    "\n",
    "violin_palette = [\"#8ecae6\", \"#ffb703\", \"#b7e4c7\"]\n",
    "box_palette = [\"#219ebc\", \"#fb8500\", \"#52b788\"]  # 比小提琴深一点\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = pt.half_violinplot(\n",
    "    x=\"Top-k Rank\", y=\"Gate Score\", data=df_long, palette=violin_palette,\n",
    "    bw=.2, cut=0, scale=\"area\", width=.7, inner=None, orient=\"v\",\n",
    "    offset=0.15, alpha=0.7, ax=None\n",
    ")\n",
    "# 叠加箱型图（左半边，facecolor透明，width小一点）\n",
    "sns.boxplot(\n",
    "    x=\"Top-k Rank\", y=\"Gate Score\", data=df_long, width=0.2, showcaps=True,\n",
    "    boxprops={'facecolor':'#8ecae6', 'alpha':0.5, 'zorder':10, 'linewidth':1.2},\n",
    "    medianprops={'color':'black', 'linewidth':1.5},\n",
    "    whiskerprops={'linewidth':1.2},\n",
    "    showfliers=True, flierprops={'marker': 'o', 'markersize': 2, 'alpha': 0.2, 'color': 'gray'},\n",
    "    ax=ax\n",
    ")\n",
    "# 叠加散点（全宽，点小透明度低）\n",
    "sns.stripplot(\n",
    "    x=\"Top-k Rank\", y=\"Gate Score\", data=df_long, size=0.3, color=\"k\",\n",
    "    alpha=0.03, jitter=0.15, ax=ax\n",
    ")\n",
    "\n",
    "ax.set_facecolor('white')\n",
    "plt.gcf().patch.set_facecolor('white')\n",
    "sns.despine(ax=ax, top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "# 5. 坐标轴/刻度/标签全部黑色\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.xaxis.label.set_color('black')\n",
    "ax.yaxis.label.set_color('black')\n",
    "ax.tick_params(axis='x', colors='black')\n",
    "ax.tick_params(axis='y', colors='black')\n",
    "\n",
    "# 6. 英文标题和标签\n",
    "plt.title(\"Top-3 Normalized Gate Score Distribution (Half Violin + Box + Dots)\", fontsize=14)\n",
    "plt.ylabel(\"Gate Score\", fontsize=12)\n",
    "plt.xlabel(\"Top-k Rank\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/gate_score_halfviolinright_box_scatter_rasterized.pdf\", format='pdf', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "cfc1a8e0e09a6472",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:35:08.871967Z",
     "start_time": "2025-07-22T08:35:08.871651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, scores in enumerate(expert_gate_scores):\n",
    "    print(f\"Expert_{i}: 非零分数数量={len(scores)}, 其中0分数量={(np.array(scores)==0).sum()}\")\n",
    "all_scores = gate_scores.flatten()\n",
    "print(\"所有分数的描述性统计：\")\n",
    "print(pd.Series(all_scores).describe())\n",
    "print(\"非零分数比例：\", (all_scores != 0).sum() / all_scores.size)\n",
    "assigned_scores = np.concatenate(expert_gate_scores)\n",
    "print(\"被分配到的分数的描述性统计：\")\n",
    "print(pd.Series(assigned_scores).describe())\n",
    "print(\"非零分数比例：\", (assigned_scores != 0).sum() / assigned_scores.size)\n",
    "# 假设 gate_scores: (num_layers, num_seqs, seq_len, num_experts)\n",
    "# topk_idx: (num_layers, num_seqs, seq_len, topk)\n",
    "\n",
    "\n",
    "print(\"topk归一化后分数的描述性统计：\")\n",
    "print(pd.DataFrame(topk_vals).describe())"
   ],
   "id": "b5f5bd9f620aabbc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4cc110ae",
   "metadata": {},
   "source": [
    "## 统计单条序列的各个专家使用情况"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:35:08.873123Z",
     "start_time": "2025-07-22T08:35:08.872796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 统计第一条序列全部140个token在硬路由下各专家的使用情况（0/1矩阵），并画热力图\n",
    "# 统计第一条序列前140个token在硬路由下各专家的门控分数（只有3个专家非零，其余为0），并画热力图\n",
    "seq_idx = 0\n",
    "valid_token_len = 140\n",
    "num_experts = gate_scores.shape[-1]\n",
    "num_layers = gate_scores.shape[0]\n",
    "topk = topk_idx.shape[-1]\n",
    "\n",
    "gate_score_matrix = np.zeros((valid_token_len, num_experts))\n",
    "for t in range(valid_token_len):\n",
    "    for layer in range(1):\n",
    "        for k in range(topk):\n",
    "            eid = topk_idx[layer, seq_idx, t, k]\n",
    "            score = gate_scores[layer, seq_idx, t, eid]\n",
    "            gate_score_matrix[t, eid] += score  # 累加所有层的分数\n",
    "\n",
    "np.save(os.path.join(data_save_dir, \"first_seq_gate_score_matrix.npy\"), gate_score_matrix)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cmap='Blues'\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(gate_score_matrix, cmap=cmap, cbar=True)\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Token Position\")\n",
    "plt.title(f\"Gate Score Heatmap (cmap={cmap})\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "39c89999",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:35:08.874277Z",
     "start_time": "2025-07-22T08:35:08.873935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 加载数据\n",
    "gate_score_matrix = np.load(os.path.join(data_save_dir, \"first_seq_gate_score_matrix.npy\"))\n",
    "num_tokens, num_experts = gate_score_matrix.shape\n",
    "token_count_per_expert = (gate_score_matrix > 0).sum(axis=0)\n",
    "\n",
    "# 环形热力图参数\n",
    "theta_max = 3 * np.pi / 2  # 四分之三圆\n",
    "theta = np.linspace(0, theta_max, num_tokens + 1)\n",
    "r = np.linspace(1, 2, num_experts + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "ax.set_theta_direction(-1)\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "# 画四分之三圆的热力图\n",
    "norm_matrix = (gate_score_matrix - gate_score_matrix.min()) / (gate_score_matrix.max() - gate_score_matrix.min() + 1e-8)\n",
    "for i in range(num_tokens):\n",
    "    for j in range(num_experts):\n",
    "        val = norm_matrix[i, j]\n",
    "        ax.bar(\n",
    "            x=theta[i], height=r[j+1] - r[j], width=theta[1] - theta[0],\n",
    "            bottom=r[j], color=plt.cm.Blues(val), edgecolor='none'\n",
    "        )\n",
    "\n",
    "# 美化极坐标\n",
    "ax.set_xticks(np.linspace(0, theta_max, 7))\n",
    "ax.set_xticklabels([f\"{int(i)}\" for i in np.linspace(0, num_tokens, 7)])\n",
    "ax.set_yticks(r)\n",
    "ax.set_yticklabels([str(i) for i in range(num_experts + 1)])\n",
    "ax.set_ylabel(\"Expert ID\", fontsize=14)\n",
    "ax.set_xlabel(\"Token Position\", fontsize=14)\n",
    "ax.set_title(\"Circular Gate Score Heatmap (3/4 Circle)\", fontsize=18, pad=20)\n",
    "ax.grid(False)\n",
    "ax.spines['polar'].set_visible(False)\n",
    "\n",
    "# colorbar\n",
    "import matplotlib as mpl\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=gate_score_matrix.min(), vmax=gate_score_matrix.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax, pad=0.1, orientation='vertical', fraction=0.05)\n",
    "cbar.set_label('Gate Score', fontsize=14)\n",
    "\n",
    "# 在左上角加一个小的直角坐标系画柱状图\n",
    "# [left, bottom, width, height]，数值0~1，左上角如[0.05, 0.65, 0.25, 0.25]\n",
    "ax_bar = fig.add_axes([0.08, 0.68, 0.28, 0.28])\n",
    "ax_bar.barh(np.arange(num_experts), token_count_per_expert, color=\"#4FC3F7\")\n",
    "ax_bar.set_yticks(np.arange(num_experts))\n",
    "ax_bar.set_yticklabels([str(i) for i in range(num_experts)], fontsize=8)\n",
    "ax_bar.set_xlabel(\"Token Count\", fontsize=10)\n",
    "ax_bar.set_ylabel(\"Expert ID\", fontsize=10)\n",
    "ax_bar.invert_yaxis()\n",
    "ax_bar.spines['top'].set_visible(False)\n",
    "ax_bar.spines['right'].set_visible(False)\n",
    "ax_bar.spines['left'].set_visible(False)\n",
    "ax_bar.spines['bottom'].set_visible(False)\n",
    "ax_bar.tick_params(axis='x', labelsize=8)\n",
    "ax_bar.tick_params(axis='y', labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(fig_save_dir, \"first_seq_gate_score_circular_heatmap_with_bar_in_corner.pdf\"), format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "51d552624085fe7d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "afdb466a",
   "metadata": {},
   "source": [
    "# 专家专用性和偏好性分析（token类型未知，先统计专家分配的token分布）分析不同类别token更倾向于被哪些专家处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449af9011cab7f94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "3aa8e4ab212b7cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:35:08.875407Z",
     "start_time": "2025-07-22T08:35:08.875089Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "aa2idx = {aa: i for i, aa in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
    "\n",
    "def read_fasta(filepath):\n",
    "    seqs = []\n",
    "    with open(filepath) as f:\n",
    "        seq = \"\"\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if seq:\n",
    "                    seqs.append(seq)\n",
    "                    seq = \"\"\n",
    "            else:\n",
    "                seq += line\n",
    "        if seq:\n",
    "            seqs.append(seq)\n",
    "    return seqs\n",
    "\n",
    "# 读取正负样本\n",
    "pos_seqs = read_fasta(\"/exp_data/sjx/star/first_data/shisuandanbai/positive_test.fasta\")\n",
    "neg_seqs = read_fasta(\"/exp_data/sjx/star/first_data/shisuandanbai/negative_test.fasta\")\n",
    "\n",
    "all_seqs = pos_seqs + neg_seqs  # 正样本在前，负样本在后\n",
    "max_len = 300  # 和ESM嵌入保持一致\n",
    "seqs_idx = np.full((len(all_seqs), max_len), -1, dtype=int)  # -1表示padding\n",
    "\n",
    "for i, seq in enumerate(all_seqs):\n",
    "    seq = seq[:max_len]  # 截断\n",
    "    for j, aa in enumerate(seq):\n",
    "        seqs_idx[i, j] = aa2idx.get(aa, -1)\n",
    "    # 小于max_len的自动padding为-1\n",
    "\n",
    "np.save(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/test_token_types.npy\", seqs_idx)\n",
    "print(\"test_token_types.npy saved! shape:\", seqs_idx.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3afa9f5b",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "token_types = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/test_token_types.npy\")  # (1149, 300)\n",
    "topk_idx = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/topk_idx.npy\")  # (4, 1149, 300, 3)\n",
    "\n",
    "num_layers = topk_idx.shape[0]\n",
    "num_seqs, seq_len = token_types.shape\n",
    "num_experts = topk_idx.max() + 1\n",
    "num_aa = 20  # 氨基酸种类数\n",
    "\n",
    "# 统计每个专家分配到的氨基酸类型数量\n",
    "expert_aa_count = np.zeros((num_experts, num_aa), dtype=int)\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    for i in range(num_seqs):\n",
    "        for t in range(seq_len):\n",
    "            for k in range(topk_idx.shape[-1]):\n",
    "                eid = topk_idx[layer, i, t, k]\n",
    "                aa = token_types[i, t]\n",
    "                if 0 <= aa < num_aa:\n",
    "                    expert_aa_count[eid, aa] += 1\n",
    "\n",
    "# 可视化：每个专家的氨基酸分布（堆叠柱状图）\n",
    "aa_list = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "df = pd.DataFrame(expert_aa_count, columns=aa_list)\n",
    "df.index.name = \"Expert\"\n",
    "df_norm = df.div(df.sum(axis=1), axis=0)  # 行归一化\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "df_norm.plot(kind=\"bar\", stacked=True, colormap=\"tab20\", width=0.9, ax=plt.gca())\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Proportion of Amino Acid Types\")\n",
    "plt.title(\"Amino Acid Type Distribution per Expert\")\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/expert_aa_distribution_stackedbar.pdf\",format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 也可以输出每个专家最偏好的氨基酸类型\n",
    "for eid in range(num_experts):\n",
    "    top_aa = aa_list[np.argmax(expert_aa_count[eid])]\n",
    "    print(f\"Expert {eid}: most preferred AA = {top_aa}, count = {expert_aa_count[eid].max()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2744709a",
   "metadata": {},
   "source": [
    "### 氨基酸理化性质偏好分析"
   ]
  },
  {
   "cell_type": "code",
   "id": "5a044824",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 氨基酸理化分类\n",
    "hydrophobic = set(\"AILMFWV\")\n",
    "polar = set(\"NQSTY\")\n",
    "positive = set(\"KRH\")\n",
    "negative = set(\"DE\")\n",
    "special = set(\"CGP\")\n",
    "aa2group = {}\n",
    "for aa in hydrophobic: aa2group[aa] = \"hydrophobic\"\n",
    "for aa in polar: aa2group[aa] = \"polar\"\n",
    "for aa in positive: aa2group[aa] = \"positive\"\n",
    "for aa in negative: aa2group[aa] = \"negative\"\n",
    "for aa in special: aa2group[aa] = \"special\"\n",
    "aa_list = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "aa_idx2group = [aa2group.get(aa, \"other\") for aa in aa_list]\n",
    "group_names = [\"hydrophobic\", \"polar\", \"positive\", \"negative\", \"special\"]\n",
    "\n",
    "# 加载数据\n",
    "token_types = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/test_token_types.npy\")\n",
    "topk_idx = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/topk_idx.npy\")\n",
    "num_layers = topk_idx.shape[0]\n",
    "num_seqs, seq_len = token_types.shape\n",
    "num_experts = topk_idx.max() + 1\n",
    "\n",
    "# 统计每个专家分配到的理化类别数量\n",
    "expert_group_count = np.zeros((num_experts, len(group_names)), dtype=int)\n",
    "for layer in range(num_layers):\n",
    "    for i in range(num_seqs):\n",
    "        for t in range(seq_len):\n",
    "            for k in range(topk_idx.shape[-1]):\n",
    "                eid = topk_idx[layer, i, t, k]\n",
    "                aa = token_types[i, t]\n",
    "                if 0 <= aa < 20:\n",
    "                    group = aa_idx2group[aa]\n",
    "                    if group in group_names:\n",
    "                        expert_group_count[eid, group_names.index(group)] += 1\n",
    "\n",
    "df_group = pd.DataFrame(expert_group_count, columns=group_names)\n",
    "df_group_norm = df_group.div(df_group.sum(axis=1), axis=0)\n",
    "plt.figure(figsize=(14, 6))\n",
    "df_group_norm.plot(kind=\"bar\", stacked=True, colormap=\"tab20\", width=0.9, ax=plt.gca())\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Proportion of AA Property\")\n",
    "plt.title(\"Amino Acid Property Distribution per Expert\")\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/expert_aa_property_distribution.pdf\",format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b453bc93",
   "metadata": {},
   "source": [
    "### 正负样本偏好分析"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b228a8e",
   "metadata": {},
   "source": [
    "# 假设正样本在前，负样本在后\n",
    "num_pos = len(read_fasta(\"/exp_data/sjx/star/first_data/shisuandanbai/positive_test.fasta\"))\n",
    "num_neg = len(read_fasta(\"/exp_data/sjx/star/first_data/shisuandanbai/negative_test.fasta\"))\n",
    "# 但fasta不能直接np.load，需用前面read_fasta函数\n",
    "def read_fasta(filepath):\n",
    "    seqs = []\n",
    "    with open(filepath) as f:\n",
    "        seq = \"\"\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if seq:\n",
    "                    seqs.append(seq)\n",
    "                    seq = \"\"\n",
    "            else:\n",
    "                seq += line\n",
    "        if seq:\n",
    "            seqs.append(seq)\n",
    "    return seqs\n",
    "num_pos = len(read_fasta(\"/exp_data/sjx/star/first_data/shisuandanbai/positive_test.fasta\"))\n",
    "num_neg = len(read_fasta(\"/exp_data/sjx/star/first_data/shisuandanbai/negative_test.fasta\"))\n",
    "\n",
    "# 分别统计正负样本专家分配\n",
    "expert_token_counts_pos = np.zeros(num_experts, dtype=int)\n",
    "expert_token_counts_neg = np.zeros(num_experts, dtype=int)\n",
    "for layer in range(num_layers):\n",
    "    for i in range(num_seqs):\n",
    "        for t in range(seq_len):\n",
    "            for k in range(topk_idx.shape[-1]):\n",
    "                eid = topk_idx[layer, i, t, k]\n",
    "                if i < num_pos:\n",
    "                    expert_token_counts_pos[eid] += 1\n",
    "                else:\n",
    "                    expert_token_counts_neg[eid] += 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_pos = np.arange(num_experts)\n",
    "\n",
    "# 正样本的棒棒糖图 (蓝色)\n",
    "plt.vlines(x=x_pos - 0.2, ymin=0, ymax=expert_token_counts_pos, color='dodgerblue', alpha=0.7, linewidth=2)\n",
    "plt.scatter(x=x_pos - 0.2, y=expert_token_counts_pos, color='dodgerblue', s=75, alpha=1, label=\"Positive\")\n",
    "\n",
    "# 负样本的棒棒糖图 (橙色)\n",
    "plt.vlines(x=x_pos + 0.2, ymin=0, ymax=expert_token_counts_neg, color='darkorange', alpha=0.7, linewidth=2)\n",
    "plt.scatter(x=x_pos + 0.2, y=expert_token_counts_neg, color='darkorange', s=75, alpha=1, label=\"Negative\")\n",
    "\n",
    "# 在棒棒糖头部标注具体数值（黑色字体）\n",
    "for i in range(num_experts):\n",
    "    plt.text(x_pos[i] - 0.2, expert_token_counts_pos[i], f\"{expert_token_counts_pos[i]}\", \n",
    "             ha='center', va='bottom', fontsize=9, color='black', rotation=90)\n",
    "    plt.text(x_pos[i] + 0.2, expert_token_counts_neg[i], f\"{expert_token_counts_neg[i]}\", \n",
    "             ha='center', va='bottom', fontsize=9, color='black', rotation=90)\n",
    "\n",
    "plt.xlabel(\"Expert ID\", fontsize=12)\n",
    "plt.ylabel(\"Token Count\", fontsize=12)\n",
    "plt.title(\"Expert Assignment Count: Positive vs Negative Samples (Lollipop)\", fontsize=14)\n",
    "plt.xticks(x_pos)\n",
    "\n",
    "# 格式化Y轴，使其更易读\n",
    "ax = plt.gca()\n",
    "ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "ax.yaxis.get_offset_text().set_fontsize(10)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/expert_pos_neg_distribution_lollipop.pdf\", format='pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7730eb1a",
   "metadata": {},
   "source": [
    "### 专家分配token的门控分数分布"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e77ef16",
   "metadata": {},
   "source": [
    "gate_scores = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/gate_scores.npy\")\n",
    "# gate_scores: (4, 1149, 300, 30)\n",
    "expert_gate_scores = [[] for _ in range(num_experts)]\n",
    "for layer in range(num_layers):\n",
    "    for i in range(num_seqs):\n",
    "        for t in range(seq_len):\n",
    "            for k in range(topk_idx.shape[-1]):\n",
    "                eid = topk_idx[layer, i, t, k]\n",
    "                score = gate_scores[layer, i, t, eid]\n",
    "                expert_gate_scores[eid].append(score)\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=[expert_gate_scores[eid] for eid in range(num_experts)])\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Gate Score\")\n",
    "plt.title(\"Gate Score Distribution per Expert (Assigned Tokens Only)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9d122361",
   "metadata": {},
   "source": [
    "### 专家分配token的多样性（香农熵）"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# 假设 num_experts, token_types, topk_idx 已经定义并赋值\n",
    "expert_aa_entropy = []\n",
    "for eid in range(num_experts):\n",
    "    aa_counts = np.zeros(20, dtype=int)\n",
    "    for aa in range(20):\n",
    "        aa_counts[aa] = np.sum((token_types == aa) & (np.any(topk_idx == eid, axis=(0,3))))\n",
    "    p = aa_counts / (aa_counts.sum() + 1e-12)\n",
    "    expert_aa_entropy.append(entropy(p, base=2))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "x = np.arange(num_experts)\n",
    "y = expert_aa_entropy\n",
    "\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, num_experts))\n",
    "\n",
    "for i in range(num_experts):\n",
    "    plt.vlines(x[i], 0, y[i], color=colors[i], linewidth=2)\n",
    "    plt.scatter(x[i], y[i], color=colors[i], s=80, zorder=3)\n",
    "    # 在棒棒糖头部上方打印具体数值，保留两位小数\n",
    "    plt.text(x[i], y[i]+0.02, f\"{y[i]:.2f}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Expert ID\")\n",
    "plt.ylabel(\"Amino Acid Diversity (Shannon Entropy)\")\n",
    "plt.title(\"Amino Acid Diversity of Tokens Assigned to Each Expert\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/expert_aa_entropy.pdf\",format='pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "eb976e666bc36b7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e32d7ef",
   "metadata": {},
   "source": [
    "### 专家对序列结构区域的偏好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ffc74",
   "metadata": {},
   "source": [
    "### 专家分配的token在序列中的位置分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f2a60",
   "metadata": {},
   "source": [
    "# 负载均衡度量\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "353ad631",
   "metadata": {},
   "source": [
    "# 统计每个专家被分配到的token数量\n",
    "all_expert_ids = topk_idx.reshape(-1)\n",
    "num_experts = gate_scores.shape[-1]\n",
    "expert_token_counts = np.zeros(num_experts, dtype=int)\n",
    "for eid in range(num_experts):\n",
    "    expert_token_counts[eid] = np.sum(all_expert_ids == eid)\n",
    "probs = expert_token_counts / expert_token_counts.sum()\n",
    "entropy = -np.sum(probs * np.log(probs + 1e-12))\n",
    "max_min_ratio = expert_token_counts.max() / (expert_token_counts.min() + 1e-12)\n",
    "std = expert_token_counts.std()\n",
    "num_collapsed = np.sum(expert_token_counts == 0)\n",
    "\n",
    "print(f\"专家分配比例: {probs}\")\n",
    "print(f\"负载均衡熵: {entropy:.4f} (最大值: {np.log(len(expert_token_counts)):.4f})\")\n",
    "print(f\"最大/最小分配比: {max_min_ratio:.2f}\")\n",
    "print(f\"塌陷专家数量（分配为0）: {num_collapsed}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0e8d9657",
   "metadata": {},
   "source": [
    "## 专家输出相关性   内存太大，没有成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1052ae19735b7f",
   "metadata": {},
   "source": [
    "### 专家输出t_sne降维和PCA降维，看是否分离说明提取得特征给你不同"
   ]
  },
  {
   "cell_type": "code",
   "id": "86dde28e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "expert_outs_path = '/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/expert_outs_lastlayer.npy'\n",
    "save_dir = '/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. 内存映射方式加载\n",
    "data = np.load(expert_outs_path, mmap_mode='r')  # (1149, 300, 3, 1152)\n",
    "\n",
    "reshaped_data = data.reshape(-1, data.shape[2], data.shape[3])  # (344700, 3, 1152)\n",
    "print(\"重塑后数据形状:\", reshaped_data.shape)\n",
    "\n",
    "expert_means = np.mean(reshaped_data, axis=0)  # (3, 1152)\n",
    "print(\"专家平均输出形状:\", expert_means.shape)\n",
    "\n",
    "# Cell 5: 计算专家间相关性矩阵\n",
    "corr_matrix = np.corrcoef(expert_means)\n",
    "print(\"相关性矩阵形状:\", corr_matrix.shape)\n",
    "print(\"相关性矩阵:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Cell 6: 可视化专家间相关性\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=True, fmt='.3f', square=True,\n",
    "            xticklabels=[f'Expert_{i}' for i in range(corr_matrix.shape[0])],\n",
    "            yticklabels=[f'Expert_{i}' for i in range(corr_matrix.shape[0])])\n",
    "plt.title('Expert Output Correlation (All Samples, Last Layer)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Expert ID', fontsize=12)\n",
    "plt.ylabel('Expert ID', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'expert_output_correlation_all_samples.svg'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea0cd6cfabe7372",
   "metadata": {},
   "source": [
    "# 正负样本氨基酸相关性分析"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a0892ba574de08c",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def read_fasta(filepath):\n",
    "    seqs = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        seq = ''\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if seq:\n",
    "                    seqs.append(seq)\n",
    "                    seq = ''\n",
    "            else:\n",
    "                seq += line.strip()\n",
    "        if seq:\n",
    "            seqs.append(seq)\n",
    "    return seqs\n",
    "\n",
    "# 合并正负样本\n",
    "pos_train = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/positive_train.fasta')\n",
    "pos_test = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/positive_test.fasta')\n",
    "neg_train = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/negative_train.fasta')\n",
    "neg_test = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/negative_test.fasta')\n",
    "\n",
    "pos_seqs = pos_train + pos_test\n",
    "neg_seqs = neg_train + neg_test\n",
    "\n",
    "# 统计全局频率\n",
    "amino_acids = list('ACDEFGHIKLMNPQRSTVWY')\n",
    "def get_freq(seqs):\n",
    "    total = Counter()\n",
    "    total_len = 0\n",
    "    for seq in seqs:\n",
    "        total.update(seq)\n",
    "        total_len += len(seq)\n",
    "    freq = np.array([total[aa] for aa in amino_acids], dtype=float) / total_len\n",
    "    return freq\n",
    "\n",
    "pos_freq = get_freq(pos_seqs)\n",
    "neg_freq = get_freq(neg_seqs)\n",
    "print(pos_freq)\n",
    "print(neg_freq)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f2b5d2321582d11f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 更高效的方法：直接计算20种氨基酸之间的相关性\n",
    "def get_aa_correlation_matrix(seqs, amino_acids=\"ACDEFGHIKLMNPQRSTVWY\"):\n",
    "    aa_list = list(amino_acids)\n",
    "    aa2idx = {aa: i for i, aa in enumerate(aa_list)}\n",
    "    aa_freq_matrix = np.zeros((len(aa_list), len(seqs)))\n",
    "    for i, seq in enumerate(seqs):\n",
    "        # 如果seq是字符串，先转成list；如果是int数组，先过滤-1\n",
    "        if isinstance(seq[0], str):\n",
    "            valid_aa = [aa for aa in seq if aa in aa2idx]\n",
    "        else:\n",
    "            # int编码，-1为padding\n",
    "            valid_aa = [aa for aa in seq if aa != -1]\n",
    "            # 需要把int转回字母\n",
    "            valid_aa = [aa_list[aa] for aa in valid_aa if 0 <= aa < 20]\n",
    "        total_len = len(valid_aa)\n",
    "        c = Counter(valid_aa)\n",
    "        for j, aa in enumerate(aa_list):\n",
    "            aa_freq_matrix[j, i] = c[aa] / total_len if total_len > 0 else 0\n",
    "    corr_matrix = np.corrcoef(aa_freq_matrix)\n",
    "    return corr_matrix\n",
    "\n",
    "print(\"计算正样本氨基酸相关性...\")\n",
    "pos_corr = get_aa_correlation_matrix(pos_seqs)\n",
    "print(\"计算负样本氨基酸相关性...\")\n",
    "neg_corr = get_aa_correlation_matrix(neg_seqs)\n",
    "\n",
    "print(f\"正样本序列数: {len(pos_seqs)}\")\n",
    "print(f\"负样本序列数: {len(neg_seqs)}\")\n",
    "print(f\"相关性矩阵形状: {pos_corr.shape}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "10f3671e6ac9404b",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# 假设你已经有 pos_corr, neg_corr, amino_acids\n",
    "pos_corr_df = pd.DataFrame(pos_corr, index=amino_acids, columns=amino_acids)\n",
    "neg_corr_df = pd.DataFrame(neg_corr, index=amino_acids, columns=amino_acids)\n",
    "\n",
    "def plot_corr_beauty(corr_df, title, save_path, highlight_boxes=None):\n",
    "    n = len(corr_df)\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    ax = plt.gca()\n",
    "    # 右上角（含主对角线）：画圆圈，主对角线只显示字母\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            val = corr_df.iloc[i, j]\n",
    "            if i == j:\n",
    "                # 主对角线：只显示字母\n",
    "                ax.text(j, i, corr_df.columns[i], ha='center', va='center', fontsize=15, fontweight='bold', color='r')\n",
    "            else:\n",
    "                color = plt.cm.coolwarm((val+0.4)/0.8)\n",
    "                size = abs(val)*800 if abs(val)>0.01 else 0\n",
    "                ax.scatter(j, i, s=size, color=color, alpha=0.8, edgecolor='k', linewidth=0.5)\n",
    "    # 左下角：显示数值\n",
    "    for i in range(1, n):\n",
    "        for j in range(i):\n",
    "            val = corr_df.iloc[i, j]\n",
    "            ax.text(j, i, f\"{val:.2f}\", ha='center', va='center', fontsize=10, color='w' if abs(val)>0.2 else 'gray')\n",
    "    # 高亮部分区域\n",
    "    if highlight_boxes:\n",
    "        for (i0, j0, w, h) in highlight_boxes:\n",
    "            rect = Rectangle((j0-0.5, i0-0.5), w, h, linewidth=2, edgecolor='red', facecolor='none', linestyle='--')\n",
    "            ax.add_patch(rect)\n",
    "    ax.set_xticks(range(n))\n",
    "    ax.set_yticks(range(n))\n",
    "    ax.set_xticklabels(corr_df.columns, fontsize=13)\n",
    "    ax.set_yticklabels(corr_df.index, fontsize=13)\n",
    "    ax.set_xlim(-0.5, n-0.5)\n",
    "    ax.set_ylim(n-0.5, -0.5)\n",
    "    plt.title(title, fontsize=16)\n",
    "    sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=-0.4, vmax=0.4))\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.045, pad=0.03, orientation='horizontal')\n",
    "    cbar.set_label('Correlation', fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "save_dir = '/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "highlight_boxes = [(13, 14, 2, 2), (16, 18, 3, 3)]  # 可根据需要调整\n",
    "\n",
    "plot_corr_beauty(pos_corr_df, 'Amino Acid Correlation (Positive, Beauty)', os.path.join(save_dir, 'positive_aa_correlation_beauty.svg'), highlight_boxes)\n",
    "plot_corr_beauty(neg_corr_df, 'Amino Acid Correlation (Negative, Beauty)', os.path.join(save_dir, 'negative_aa_correlation_beauty.svg'), highlight_boxes)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cell 1: 导入依赖\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "# Cell 2: 加载数据\n",
    "attn_weights_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/attn_weights.npy\"\n",
    "gate_scores_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/gate_scores.npy\"\n",
    "topk_idx_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/topk_idx.npy\"\n",
    "token_types_path = \"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/test_token_types.npy\"\n",
    "\n",
    "attn_weights = np.load(attn_weights_path)  # (4, 1149, 300, 300)\n",
    "gate_scores = np.load(gate_scores_path)    # (4, 1149, 300, 30)\n",
    "topk_idx = np.load(topk_idx_path)          # (4, 1149, 300, 3)\n",
    "token_types = np.load(token_types_path)    # (1149, 300)\n",
    "\n",
    "print(\"数据形状:\")\n",
    "print(f\"attn_weights: {attn_weights.shape}\")\n",
    "print(f\"gate_scores: {gate_scores.shape}\")\n",
    "print(f\"topk_idx: {topk_idx.shape}\")\n",
    "print(f\"token_types: {token_types.shape}\")\n",
    "\n",
    "# Cell 3: 选择要分析的序列和层\n",
    "seq_idx = 0  # 第一条序列\n",
    "layer_idx = 0  # 第一层\n",
    "seq_len = 140  # 实际序列长度（去除padding）\n",
    "\n",
    "# 获取该序列的数据\n",
    "seq_attn = attn_weights[layer_idx, seq_idx, :seq_len, :seq_len]  # (seq_len, seq_len)\n",
    "seq_gate = gate_scores[layer_idx, seq_idx, :seq_len]  # (seq_len, 30)\n",
    "seq_experts = topk_idx[layer_idx, seq_idx, :seq_len]  # (seq_len, 3)\n",
    "seq_tokens = token_types[seq_idx, :seq_len]  # (seq_len,)\n",
    "\n",
    "print(f\"分析序列 {seq_idx}，层 {layer_idx}，长度 {seq_len}\")\n",
    "# Cell 4: 准备桑基图数据 - Token到Expert的分配\n",
    "def prepare_sankey_data(seq_attn, seq_gate, seq_experts, seq_tokens, top_k=3):\n",
    "    \"\"\"\n",
    "    准备桑基图数据：Token -> Expert -> Attention Weight\n",
    "    \"\"\"\n",
    "    # 节点定义\n",
    "    token_nodes = [f\"Token_{i}\" for i in range(len(seq_tokens))]\n",
    "\n",
    "    expert_nodes = [f\"Expert_{eid}\" for eid in range(30)]\n",
    "    \n",
    "    # 边数据\n",
    "    source = []\n",
    "    target = []\n",
    "    value = []\n",
    "    color = []\n",
    "    \n",
    "    # Token到Expert的连接\n",
    "    for token_idx in range(len(seq_tokens)):\n",
    "        if seq_tokens[token_idx] == -1:  # 跳过padding\n",
    "            continue\n",
    "            \n",
    "        for k in range(top_k):\n",
    "            expert_id = seq_experts[token_idx, k]\n",
    "            gate_score = seq_gate[token_idx, expert_id]\n",
    "            \n",
    "            source.append(token_idx)\n",
    "            target.append(len(token_nodes) + expert_id)\n",
    "            value.append(gate_score)\n",
    "            color.append(f\"rgba(100, 149, 237, {gate_score})\")\n",
    "    \n",
    "    # Expert到Attention的连接\n",
    "    attention_in = seq_attn.sum(axis=0)  # 每个token被关注的程度\n",
    "    \n",
    "    for expert_id in range(30):\n",
    "        # 找出该专家处理的token\n",
    "        expert_tokens = []\n",
    "        for token_idx in range(len(seq_tokens)):\n",
    "            if expert_id in seq_experts[token_idx]:\n",
    "                expert_tokens.append(token_idx)\n",
    "        \n",
    "        if expert_tokens:\n",
    "            # 计算该专家处理的token的平均注意力\n",
    "            avg_attention = np.mean([attention_in[t] for t in expert_tokens])\n",
    "            \n",
    "            source.append(len(token_nodes) + expert_id)\n",
    "            target.append(len(token_nodes) + 30)  # 虚拟的\"Attention\"节点\n",
    "            value.append(avg_attention)\n",
    "            color.append(f\"rgba(255, 99, 71, {avg_attention})\")\n",
    "    \n",
    "    return token_nodes, expert_nodes, source, target, value, color\n",
    "\n",
    "token_nodes, expert_nodes, source, target, value, color = prepare_sankey_data(\n",
    "    seq_attn, seq_gate, seq_experts, seq_tokens\n",
    ")\n",
    "# Cell 5: 创建桑基图\n",
    "def create_sankey_diagram(token_nodes, expert_nodes, source, target, value, color):\n",
    "    \"\"\"\n",
    "    创建桑基图\n",
    "    \"\"\"\n",
    "    # 所有节点\n",
    "    all_nodes = token_nodes + expert_nodes + [\"Attention\"]\n",
    "    node_colors = [\"lightblue\"] * len(token_nodes) + [\"lightgreen\"] * len(expert_nodes) + [\"lightcoral\"]\n",
    "    \n",
    "    # 创建桑基图\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node = dict(\n",
    "            pad = 15,\n",
    "            thickness = 20,\n",
    "            line = dict(color = \"black\", width = 0.5),\n",
    "            label = all_nodes,\n",
    "            color = node_colors\n",
    "        ),\n",
    "        link = dict(\n",
    "            source = source,\n",
    "            target = target,\n",
    "            value = value,\n",
    "            color = color\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title_text=f\"Token-Expert-Attention Flow (Sequence {seq_idx}, Layer {layer_idx})\",\n",
    "    font_size=10,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = create_sankey_diagram(token_nodes, expert_nodes, source, target, value, color)\n",
    "fig.show()\n",
    "# Cell 6: 保存桑基图\n",
    "save_path = f\"/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/sankey_seq{seq_idx}_layer{layer_idx}.html\"\n",
    "fig.write_html(save_path)\n",
    "print(f\"桑基图已保存到: {save_path}\")"
   ],
   "id": "6ea8b424ebbd52e5",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1a7564c4137e8b34",
   "metadata": {},
   "source": [
    "# Cell 1: 导入依赖\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Cell 2: 读取 FASTA 格式的氨基酸序列\n",
    "def read_fasta(filepath):\n",
    "    seqs = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        seq = ''\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if seq:\n",
    "                    seqs.append(seq)\n",
    "                    seq = ''\n",
    "            else:\n",
    "                seq += line.strip()\n",
    "        if seq:\n",
    "            seqs.append(seq)\n",
    "    return seqs\n",
    "\n",
    "# 读取正负样本序列\n",
    "pos_train = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/positive_train.fasta')\n",
    "pos_test = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/positive_test.fasta')\n",
    "neg_train = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/negative_train.fasta')\n",
    "neg_test = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/negative_test.fasta')\n",
    "\n",
    "pos_seqs = pos_train + pos_test\n",
    "neg_seqs = neg_train + neg_test\n",
    "\n",
    "print(f\"正样本序列数: {len(pos_seqs)}\")\n",
    "print(f\"负样本序列数: {len(neg_seqs)}\")\n",
    "print(f\"第一条正样本序列: {pos_seqs[0][:50]}...\")\n",
    "# Cell 3: 设置氨基酸顺序\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "num_aa = len(amino_acids)\n",
    "print(\"氨基酸列表:\", amino_acids)\n",
    "# Cell 4: 计算正样本氨基酸相关性矩阵\n",
    "def get_aa_correlation_matrix(seqs):\n",
    "    \"\"\"\n",
    "    计算20种氨基酸之间的相关性矩阵\n",
    "    seqs: list of strings, 每条序列是氨基酸字符串\n",
    "    \"\"\"\n",
    "    aa_freq_matrix = np.zeros((len(amino_acids), len(seqs)))\n",
    "    \n",
    "    for i, seq in enumerate(seqs):\n",
    "        # 只统计真实氨基酸，不统计其他字符\n",
    "        valid_aa = [aa for aa in seq if aa in amino_acids]\n",
    "        total_len = len(valid_aa)\n",
    "        if total_len == 0:\n",
    "            print(f\"Warning: sequence {i} has no valid amino acids!\")\n",
    "            continue\n",
    "        c = Counter(valid_aa)\n",
    "        for j, aa in enumerate(amino_acids):\n",
    "            aa_freq_matrix[j, i] = c[aa] / total_len\n",
    "    \n",
    "    corr_matrix = np.corrcoef(aa_freq_matrix)\n",
    "    return corr_matrix\n",
    "\n",
    "print(\"计算正样本氨基酸相关性...\")\n",
    "pos_corr = get_aa_correlation_matrix(pos_seqs)\n",
    "# Cell 5: 计算负样本氨基酸相关性矩阵\n",
    "print(\"计算负样本氨基酸相关性...\")\n",
    "neg_corr = get_aa_correlation_matrix(neg_seqs)\n",
    "# Cell 6: 检查相关性矩阵\n",
    "print(\"正样本相关性矩阵最大值：\", np.max(pos_corr))\n",
    "print(\"正样本相关性矩阵最小值：\", np.min(pos_corr))\n",
    "print(\"负样本相关性矩阵最大值：\", np.max(neg_corr))\n",
    "print(\"负样本相关性矩阵最小值：\", np.min(neg_corr))\n",
    "# Cell 7: 转换为DataFrame\n",
    "pos_corr_df = pd.DataFrame(pos_corr, index=amino_acids, columns=amino_acids)\n",
    "neg_corr_df = pd.DataFrame(neg_corr, index=amino_acids, columns=amino_acids)\n",
    "# Cell 8: 画图函数\n",
    "def plot_corr_beauty(corr_df, title, save_path, highlight_boxes=None):\n",
    "    n = len(corr_df)\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    ax = plt.gca()\n",
    "    # 右上角（含主对角线）：画圆圈，主对角线只显示字母\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            val = corr_df.iloc[i, j]\n",
    "            if i == j:\n",
    "                # 主对角线：只显示字母\n",
    "                ax.text(j, i, corr_df.columns[i], ha='center', va='center', fontsize=15, fontweight='bold', color='r')\n",
    "            else:\n",
    "                color = plt.cm.coolwarm((val+0.4)/0.8)\n",
    "                size = abs(val)*800 if abs(val)>0.01 else 0\n",
    "                ax.scatter(j, i, s=size, color=color, alpha=0.8, edgecolor='k', linewidth=0.5)\n",
    "    # 左下角：显示数值\n",
    "    for i in range(1, n):\n",
    "        for j in range(i):\n",
    "            val = corr_df.iloc[i, j]\n",
    "            ax.text(j, i, f\"{val:.2f}\", ha='center', va='center', fontsize=10, color='w' if abs(val)>0.2 else 'gray')\n",
    "    # 高亮部分区域\n",
    "    if highlight_boxes:\n",
    "        for (i0, j0, w, h) in highlight_boxes:\n",
    "            rect = Rectangle((j0-0.5, i0-0.5), w, h, linewidth=2, edgecolor='red', facecolor='none', linestyle='--')\n",
    "            ax.add_patch(rect)\n",
    "    ax.set_xticks(range(n))\n",
    "    ax.set_yticks(range(n))\n",
    "    ax.set_xticklabels(corr_df.columns, fontsize=13)\n",
    "    ax.set_yticklabels(corr_df.index, fontsize=13)\n",
    "    ax.set_xlim(-0.5, n-0.5)\n",
    "    ax.set_ylim(n-0.5, -0.5)\n",
    "    plt.title(title, fontsize=16)\n",
    "    sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=-0.4, vmax=0.4))\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.045, pad=0.03, orientation='horizontal')\n",
    "    cbar.set_label('Correlation', fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "666f741ccbea1609",
   "metadata": {},
   "source": [
    "### 氨基酸频率跟注意力权重得关系（每一个点就表示一个样本，然后上边是指定氨基酸的注意力权重分布，右边是指定氨基酸频率的分布）"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-22T08:35:08.889555Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 加载数据\n",
    "token_types = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/test_token_types.npy\")  # (num_samples, seq_len)\n",
    "attn_weights = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/attn_weights.npy\")      # (num_layers, num_samples, seq_len, seq_len)\n",
    "labels = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/labels.npy\")                  # \n",
    "# (num_samples,)\n",
    "# 你要分析的AA编号（如K=9, R=3, E=7, G=14, Q=8，可自行调整）\n",
    "aa_list = [9, 3, 7, 14, 8]\n",
    "aa_map = {9: \"K(Lys)\", 3: \"R(Arg)\", 7: \"E(Glu)\", 14: \"G(Gly)\", 8: \"Q(Gln)\"}\n",
    "layer_idx = 3  # 可调整分析哪一层\n",
    "df[\"label\"] = df[\"label\"].astype(str)\n",
    "palette = {\"0\": \"#00BFC4\", \"1\": \"#F8766D\"}\n",
    "\n",
    "for aa in aa_list:\n",
    "    all_data = []\n",
    "    for i in range(token_types.shape[0]):\n",
    "        seq = token_types[i]\n",
    "        attn = attn_weights[layer_idx, i]  # (seq_len, seq_len)\n",
    "        label = int(labels[i])\n",
    "        valid_mask = (seq != -1)\n",
    "        seq_len = valid_mask.sum()\n",
    "        aa_pos = np.where(seq == aa)[0]\n",
    "        if len(aa_pos) == 0 or seq_len == 0:\n",
    "            continue\n",
    "        # 频率\n",
    "        freq = len(aa_pos) / seq_len\n",
    "        # 被关注度：所有token对这些AA位置的attention weight之和，取均值\n",
    "        attn_in = attn[:, aa_pos]         # (seq_len, n_aa)\n",
    "        attn_in_mean = attn_in.mean()     # 直接均值，范围0~1\n",
    "        all_data.append({\n",
    "            'freq': freq,\n",
    "            'attn_weight': attn_in_mean,\n",
    "            'label': label\n",
    "        })\n",
    "    df = pd.DataFrame(all_data)\n",
    "    if df.empty:\n",
    "        print(f\"{aa_map.get(aa, aa)} 没有数据，跳过\")\n",
    "        continue\n",
    "\n",
    "    # jointplot：散点+上下分布\n",
    "    plt.figure()\n",
    "    df[\"label\"] = df[\"label\"].astype(str)\n",
    "    palette = {'0': \"#00BFC4\", '1': \"#F8766D\"}\n",
    "    g = sns.jointplot(\n",
    "        data=df, x=\"attn_weight\", y=\"freq\", hue=\"label\", palette=palette,\n",
    "        kind=\"scatter\", height=7, marginal_kws=dict(common_norm=False, fill=True, alpha=0.5)\n",
    "    )\n",
    "    g.ax_joint.set_xlabel(\"Mean attention-in\")\n",
    "    g.ax_joint.set_ylabel(\"Amino acid frequency \")\n",
    "    plt.suptitle(f\"{aa_map.get(aa, aa)} | Layer {layer_idx}\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    r, p = pearsonr(df[\"attn_weight\"], df[\"freq\"])\n",
    "    print(f\"Pearson r = {r:.3f}, p-value = {p:.3g}\")\n",
    "\n",
    "    # 上方箱型图：正负样本的被关注度分布\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.boxplot(x=\"label\", y=\"attn_weight\", data=df, palette=palette)\n",
    "    plt.title(f\"{aa_map.get(aa, aa)} 被关注度分布 | Layer {layer_idx}\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Mean attention-in\")\n",
    "    plt.show()\n",
    "\n",
    "    # 右侧箱型图：正负样本的频率分布\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.boxplot(x=\"label\", y=\"freq\", data=df, palette=palette)\n",
    "    plt.title(f\"{aa_map.get(aa, aa)} 频率分布 | Layer {layer_idx}\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Amino acid frequency\")\n",
    "    p\"lt.show()\n",
    "\"\"\""
   ],
   "id": "6ae3527806e0a499",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-22T08:35:08.890671Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"print(df[\"label\"].unique())\n",
    "print(type(df[\"label\"].iloc[0]))\n",
    "print(\"attn sum per column:\", attn.sum(axis=0))\n",
    "print(\"attn sum per row:\", attn.sum(axis=1))\"\"\""
   ],
   "id": "b72b38b382a0995",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-22T08:35:08.891768Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"from collections import Counter\n",
    "\n",
    "all_aa = token_types[token_types != 0]\n",
    "aa_counts = Counter(all_aa.flatten())\n",
    "total = len(all_aa)\n",
    "\n",
    "for aa, count in aa_counts.items():\n",
    "    print(f\"AA {aa}: {count} 次，频率约 {count / total:.4f}\")\n",
    "print(\"token_types.min():\", token_types.min())\n",
    "idx = np.argmax((token_types == -1).sum(axis=1))  # 找出含 -1 最多的样本\n",
    "print(\"含 -1 的样本索引：\", idx)\n",
    "print(\"token_types[{}]:\".format(idx), token_types[idx])\"\"\"\n"
   ],
   "id": "55cf289364af2a62",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3978e66fcbdfcc5b",
   "metadata": {},
   "source": [
    "# 判断专家是否专注于有意义的区域"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-22T08:35:08.892920Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "def read_fasta(filepath):\n",
    "    \"\"\"读取fasta文件\"\"\"\n",
    "    seqs = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        seq = ''\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                if seq:\n",
    "                    seqs.append(seq)\n",
    "                    seq = ''\n",
    "            else:\n",
    "                seq += line.strip()\n",
    "        if seq:\n",
    "            seqs.append(seq)\n",
    "    return seqs\n",
    "\n",
    "# 读取测试集序列\n",
    "pos_test_seqs = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/positive_test.fasta')\n",
    "neg_test_seqs = read_fasta('/exp_data/sjx/star/first_data/shisuandanbai/negative_test.fasta')\n",
    "\n",
    "print(f\"正样本测试集序列数: {len(pos_test_seqs)}\")\n",
    "print(f\"负样本测试集序列数: {len(neg_test_seqs)}\")\n",
    "\n",
    "# 加载模型权重数据\n",
    "attn_weights = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/attn_weights.npy\")\n",
    "gate_scores = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/gate_scores.npy\")\n",
    "topk_idx = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/topk_idx.npy\")\n",
    "labels = np.load(\"/exp_data/sjx/star/main_transformer_moe_weight/experiment_data/labels.npy\")\n",
    "\n",
    "print(f\"数据形状:\")\n",
    "print(f\"  attn_weights: {attn_weights.shape}\")\n",
    "print(f\"  gate_scores: {gate_scores.shape}\")\n",
    "print(f\"  topk_idx: {topk_idx.shape}\")\n",
    "print(f\"  labels: {labels.shape}\")\n",
    "\n",
    "# 选择第一条正样本序列进行分析\n",
    "seq_idx = 1  # 第一条正样本\n",
    "layer_idx = 0  # 第一层\n",
    "target_seq = pos_test_seqs[seq_idx]\n",
    "seq_len = len(target_seq)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"序列详细信息\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"序列索引: {seq_idx}\")\n",
    "print(f\"序列长度: {seq_len}\")\n",
    "print(f\"序列标签: {labels[seq_idx]} (1=正样本)\")\n",
    "print(f\"完整序列: {target_seq}\")\n",
    "print(f\"序列前50个氨基酸: {target_seq[:50]}\")\n",
    "print(f\"序列后50个氨基酸: {target_seq[-50:] if seq_len > 50 else target_seq}\")\n",
    "\n",
    "# 氨基酸组成统计\n",
    "aa_counts = Counter(target_seq)\n",
    "print(f\"\\n氨基酸组成:\")\n",
    "for aa in sorted(aa_counts.keys()):\n",
    "    print(f\"  {aa}: {aa_counts[aa]} ({aa_counts[aa]/seq_len*100:.1f}%)\")\n",
    "\n",
    "# 检查注意力权重的实际形状\n",
    "print(f\"\\n注意力权重形状检查:\")\n",
    "print(f\"  attn_weights[layer_idx, seq_idx].shape: {attn_weights[layer_idx, seq_idx].shape}\")\n",
    "print(f\"  attn_weights[layer_idx, seq_idx].ndim: {attn_weights[layer_idx, seq_idx].ndim}\")\n",
    "\n",
    "# 根据实际形状获取注意力权重\n",
    "if attn_weights[layer_idx, seq_idx].ndim == 3:\n",
    "    # 如果是 [heads, seq_len, seq_len]\n",
    "    seq_attn = attn_weights[layer_idx, seq_idx].mean(axis=0)  # [seq_len, seq_len]\n",
    "elif attn_weights[layer_idx, seq_idx].ndim == 2:\n",
    "    # 如果已经是 [seq_len, seq_len]\n",
    "    seq_attn = attn_weights[layer_idx, seq_idx]\n",
    "else:\n",
    "    print(f\"意外的注意力权重形状: {attn_weights[layer_idx, seq_idx].shape}\")\n",
    "    # 尝试重塑\n",
    "    seq_attn = attn_weights[layer_idx, seq_idx].reshape(300, 300)  # 假设最大长度是300\n",
    "\n",
    "seq_gate_scores = gate_scores[layer_idx, seq_idx]  # [seq_len, num_experts]\n",
    "seq_expert_assign = topk_idx[layer_idx, seq_idx]  # [seq_len, topk]\n",
    "\n",
    "print(f\"\\n处理后的数据形状:\")\n",
    "print(f\"  seq_attn: {seq_attn.shape}\")\n",
    "print(f\"  seq_gate_scores: {seq_gate_scores.shape}\")\n",
    "print(f\"  seq_expert_assign: {seq_expert_assign.shape}\")\n",
    "\n",
    "# 只取实际序列长度的部分（去除padding）\n",
    "seq_attn = seq_attn[:seq_len, :seq_len]\n",
    "seq_gate_scores = seq_gate_scores[:seq_len]\n",
    "seq_expert_assign = seq_expert_assign[:seq_len]\n",
    "\n",
    "print(f\"\\n裁剪后的数据形状:\")\n",
    "print(f\"  seq_attn: {seq_attn.shape}\")\n",
    "print(f\"  seq_gate_scores: {seq_gate_scores.shape}\")\n",
    "print(f\"  seq_expert_assign: {seq_expert_assign.shape}\")\n",
    "\n",
    "# 计算每个位置的注意力权重总和（被其他位置关注的程度）\n",
    "attention_in = seq_attn.sum(axis=0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"高注意力区域分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 找出高注意力区域\n",
    "attention_threshold = np.percentile(attention_in, 80)  # 前20%的高注意力位置\n",
    "high_attention_positions = np.where(attention_in > attention_threshold)[0]\n",
    "\n",
    "print(f\"注意力阈值 (前20%): {attention_threshold:.4f}\")\n",
    "print(f\"高注意力位置数量: {len(high_attention_positions)}\")\n",
    "print(f\"高注意力位置索引: {high_attention_positions.tolist()}\")\n",
    "\n",
    "print(f\"\\n高注意力位置详细信息:\")\n",
    "for i, pos in enumerate(high_attention_positions):\n",
    "    print(f\"  位置 {pos+1}: {target_seq[pos]} (注意力分数: {attention_in[pos]:.4f})\")\n",
    "\n",
    "print(f\"\\n高注意力区域序列片段:\")\n",
    "high_attention_seq = ''.join([target_seq[i] for i in high_attention_positions])\n",
    "print(f\"  完整片段: {high_attention_seq}\")\n",
    "\n",
    "# 分析每个专家专注的位置\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"专家专注区域分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "num_experts = gate_scores.shape[-1]\n",
    "for expert_id in range(num_experts):\n",
    "    # 找出该专家被分配的位置\n",
    "    expert_positions = []\n",
    "    for pos in range(seq_len):\n",
    "        if expert_id in seq_expert_assign[pos]:\n",
    "            expert_positions.append(pos)\n",
    "    \n",
    "    if expert_positions:\n",
    "        # 计算该专家专注位置与高注意力位置的重合度\n",
    "        overlap = len(set(expert_positions) & set(high_attention_positions))\n",
    "        overlap_ratio = overlap / len(expert_positions) if expert_positions else 0\n",
    "        \n",
    "        print(f\"\\nExpert {expert_id}:\")\n",
    "        print(f\"  专注位置数量: {len(expert_positions)}\")\n",
    "        print(f\"  专注位置索引: {expert_positions}\")\n",
    "        print(f\"  专注位置氨基酸: {[target_seq[i] for i in expert_positions]}\")\n",
    "        print(f\"  专注区域序列: {''.join([target_seq[i] for i in expert_positions])}\")\n",
    "        print(f\"  与高注意力区域重合度: {overlap_ratio:.2f} ({overlap}/{len(expert_positions)})\")\n",
    "        \n",
    "        # 分析该专家专注的氨基酸类型\n",
    "        aa_counts = Counter([target_seq[i] for i in expert_positions])\n",
    "        print(f\"  氨基酸分布: {dict(aa_counts)}\")\n",
    "        \n",
    "        # 计算该专家专注位置的平均门控分数\n",
    "        avg_gate_score = np.mean([seq_gate_scores[pos, expert_id] for pos in expert_positions])\n",
    "        print(f\"  平均门控分数: {avg_gate_score:.4f}\")\n",
    "\n",
    "# 保存序列信息到文件\n",
    "with open('/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/sequence_analysis_info.txt', 'w') as f:\n",
    "    f.write(\"序列分析详细信息\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"序列索引: {seq_idx}\\n\")\n",
    "    f.write(f\"序列长度: {seq_len}\\n\")\n",
    "    f.write(f\"完整序列: {target_seq}\\n\")\n",
    "    f.write(f\"高注意力位置: {high_attention_positions.tolist()}\\n\")\n",
    "    f.write(f\"高注意力区域序列: {high_attention_seq}\\n\")\n",
    "\n",
    "print(f\"\\n序列信息已保存到: /exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/sequence_analysis_info.txt\")\"\"\""
   ],
   "id": "4a1038a1accb6d5c",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cc90dc35ed3d1e53",
   "metadata": {},
   "source": [
    "##### UniProt ID: A0A3M8QPJ6"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-22T08:35:08.894043Z"
    }
   },
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你已经有 attn_weights, pos_test_seqs, seq_idx, target_seq, seq_len\n",
    "import numpy as np\n",
    "\n",
    "# 假设你已经有 attn_weights, target_seq, seq_idx, seq_len\n",
    "import numpy as np\n",
    "\n",
    "# 调整高注意力token的输出，减少数量，提高阈值\n",
    "def output_high_attention_tokens(attn_weights, target_seq, seq_idx, seq_len, output_txt, percentile=95):\n",
    "    with open(output_txt, 'w') as f:\n",
    "        f.write(f\"Sequence index: {seq_idx}\\n\")\n",
    "        f.write(f\"Sequence length: {seq_len}\\n\")\n",
    "        f.write(f\"Full sequence:\\n{target_seq}\\n\\n\")\n",
    "        for layer_idx in range(4):\n",
    "            attn = attn_weights[layer_idx, seq_idx]\n",
    "            if attn.ndim == 3:\n",
    "                attn = attn.mean(axis=0)\n",
    "            attn = attn[:seq_len, :seq_len]\n",
    "            attention_in = attn.sum(axis=0)\n",
    "            attention_threshold = np.percentile(attention_in, percentile)\n",
    "            high_idx = np.where(attention_in >= attention_threshold)[0]\n",
    "            high_aas = [target_seq[i] for i in high_idx]\n",
    "            f.write(f\"Layer {layer_idx} high-attention tokens (threshold={attention_threshold:.4f}, top {len(high_idx)} tokens):\\n\")\n",
    "            f.write(f\"Indices: {high_idx.tolist()}\\n\")\n",
    "            f.write(f\"Amino acids: {''.join(high_aas)}\\n\\n\")\n",
    "            print(f\"Layer {layer_idx}: high-attention token indices: {high_idx.tolist()}\")\n",
    "            print(f\"Layer {layer_idx}: high-attention amino acids: {''.join(high_aas)}\")\n",
    "            print(f\"Layer {layer_idx}: number of high-attention tokens: {len(high_idx)}\")\n",
    "\n",
    "# 用法示例（提高阈值到90%，减少高注意力token数量）：\n",
    "# output_high_attention_tokens(attn_weights, target_seq, seq_idx, seq_len, '/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/high_attention_tokens_info.txt', percentile=90)\n",
    "for layer_idx in range(4):  # 4层\n",
    "    # 1. 取该层的注意力\n",
    "    attn = attn_weights[layer_idx, seq_idx]\n",
    "    if attn.ndim == 3:\n",
    "        attn = attn.mean(axis=0)  # [seq_len, seq_len]\n",
    "    attn = attn[:seq_len, :seq_len]\n",
    "\n",
    "    # 2. 注意力热图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(attn, cmap='Blues', aspect='auto')\n",
    "    plt.title(f'Attention Weights (Layer {layer_idx})')\n",
    "    plt.xlabel('Token Position')\n",
    "    plt.ylabel('Token Position')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/attn_heatmap_layer{layer_idx}.svg')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # 3. 注意力权重分布\n",
    "    attention_in = attn.sum(axis=0)\n",
    "    attention_threshold = np.percentile(attention_in, 80)\n",
    "    high_attention_positions = np.where(attention_in > attention_threshold)[0]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(seq_len), attention_in, 'b-', linewidth=2)\n",
    "    plt.axhline(y=attention_threshold, color='r', linestyle='--', label=f'Threshold ({attention_threshold:.4f})')\n",
    "    plt.scatter(high_attention_positions, attention_in[high_attention_positions], \n",
    "                color='red', s=50, zorder=5, label='High Attention Positions')\n",
    "    plt.title(f'Attention Incoming Weights (Layer {layer_idx})')\n",
    "    plt.xlabel('Token Position')\n",
    "    plt.ylabel('Sum of Incoming Attention')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/attn_incoming_layer{layer_idx}.svg')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # 3.1 输出注意力权重最高的前5个token\n",
    "    top_n = 5\n",
    "    top_idx = np.argsort(attention_in)[-top_n:][::-1]  # 从大到小\n",
    "    top_aas = [target_seq[i] for i in top_idx]\n",
    "    top_values = attention_in[top_idx]\n",
    "    print(f\"Layer {layer_idx}: Top {top_n} high-attention token indices: {top_idx.tolist()}\")\n",
    "    print(f\"Layer {layer_idx}: Top {top_n} high-attention amino acids: {''.join(top_aas)}\")\n",
    "    print(f\"Layer {layer_idx}: Top {top_n} attention values: {top_values.tolist()}\")\n",
    "output_high_attention_tokens(attn_weights, target_seq, seq_idx, seq_len, '/exp_data/sjx/star/main_transformer_moe_weight/moe_analysis/high_attention_tokens_info.txt')\"\"\""
   ],
   "id": "989f04769569b28c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "29dc436ff909ec",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
