{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:11.804400Z",
     "start_time": "2025-07-12T02:07:09.594600Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, roc_auc_score, average_precision_score\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(42)  # 你可以换成其它数字\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 数据集类\n",
    "class ProteinNPYIndexDataset(Dataset):\n",
    "    def __init__(self, pos_path, neg_path, pos_indices, neg_indices):\n",
    "        self.pos_path = pos_path\n",
    "        self.neg_path = neg_path\n",
    "        self.pos_indices = pos_indices\n",
    "        self.neg_indices = neg_indices\n",
    "        self.pos_len = len(pos_indices)\n",
    "        self.neg_len = len(neg_indices)\n",
    "        self.total_len = self.pos_len + self.neg_len\n",
    "        self.pos_npy = None\n",
    "        self.neg_npy = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.pos_npy is None:\n",
    "            self.pos_npy = np.load(self.pos_path, mmap_mode='r')\n",
    "        if self.neg_npy is None:\n",
    "            self.neg_npy = np.load(self.neg_path, mmap_mode='r')\n",
    "        if idx < self.pos_len:\n",
    "            x = self.pos_npy[self.pos_indices[idx]]\n",
    "            y = 1\n",
    "        else:\n",
    "            x = self.neg_npy[self.neg_indices[idx - self.pos_len]]\n",
    "            y = 0\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "class MLPExperts(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.fc1 = nn.Linear(d_model, d_ff * num_experts, bias=True)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model, bias=True)\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "    def forward(self, x, expert_idx):\n",
    "        # x: [B*L, d_model], expert_idx: [B*L, k]\n",
    "        all_hidden = self.fc1(x)  # [B*L, d_ff * num_experts]\n",
    "        all_hidden = all_hidden.view(x.size(0), self.num_experts, self.d_ff)  # [B*L, num_experts, d_ff]\n",
    "        out = []\n",
    "        for i in range(expert_idx.size(1)):\n",
    "            idx = expert_idx[:, i]  # [B*L]\n",
    "            hidden = all_hidden[torch.arange(x.size(0)), idx]  # [B*L, d_ff]\n",
    "            hidden = F.gelu(hidden)\n",
    "            out_i = self.fc2(hidden)  # [B*L, d_model]\n",
    "            out.append(out_i)\n",
    "        out = torch.stack(out, dim=1)  # [B*L, k, d_model]\n",
    "        return out\n",
    "\n",
    "\n",
    "class NoisyTopKMoE(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, num_experts=30, k=2, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.k = k\n",
    "        self.noisy_std = noisy_std\n",
    "        self.experts = MLPExperts(d_model, d_ff, num_experts)\n",
    "        self.gate = nn.Linear(d_model, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, d_model]\n",
    "        B, L, D = x.shape\n",
    "        x_flat = x.reshape(-1, D)  # [B*L, D]\n",
    "        gate_logits = self.gate(x_flat)  # [B*L, num_experts]\n",
    "        # Noisy gating\n",
    "        if self.training and self.noisy_std > 0:\n",
    "            noise = torch.randn_like(gate_logits) * self.noisy_std\n",
    "            gate_logits = gate_logits + noise\n",
    "        gate_scores = F.softmax(gate_logits, dim=-1)  # [B*L, num_experts]\n",
    "\n",
    "        # 稀疏路由：只选top-k\n",
    "        topk_val, topk_idx = torch.topk(gate_scores, self.k, dim=-1)  # [B*L, k]\n",
    "        # 负载均衡损失（新版，防止爆炸）\n",
    "        meangate = gate_scores.mean(dim=0)  # [num_experts]\n",
    "        load_balance_loss = (meangate * meangate).sum() * (self.num_experts ** 2)\n",
    "        # 专家并行输出\n",
    "        expert_outs = self.experts(x_flat, topk_idx)  # [B*L, k, d_model]\n",
    "        topk_val = topk_val / (topk_val.sum(dim=-1, keepdim=True) + 1e-9)\n",
    "        moe_out = (expert_outs * topk_val.unsqueeze(-1)).sum(dim=1)  # [B*L, d_model]\n",
    "        moe_out = moe_out.view(B, L, D)\n",
    "        return moe_out, load_balance_loss\n",
    "\n",
    "\n",
    "class TransformerMoEBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, num_experts=30, k=2, dropout=0.1, noisy_std=1.0):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.moe = NoisyTopKMoE(d_model, d_ff, num_experts, k, noisy_std)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        moe_out, load_balance_loss = self.moe(x)\n",
    "        x = x + self.dropout(moe_out)\n",
    "        x = self.norm2(x)\n",
    "        return x, load_balance_loss\n",
    "\n",
    "\n",
    "class TransformerMoE(nn.Module):\n",
    "    def __init__(self, d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=2, dropout=0.1, noisy_std=1.0,\n",
    "                 num_classes=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerMoEBlock(d_model, nhead, d_ff, num_experts, k, dropout, noisy_std)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        total_load_balance_loss = 0\n",
    "        for layer in self.layers:\n",
    "            x, lb_loss = layer(x)\n",
    "            total_load_balance_loss += lb_loss\n",
    "        x = x.mean(dim=1)  # 池化\n",
    "        logits = self.classifier(x)\n",
    "        return logits, total_load_balance_loss\n",
    "\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    pre = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "    sn = rec\n",
    "    sp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    print(f\"ACC: {acc:.4f}, F1: {f1:.4f}, Recall(Sn): {sn:.4f}, MCC: {mcc:.4f}, Precision: {pre:.4f}, Sp: {sp:.4f}, AUC: {auc:.4f}, AUPRC: {auprc:.4f}\")\n",
    "    return acc, f1, sn, mcc, pre, sp, auc, auprc"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:11.812366Z",
     "start_time": "2025-07-12T02:07:11.805958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_train_embedding.npy'\n",
    "train_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_train_embedding.npy'\n",
    "test_pos = '/exp_data/sjx/star/first_data/ESM-embedding/positive_test_embedding.npy'\n",
    "test_neg = '/exp_data/sjx/star/first_data/ESM-embedding/negative_test_embedding.npy'\n",
    "\n",
    "pos_len = np.load(train_pos, mmap_mode='r').shape[0]\n",
    "neg_len = np.load(train_neg, mmap_mode='r').shape[0]\n",
    "test_pos_len = np.load(test_pos, mmap_mode='r').shape[0]\n",
    "test_neg_len = np.load(test_neg, mmap_mode='r').shape[0]\n",
    "\n",
    "print(f\"训练集正样本: {pos_len}, 负样本: {neg_len}\")\n",
    "print(f\"测试集正样本: {test_pos_len}, 负样本: {test_neg_len}\")"
   ],
   "id": "d656ccd27230d096",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 上采样方法",
   "id": "94d31a5d004cae74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:11.818866Z",
     "start_time": "2025-07-12T02:07:11.814810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 上采样负样本到与正样本一样多\n",
    "pos_indices = np.arange(pos_len)\n",
    "neg_indices = np.random.choice(neg_len, size=pos_len, replace=True)\n",
    "\n",
    "train_dataset = ProteinNPYIndexDataset(train_pos, train_neg, pos_indices, neg_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)"
   ],
   "id": "65c8fac8e27e49ba",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 权重采样方法",
   "id": "76442599428c0337"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:11.826317Z",
     "start_time": "2025-07-12T02:07:11.820216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 权重采样\n",
    "all_indices = np.concatenate([np.arange(pos_len), np.arange(neg_len)])\n",
    "all_labels = np.concatenate([np.ones(pos_len, dtype=int), np.zeros(neg_len, dtype=int)])\n",
    "weights = np.zeros_like(all_labels, dtype=np.float32)\n",
    "weights[all_labels == 1] = 1. / pos_len\n",
    "weights[all_labels == 0] = 1. / neg_len\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "train_dataset_w = ProteinNPYIndexDataset(train_pos, train_neg, np.arange(pos_len), np.arange(neg_len))\n",
    "train_loader_w = DataLoader(train_dataset_w, batch_size=32, sampler=sampler, num_workers=2)"
   ],
   "id": "9d3616d6db5c97d0",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:11.830293Z",
     "start_time": "2025-07-12T02:07:11.827742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = ProteinNPYIndexDataset(test_pos, test_neg, np.arange(test_pos_len), np.arange(test_neg_len))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ],
   "id": "5fc0ad4e86d48370",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:11.834999Z",
     "start_time": "2025-07-12T02:07:11.831834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "id": "b038222713d28f19",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:07:24.461092Z",
     "start_time": "2025-07-12T02:07:20.882555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TransformerMoE(\n",
    "    d_model=1152, nhead=8, d_ff=2048, num_layers=4, num_experts=30, k=3, dropout=0.1, noisy_std=1.0, num_classes=2\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "id": "d241f3d50ec76fda",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用train_loader使用上采样方法",
   "id": "40599841843326b0"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-11T16:50:27.386371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_dir = '/exp_data/sjx/star/experiments/gan_anlysis/gan_sampling/weight_points/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # 每个epoch都保存最后权重\n",
    "    last_path = os.path.join(save_dir, 'moe_last.pth')\n",
    "    torch.save(model.state_dict(), last_path)"
   ],
   "id": "d8d2efc7d0a05e8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:08:08.648128Z",
     "start_time": "2025-07-12T02:07:52.471882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"测试集评估：\")\n",
    "save_dir = '/exp_data/sjx/star/experiments/gan_anlysis/gan_sampling/weight_points/'\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'moe_last.pth')))\n",
    "eval_model(model, test_loader, device)"
   ],
   "id": "c18752534e331f90",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用train_loader_w使用权重采样",
   "id": "a4133bd9dffb40d2"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "save_dir = '/exp_data/sjx/star/experiments/gan_anlysis/gan_sampling/weight_points/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    loss = train_one_epoch(model, train_loader_w, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # 每个epoch都保存最后权重\n",
    "    last_path = os.path.join(save_dir, 'moe_last_w.pth')\n",
    "    torch.save(model.state_dict(), last_path)"
   ],
   "id": "7c0dbb2fc6c07a49",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:08:24.562534Z",
     "start_time": "2025-07-12T02:08:08.650299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"测试集评估：\")\n",
    "save_dir = '/exp_data/sjx/star/experiments/gan_anlysis/gan_sampling/weight_points/'\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'moe_last_w.pth')))\n",
    "eval_model(model, test_loader, device)"
   ],
   "id": "83cbb307e62c3f97",
   "execution_count": 11,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
